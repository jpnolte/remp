[["index.html", "R für empirische Wissenschaften Vorwort Lizenz", " R für empirische Wissenschaften Jan Philipp Nolte 2023-03-16 Vorwort Willkommen zur Internetseite des Buches R für empirische Wissenschaften. Hier wirst du ohne Vorwissen lernen, die Programmiersprache R zur Datenanalyse anzuwenden. Die Zielgruppen sind WissenschaftlerInnen und StudentInnen der Fachrichtungen Medizin, Psychologie, Betriebswirtschaftslehre, Wirtschaftswissenschaften, soziale Arbeit, Pharmazie, Agrarwissenschaften, Neurowissenschaften, Biologie, Journalismus, Tourismus, Data Science, Biostatistik und allen weiteren Disziplinen, die Daten auswerten möchten. Ergänzend wird das remp Package bereitgestellt, welches Datensätze, Übungen und praktische Funktionen beinhaltet. In der Navigationsleiste auf der linken Seite können zwölf Kapitel ausgewählt werden. Alternativ kannst du auch mithilfe der linken und rechten Pfeiltaste zwischen den Hauptkapiteln wechseln. Oben in der Leiste ruft die Lupe die Suchfunktion auf, während man über das A die Schriftgröße, Schriftart und das Farbthema anpassen kann. Lizenz Veröffentlicht ist das gesamte Buch unter der Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International Lizenz. "],["intro.html", "Kapitel 1 Einleitung 1.1 Für wen ist dieses Buch? 1.2 Aufbau und Bearbeitungsstrategie 1.3 Boxen, Übungen und Datensätze 1.4 Ergänzende Literatur", " Kapitel 1 Einleitung In diesem Kapitel wird die allgemeine Herangehensweise an die verschiedenen Themen dieses Buches erläutert. Außerdem werden hilfreiche Bücher zur Vertiefung und zum Erlangen des Statistikverständnisses vorgestellt. 1.1 Für wen ist dieses Buch? Das Buch ist grundsätzlich für jeden geeignet, der R lernen möchte. Ein Vorwissen über Programmiersprachen wird nicht vorausgesetzt. Neben der Grundlagen von R wirst du nach Lesen dieses Buches einen Datensatz einlesen und bereinigen können. Du wirst verstehen, wie man publikationsreife Visualisierungen und Tabellen erstellt. Auch wirst du deskriptive Maße und die üblichsten statistischen Hypothesentests berechnen können. Die statistischen Verfahren werden nicht separat eingeführt, da es dafür bereits ausführliche Lehrbücher gibt. Dieses Buch konzentriert sich folglich auf die computergestützte Datenauswertung und nicht auf die zugrundeliegende Statistik. 1.2 Aufbau und Bearbeitungsstrategie Tatsächlich sind die Kapitel in der Reihenfolge aufgebaut, wie man normalerweise mit einem frisch erhobenen Datensatz umgeht. Nachdem alles richtig eingerichtet und aufgesetzt ist (Teil I), werden die Daten bereinigt und aufbereitet (Teil II), bis die Fragestellungen mithilfe statistischer Analysen beantwortet werden (Teil III). Vertiefende Konzepte für eine fortgeschrittene Verwendung runden den Inhalt des Buches schließlich ab (Teil IV). Teil I: Die ersten Schritte. Kapitel eins und zwei bilden den ersten Teil, der auch von Lesern, die bereits mit R gearbeitet haben, gründlich durchgelesen werden sollte. Vor allem die Installation bereitet häufig schon die ersten großen Probleme. Auch werden verschiedene Hilfestellungen eingeführt. Teil II: Vorbereitung. Die meiste Zeit in der Datenanalyse wird von der Datenvorbereitung beansprucht. Die eigentliche Auswertung geht anschließend meistens vergleichsweise schnell. Daher ist die Datenvorbereitung auch eines der ausführlichsten Kapitel dieses Buches. Außerdem werden die essentiellen R Projektdateien sowie einige notwendige Grundlagen erläutert. Darüber hinaus wird das Einlesen von Datensätzen verschiedener Dateienarten erklärt. Teil III: Auswertung. Wenn der Datensatz endlich fertig aufbereitet ist, können Abbildungen erstellt sowie deskriptive Statistiken und inferenzstatistische Hypothesentests berechnet werden. Die Visualisierungen und in Tabellen dargestellten Ergebnisse werden dabei direkt publikationsreif ausgegeben. Teil IV: Vertiefung. Hier werden weiterführende und vertiefende Konzepte vorgestellt, die nicht zwingend für die eigentliche Datenanalyse benötigt werden. Es wird erklärt, wie man Tabellen oder ganze Berichte in Word oder PDF umwandeln kann. Die verschiedenen Datenstrukturen werden verglichen und abschließend fortgeschrittenere Programmiertechniken vorgestellt. Jeder hat einen individuellen Lernstil und liest ein Lehrbuch auf unterschiedliche Art und Weise. Die einzelnen Kapitel des Buches bauen zwar grundsätzlich aufeinander auf, allerdings wurde gleichzeitig darauf geachtet, die Kapitel zum schnellen Nachschlagen möglichst in sich geschlossen zu halten. Wer also nicht das gesamte Buch Schritt für Schritt durcharbeiten möchte, sollte aber zumindest nachfolgende Kapitel gelesen haben. Dies gilt auch für jene, die nur an einem ganz bestimmten statistischen Test für die Bachelorarbeit interessiert sind. Zeitmangel? Man sollte sich mindestens mit den Kapiteln 2, 3, 4, 5 und 6.1 vertraut machen, da diese essentiell zum Arbeiten mit R sind. 1.3 Boxen, Übungen und Datensätze Es gibt drei Arten von Boxen mit jeweils unterschiedlicher Farbe und Symbol. Die mit der Glühbirne markierten Boxen fassen besonders wichtige Konzepte zusammen, die mit dem Warnzeichnen weisen auf häufige Probleme hin und die mit dem Laptop enthalten interaktive Übungen. Nach Durcharbeiten dieses Buches kann jeder und jede selbstständig Fragestellungen verschiedener wissenschaftlicher Fachrichtungen anhand eigener Datensätze beantworten. Nach dem Starten von R sollte immer erst ein Projekt erstellt werden, bevor die Datensätze durch Befehle innerhalb eines R Skripts eingelesen werden. Übung 6.1. In dieser Übung lernst du das Auswählen und Umbenennen von Spalten eines Datensatzes. Starte die Übung mit hands_on(\"6.1\"). Die Funktion hands_on() öffnet deinen Browser, in welchem du dann die Übungen bearbeiten kannst. Dafür wird kein Internet benötigt. Alternativ stehen die Übungsaufgaben und Lösungen auch auf der Internetseite zum Buch bereit (https://r-empirische-wissenschaften.de). Das zugehörige Übungsverzeichnis findest du im Appendix. Im Laufe des Buches werden aus didaktischen Gründen verschiedene Datensätze verwendet, die ebenfalls im Appendix genau vorgestellt werden. Zum Anwenden auf dem heimischen Computer oder Laptop kannst du entweder händisch den im Buch beschrieben Code abtippen oder du verwendest den Copy to Clipboard Button, der online oben rechts im Codeblock erscheint. Dieser macht genau dasselbe, als würdest du den Befehl markieren und mit Strg + c oder Rechtsklick + Kopieren kopieren. 1.4 Ergänzende Literatur Statistik: Der Weg zur Datenanalyse. Ein verständliches, deutschsprachiges Buch als Einleitung für die wichtigsten Konzepte der Statistik. Der Fokus liegt tendenziell eher auf Sozial- und WirtschaftswissenschaftlerInnen, allerdings eignet sich das Buch generell als Einführung in die Statistik. Regression Methods in Biostatistics: Linear, Logistic, Survival, and Repeated Measures Models. Dieses Buch ist etwas fortgeschrittener als das zuvor genannte, wobei hier alle in diesem Buch verwendeten statistischen Modelle ausführlich erklärt werden. ggplot2: Elegant Graphics for Data Analysis (3rd Edition). In R für empirische Wissenschaften wird ein sehr umfangreiches Erweiterungspaket namens ggplo2 zum Erstellen der Visualisierungen verwendet. Während es hier um konkrete Anwendungen geht, werden im vorgeschlagenen Buch die technischen Hintergründe erläutert. Diese sind vor allem interessant, wenn man darauf basierende Erweiterungen entweder verwenden oder selbst erstellen möchte. Das Buch kann kostenlos unter https://ggplot2-book.org/ eingesehen werden. R Markdown: The Definite Guide. Dieses Buch erläutert die in Kapitel 10.2 eingeführten Exportierungsmöglichkeiten mithilfe von R Markdown deutlich ausführlicher. Denn mit R Markdown kann man nicht nur Tabellen und kurze Berichte, sondern auch Bücher, Internetseiten und Abschlussarbeiten erstellen. Es ist kostenlos auf der Seite https://bookdown.org/yihui/rmarkdown/ lesbar. Advanced R (2nd Edition). Hier werden tiefe Einblicke in R als Programmiersprache als solche gegeben. Wenn man seine Programmierfähigkeit mit R ausbauen möchte, kommt man an diesem Buch nicht vorbei. Auch hier kann das Buch im Internet kostenfrei gelesen werden (https://adv-r.hadley.nz/). "],["start.html", "Kapitel 2 Startvoraussetzungen 2.1 Installation von R und RStudio 2.2 Aufbau von RStudio 2.3 RStudio anpassen 2.4 Funktionen und ihre Argumente 2.5 Packages (Erweiterungen) 2.6 Fehler- und Warnmeldungen", " Kapitel 2 Startvoraussetzungen Die erste große Hürde beim Programmieren ist häufig die Einrichtung der notwendigen Programme auf dem eigenen Computer. Auch wenn im Falle von R die Installation vergleichsweise einfach funktioniert, haben doch viele AnfängerInnen Probleme damit. Schritt für Schritt wird außerdem erklärt, was Funktionen sind und wie man mit deren Hilfe Erweiterungen installieren und laden kann. Abschließend wird das Beheben von Fehlern besprochen. 2.1 Installation von R und RStudio Die Unterscheidung zwischen R und RStudio ist für viele Anfänger verwirrend. Entgegen des ersten Eindrucks, handelt es sich dabei nicht um zwei austauschbare Alternativen. Stattdessen stellt R die Programmiersprache und RStudio eine Programmierumgebung dar. Den Unterschied können wir uns am Zusammenspiels eines Motors in einer Karosserie vor Augen führen, welcher in Abbildung 2.1 illustriert ist. Man braucht die Programmiersprache R, damit überhaupt etwas voran geht. Dabei könnte man das Auto grundsätzlich auch mit einem spartanischen Stahlgerüst fahren. Abbildung 2.1: Illustration des Unterschieds zwischen R und RStudio. Die Programmierumgebung RStudio macht aus dem minimalistischen Stahlgerüst mit dem Motor R eine komfortable Luxuslimousine mit Navigationssystem und Sitzheizung. Man kann R folglich auch ohne RStudio benutzen, aber RStudio nicht ohne R. Sonderlich viel Spaß bereitet das allerdings nicht. RStudio bietet eine Vielzahl von großartigen und praktischen Features, weshalb wir im Laufe des Buches nur innerhalb von RStudio arbeiten werden. Es wird aber trotzdem häufig von R die Rede sein, da RStudio lediglich die verwendete Programmierumgebung ist. In den folgenden Kapiteln wird Schritt für Schritt erklärt, wie du R und RStudio auf den gängigsten Betriebssystemen installierst und wichtige Anpassungen innerhalb von RStudio vornimmst. Auch wenn sich RStudio bereits auf deinem Computer oder Laptop befindet, solltest du Kapitel 2.3 unbedingt lesen. 2.1.1 Programmiersprache R Zum Bearbeiten der Übungen dieses Buches benötigst du die R Version 4.1.0 oder neuer. Falls beim späteren Installieren der Packages (siehe Kapitel 2.5) ein Fehler auftritt, liegt das aller Wahrscheinlichkeit an einer zu alten R Version. Am besten installierst du R, genau wie es hier beschrieben wird, neu. Bei der Installation gibt es Unterschiede zwischen den verschiedenen Betriebssystemen Windows, macOS (Apple) und Ubuntu (Linux). In der späteren Benutzung gibt es hingegen keine Unterschiede. Du musst dir also nur den jeweiligen Abschnitt für dein Betriebssystem anschauen. Nach der Installation musst du mit R nichts weiter machen und kannst sofort zum Herunterladen von RStudio hinübergehen. Windows: Geh auf cloud.r-project.org und wähle Download R for Windows Klicke anschließend auf den Link base. Drücke dann auf Download R for Windows und achte darauf, wohin du die Installationsdatei abspeicherst. Führe die Installationsdatei (z.B. R-4.1.0-win.exe) mit einem Doppelklick aus. Folge schließlich den Installationsanweisungen. Hierbei ist das Entfernen des Häkchen bei Message translations zwingend erforderlich (siehe Abbildung 2.2). Ansonsten muss nichts an den Standardeinstellungen der Installation geändert werden. Nach erfolgreicher Installation kannst du die heruntergeladene Installationsdatei (z.B. R-4.1.0-win.exe) wieder löschen. Abbildung 2.2: Richtige Installation von R ohne Sprachsupport macOS (Apple) : Gehe auf cloud.r-project.org und wähle Download R for (Mac) OS X. Je nachdem wie alt dein Mac ist, muss eine andere Version von R heruntergeladen werden. Deine macOS Version darf zur Benutzung der in diesem Buch vorgestellten Methoden nicht älter als 10.9 Mavericks sein. macOS 10.13 High Sierra und neuer: R-4.1.0.pkg (beziehungsweise die derzeit aktuellste Version) macOS 10.11 El Capitan und neuer: R-3.6.3.pkg macOS 10.9 Mavericks und neuer: R-3.3.3.pkg Achte auf den Speicherort der Installationsdatei und führe diese aus. Falls deine Einstellungen die Installation externer Programme verhindern, musst du das Installieren von externen Paketen (mit der Endung .pkg) explizit erlauben (siehe unten). Bei der Installation kann, ohne was zu verändern, stets auf weiter gedrückt werden. Nach fertiger Installation kann die Installationsdatei (z.B. R-4.1.0.pkg) gelöscht werden. Für englische Fehlermeldungen muss schließlich noch folgender Befehl innerhalb von R ausgeführt werden. Danach muss R geschlossen und erneut geöffnet werden. Alternativ kann man auch zuerst RStudio installieren und den Befehl dort entsprechend eingeben. system(&quot;defaults write org.R-project.R force.LANG en_US.UTF-8&quot;) Zum Schluss müssen wir noch manuell XQuartz (X11) installieren, da dies in neueren macOS Versionen nicht mehr standardmäßig enthalten ist. Dies brauchen wir später, um Datensätze auch innerhalb von RStudio anschauen zu können. Gehe dafür auf xquartz.org, lade die Installationsdatei (z.B. XQuartz-2.8.2.dmg) herunter und führe diese mit Doppelklick aus. Je nach Einstellungen des Betriebssystems kann die Installation externer Software (nicht von Apple zertifiziert) wie R aus Sicherheitsgründen blockiert werden. Um das zu verhindern, musst du mit dem Finder (nicht Launchpad) nach der Installationsdatei (z.B. R-4.1.0.pkg) suchen. Halte anschließend Ctrl gedrückt und klicke auf die Datei. Aus dem erscheinenden Kontextmenü, kann schließlich Öffnen ausgewählt werden. Ubuntu (Linux): Drücke die Tastenkombination Strg + Alt + T oder tippe Terminal in die Suchleiste ein, um den Terminal zu öffnen. Bringe die Informationen deiner Repositories auf den neuesten Stand und installiere ein notwendiges Paket. sudo apt update -qq sudo apt install --no-install-recommends software-properties-common dirmngr Füge nun den Key hinzu, um für jetzt und zukünftige Updates einen sicheren Download zu gewährleisten. wget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo tee -a /etc/apt/trusted.gpg.d/cran\\_ubuntu\\_key.asc Das entsprechende Repository kann anschließend mit folgendem Befehl hinzugefügt werden. sudo add-apt-repository &quot;deb https://cloud.r-project.org/bin/linux/ubuntu $(lsb_release -cs)-cran40/&quot; Zum Installieren von R führe nun folgenden Befehl aus: sudo apt install --no-install-recommends r-base Zum Einstellen englischer Fehlermeldungen muss LANGUAGE=en an beliebiger Stelle in Renviron.site kopiert und gespeichert werden. Öffne die Datei dazu mit einem Texteditor wie gedit. Vergiss dabei nicht, die Datei im Anschluss abzuspeichern. sudo gedit /etc/R/Renviron.site 2.1.2 Programmierumgebung RStudio Nachdem R auf deinem Computer oder Laptop eingerichtet ist, kannst du die Installationsdatei für RStudio unter posit.co/download/rstudio-desktop/ herunterladen. Scrolle dafür hinunter und suche bei All Installers and Tarballs die richtige Datei aus. Wie beim Installieren von R musst du die heruntergeladene Installationsdatei mit der für dein Betriebssystem richtigen Endung (.exe, .pkg, .deb) ausführen und den anschließend eingeblendeten Anweisungen folgen. Nach Installation des Programms, kannst du die Installationsdatei auch in diesem Fall wieder löschen. Das eigentliche Programm RStudio findest du nun auf dem Computer zum Beispiel beim Drücken der Windows Taste und Eingabe des Wortes RStudio oder bei macOS über den Finder. Von jetzt an solltest du zum Arbeiten mit R immer RStudio öffnen und nicht R. Die extra vorhandene minimalistische Oberfläche von R kannst du indes ignorieren. Es ist bloß wichtig, es auf dem Computer installiert zu haben. 2.2 Aufbau von RStudio Wir schauen uns nun die einzelnen Komponenten innerhalb von RStudio an. Die Oberfläche ist dabei in vier Bereiche unterteilt: Nach frischer Installation ist die Console links unten, das R Skript als Source links oben, Environment &amp; History rechts oben und Plots, Hilfe, Packages und mehr unten rechts. Diese Reihenfolge kann beliebig nach eigener Präferenz verändert werden (siehe Kapitel 2.3). Abbildung 2.3: Aufbau von R Studio mit Skript (oben links), Konsole (unten links), Environment (oben rechts) und u.a. Plots und Help (unten rechts). Console. In der Konsole befindet sich im Prinzip die reine Programmiersprache R. Wir können also jegliche Befehle direkt in die Konsole eingeben, auf Enter Enter drücken und das Ergebnis erhalten. Im Anschluss ist der eingegebene Befehl jedoch weg. Mit der oberen und unteren Pfeiltaste kannst du die in der bisherigen Sitzung bereits ausgeführten Befehle durchgehen. Da das weder sonderlich praktisch noch reproduzierbar ist, sollte man so genannte Skripte verwenden, die in einer gesonderten Datei (mit der Endung .R) gespeichert werden und nach Öffnen immer wieder ausführbar sind. Source. Beim initialen Starten von R wird kein Skript angezeigt. Die Konsole nimmt also zuerst die gesamte linke Seite ein. Zum Erstellen eines R Skriptes kann man entweder die Tastenkombination Strg + Shift + N in Windows und Linux oder Cmd + Shift + N in macOS verwenden oder auf das unterhalb des Reiters File gelegene Blatt Papier mit dem Pluszeichen klicken und dort R Script auswählen. Gespeichert wird das R Skript wie üblich mit Strg + S oder über das Menü. Die Endung des Skriptes muss dabei .R sein, da die darin enthaltenen Befehle sonst nicht ausgeführt werden können. Man kann die Befehle innerhalb des Skriptes nun mit Strg / Cmd + Enter ausführen. Möchte man mehrere Zeilen ausführen, müssen diese erst markiert werden. Beispielsweise könnte man das gesamte R Skript ausführen, indem man erst mit Strg / Cmd + A alles markiert und anschließend mit Strg / Cmd + Enter bestätigt. Man kann mit der Tastenkombination Strg / Cmd + 1 und Strg / Cmd + 2 mit der Tastatur zwischen Konsole und Skript wechseln. Environment &amp; History. In der Environment werden alle gespeicherten Variablen angezeigt (siehe Kapitel 4.2). Man kann dort auch auf die eingelesenen Datensätze klicken und sich diese innerhalb von RStudio in einem eigenen Reiter ansehen. Vorsicht sei hier bei großen Datensätzen geboten, da diese Ansicht relativ rechenintensiv ist und RStudio dadurch abstürzen kann. Es empfiehlt sich daher, große Datensätze in ein anderes Format wie CSV oder Excel umzuwandeln, um dort einen guten Überblick über den Datensatz zu erhalten (siehe Kapitel 5). Die History zeigt alles an, was in der Konsole innerhalb einer R Sitzung ausgeführt wurde. Wenn du vollständig mit Skripten arbeitest, kannst du die History ignorieren. Tatsächlich solltest du das automatische Speichern und Laden der History, wie in Kapitel 2.3 erklärt, sogar ausschalten. Schließlich haben wir sämtliche durchgeführten Berechnungen bereits reproduzierbar durch das R Skript gegeben. Plots, Help &amp; Packages. Plots zeigt die erstellten Visualisierungen an (siehe Kapitel 8). Dabei kann man unter Zoom ein eigenes Fenster mit der Abbildung öffnen. Die Abbildung verändert sich, wenn man die Länge oder Breite des Fensters entsprechend verschiebt. Grundsätzlich kann mit Export die Visualisierung direkt in der Form gespeichert werden. Darauf sollte allerdings aufgrund der Auflösungsunterschiede verzichtet werden (siehe Kapitel 8.12). Unter Help wird die Dokumentation der verschiedenen R Funktionen angezeigt (siehe Kapitel 2.6). Der Reiter Packages ist auch nicht weiter von Bedeutung, da wir Packages im Rahmen dieses Buches über die Konsole installieren und laden. 2.3 RStudio anpassen Die ersten zwei in diesem Kapitel erklärten Anpassungen sind essentielle und unabdingbare Voraussetzungen, um das erfolgreiche Ausführen des Codes auch auf anderen Computern zu gewährleisten. Diese Einstellungen nicht vorgenommen zu haben, ist eine häufige und schwer zu findende Fehlerquelle. Die anderen Anpassungen stellen Empfehlungen dar, die dir das Programmieren erleichtern sollen. Niemals den Workspace und die History speichern. Um zu gewährleisten, dass dein Code nicht nur auf deinem Computer funktioniert, ist es dringend notwendig, das ständige Speichern und Laden des Workspaces auszustellen. Auch gewährleistest du dadurch, dass der Code immer funktioniert, wenn du diesen neu durchlaufen lässt. Gehe zu: Tools/Global Options.../General Entferne den Haken bei: Restore .RData into workspace at startup Ändere Save workspace to .RData on exit zu never Entferne den Haken bei: Always save history Keine Sorge, auf das Speichern deines Codes hat das keine Auswirkung. Im Sinne der Reproduzierbarkeit für Andere und für die eigene Fehlerbehebung ist es essentiell, beim erneuten Start von RStudio keine alten Zwischenergebnisse zu laden. Alle Berechnungen sollten durch die im Skript enthaltenen Befehle der Reihe nach auszuführen sein. Standard Zeichenencodierung. Damit man den geschriebenen Code fehlerfrei auf anderen Geräten lesen kann, muss dieselbe Zeichencodierung gewählt werden. Die modernste und am weitesten verbreitetste ist UTF-8. Gehe zu: Tools/Global Options.../Code/Saving Ändere: Default text encoding zu UTF-8 Programmierhilfen. Aller Anfang ist schwer und warum sollte man dann nicht jede zur Verfügung stehende Hilfe nutzen wollen? Hier wird eingestellt, dass Funktionen vom Rest des Codes farblich hervorgehoben werden. Außerdem wirst du darauf hingewiesen, wenn zu wenige oder zu viele Leerzeichen gesetzt wurden. Zum Schluss stellen wir die Vorschläge zur Vervollständigung von Code noch auf eine kürzere Zeit ein. Gehe zu: Tools/Global Options.../Code Wechsel zu Display und mache einen Haken bei Highlight R function calls Wechsel zu Diagnostics und mache einen Haken bei Provide R style diagnostics Wechsel zu Completion und ändere im Abschnitt Completion Delay die Zahlen auf 1 (Character) und 0 (ms) Schickes Aussehen. Es hat einen Grund, weshalb heutzutage viele Internetseiten und Smartphone Apps mit einem dunklen Farbthema angezeigt werden. Das ganze sieht nicht nur besser aus, sondern ist auch deutlich angenehmer für die Augen. Gehe zu: Tools/Global Options.../Appearance Nun kannst du aus verschiedenen Themen wählen und auch die Schriftart und Schriftgröße anpassen. Anordnung der vier Layer. Die Anordnung von Console, Skript und Co ist Geschmackssache. Sinnvoll ist beispielsweise eine Aufteilung mit dem Skript auf der linken oberen Seite und der Console auf der rechten oberen Seite. Die Fenster unten links kannst du dann für immer Minimieren und hast so mehr Platz zum Arbeiten im Skript. Gehe zu: Tools/Global Options.../Pane Layout Oben links: Source Oben rechts: Console Unten links: History, Connections Unten rechts: Environment, Files, Plots, Packages, Help, Build, VCS, Viewer Komfortables Arbeiten. Wenig ist nerviger als dauernd die R Datei im Unterordner des Unterordners zu finden, um das Programm zu öffnen. Deshalb kann man einstellen, dass sich immer das zuletzt verwendete R Skript und Projekt öffnet. Über R Projekte erfährst du mehr in Kapitel 3. Gehe zu: Tools/Global Options.../General Mache einen Haken bei Restore most recently openend project at startup Und bei Restore previously open source documents at startup 2.4 Funktionen und ihre Argumente Eine Funktion erkennst du immer daran, dass sie von zwei runden Klammern gefolgt ist. Wenn du den Anweisungen in Kapitel 2.3 gefolgt bist, wird der Name der Funktion farblich hervorgehoben. Schauen wir uns exemplarisch die Funktion zur Berechnungen der Summe mehrerer Werte an. Hier sollen die Werte 3, 4, 7 und 2 mithilfe der Funktion sum() zusammengezählt werden. Sämtliche Argumente (hier die vier Zahlen) müssen innerhalb runder Klammern der Funktion übergeben und dabei mit einem Komma voneinander getrennt werden. sum(3, 4, 7, 2) [1] 16 Auf diese Art und Weise können beliebig viele Argumente der Funktion übergeben werden. So könnte man bei einem vorliegendem fehlenden Wert (definiert als NA) diesen bei Zusammenzählen der Werte ignorieren und erhält nach wie vor ein Ergebnis. Das Argument zum Entfernen fehlender Werte heißt dabei na.rm. sum(3, 4, 7, NA, 2, na.rm = TRUE) [1] 16 Solange die Reihenfolge der Argumente, wie sie in der Funktion vorgeschrieben ist, eingehalten wird, können wir den Namen des Arguments weglassen. Davon werden wir im Verlauf des Buches immer wieder Gebrauch machen. In diesem Beispiel hingegen müssen wir na.rm explizit nennen, um den fehlenden Wert entfernen zu können. Die Entwickler der jeweiligen Funktionen definieren immer das Standardverhalten, falls keine weiteren Argumente genannt werden. Bei der Funktion sum() werden fehlende Werte bspw. standardmäßig nicht entfernt, weswegen wir dieses Verhalten mit na.rm = TRUE explizit hervorrufen müssen. Der Funktionsname wird von einer öffnenden und einer schließenden runden Klammer gefolgt (z.B. sum() für die Summe, mean() für den Mittelwert oder median() für den Median). Verschiedene Argumente können innerhalb der runden Klammern, getrennt durch ein Komma, mit einem Gleichheitszeichen verändert werden. 2.5 Packages (Erweiterungen) Direkt in R ist eine Bandbreite an Funktionen integriert. Darüber hinaus gibt es zahlreiche Erweiterungen, die das Lösen verschiedener Problemstellungen erheblich erleichtern. Diese kostenlosen Erweiterungen nennt man Packages. Stell dir vor, du kaufst dir ein neues Smartphone, auf dem von Anfang an verschiedene Apps installiert sind. Du könntest dieses Smartphone mit den vorinstallierten Apps grundsätzlich verwenden. Für eine bessere Nutzerfreundlichkeit oder andere Funktionalitäten können allerdings auch zusätzliche Apps von Drittanbietern installiert werden. Genauso sind Packages in R zu verstehen. Auch mit den von Anfang an integrierten Funktionen könnte man die meisten Sachen irgendwie hinbekommen. Nur wäre dies mit deutlich mehr Aufwand verbunden als heutzutage notwendig. Deshalb arbeiten wir im Verlaufe des Buches mit verschiedenen Packages, die erst einmal installiert und geladen werden müssen. Die Packages werden unter anderem auf CRAN, Github oder Bioconductor geteilt, von wo sie heruntergeladen und in die eigene Analyse integriert werden können. Es gibt beispielsweise mittlerweile über 11000 Packages alleine auf CRAN. 2.5.1 Installieren und laden Wir unterscheiden zwischen einer Funktion zum einmaligen Installieren und einer Funktion zum wiederholten Laden des Packages innerhalb von R. Abbildung 2.4 verdeutlicht den Unterschied der beiden Funktionen. Abbildung 2.4: Vergleich vom (a) Installieren und (b) vom Laden von Packages. Während install.packages() das Package installiert, muss man es mit library() jedes Mal beim Starten von R neu laden. Erstere Funktion kannst du dir wie das Eindrehen einer Glühbirne vorstellen. Es bleibt dunkel im Zimmer, solange du nicht den Lichtschalter betätigst. Wenn du das Zimmer verlässt (R beendest), wird das Licht automatisch wieder ausgeschaltet. Jedes Mal, wenn du das Zimmer erneut betrittst, muss das Licht also erneut eingeschaltet werden. Beim Starten von R muss jedes Mal aufs Neue der Befehl library() für jedes Package ausgeführt werden, welches du benutzen möchtest. Es gilt generell, so wenige Packages wie möglich und so viele wie nötig zu verwenden. In diesem Buch werden nur aufeinander abgestimmte Packages verwendet, aber das ist nicht immer der Fall. Auch verändern sich manche Packages im Laufe der Zeit nennenswert, sodass die eigene Analyse zwei Jahre später ggf. nicht mehr funktionieren könnte. Die Funktion install.packages(\"package\") benötigt zur Installation als Argument den Namen des Packages in Anführungszeichen. install.packages(&quot;here&quot;) Innerhalb von RStudio wird der Befehlsaufruf in der Konsole eingegeben. Wie in Abbildung 2.5 illustriert, erscheint nach Ausführen der Funktion durch Drücken der Enter Enter Taste der Installationsverlauf in roter Schrift. Dabei handelt es sich, anders als die rote Farbe suggeriert, weder um eine Warnmeldung noch um eine Fehlermeldung. Ein Fehler würde in diesen Benachrichtigungen als Error beschrieben werden und die Installation stoppen. Abbildung 2.5: Eingabe der einmaligen Installation in die Konsole. Falls bei der Installation Fehler auftreten, sollte das Argument dependencies = TRUE, getrennt mit einem Komma, zusätzlich verwendet werden. Damit werden die Packages installiert, von denen das gewünschte Package gegebenenfalls zusätzlich abhängt. install.packages(&quot;here&quot;, dependencies = TRUE) Damit man auf die Funktionen des Packages zugreifen kann, muss das Package jedes Mal – also nach jedem neuen Öffnen von RStudio – aus der Bibliothek mithilfe von library(package) erneut geladen werden. Hierbei sind keine Anführungszeichen notwendig. library(here) Zur besseren Übersichtlichkeit solltest du alle library() Befehle am Anfang des jeweiligen R Skriptes untereinander schreiben und aufrufen. Nach der Installation der Packages gibt es zwei Gründe, die Packages erneut installieren zu müssen. Der Umstieg auf eine neue Hauptversion von R (z.B. von R 4.0.0 auf R 5.0.0): Dabei wird der Ordner, der die Packages enthält, neu angelegt. Daher müssen alle Packages erneut installiert werden. Es gibt leider keinen einfachen Weg, alle installierten Packages automatisch in den neuen Ordner zu kopieren. In einem der Packages gibt es eine neue Funktion, die man verwenden möchte. Der einfachste Weg, Packages zu updaten, ist durch die erneute Installation. Es gibt zwar den Befehl update.packages(), allerdings muss dieser als Administrator in R und nicht RStudio ausgeführt werden. Selbst bei Ausführung als Administrator können dabei Probleme auftreten. Also ist man mit der erneuten Installation der Packages im Regelfall besser beraten. In aktuellen Versionen von RStudio wird automatisch eine Benachrichtigung am Anfang des Skriptes angezeigt, falls in dem Skript erwähnte Packages nicht installiert sind. Diese können dann über entsprechenden Mausklick durch RStudio installiert werden. Die gute Nachricht ist, dass man im Grunde genommen weder R noch die Packages updaten muss. Alle in diesem Buch verwendeten Packages werden sich in Zukunft voraussichtlich nicht mehr nennenswert verändern und auch in R kommen nur selten für die Datenanalyse relevante Neuerungen hinzu. 2.5.2 Notwendige Packages für dieses Buch Diese vier für dieses Buch essentiellen Packages werden wir nun zuerst installieren. Das remotes Package verwenden wir nur einmalig, um das Package begleitend zum Buch namens remp von Github herunterladen zu können. Wofür jedes einzelnen Package genau zuständig ist, wirst du im Verlaufe des Buches erfahren. Die Installation kann je nach Internet und Computer einige Minuten in Anspruch nehmen. Jeder Aufruf der Funktion install.packages() muss nur einmal ausgeführt werden. Kopiere nacheinander die einzelnen Befehle in die Console und warte jeweils, bis die Installation abgeschlossen ist. install.packages(&quot;tidyverse&quot;) install.packages(&quot;here&quot;) install.packages(&quot;rio&quot;) install.packages(&quot;remotes&quot;) Um auf die Übungsdatensätze und interaktive Übungen zugreifen zu können, musst du das Package remp installieren. Dafür wird zunächst das Package namens remotes geladen. Während der Installation des Packages kann es sein, dass du gefragt wirst, ob du bestimmte Packages aktualisieren möchtest. Du solltest dies an der Stelle ohne weiteres Zutun mit durch Klicken der Enter Enter Taste verneinen. library(remotes) install_github(&quot;j3ypi/remp&quot;) Alle anderen teilweise speziell auf einen Kontext zugeschnittenen Packages, die im Rahmen des Buches vorgestellt werden, kannst du bei Bedarf installieren. Am Anfang jedes Kapitels mit einem neuen Package wird immer explizit darauf hingewiesen. Im remp Package sind Datensätze, Funktionen und Übungen für dieses Buch enthalten. Da dieses Package nicht auf CRAN sondern auf Github gespeichert ist, muss hier zur Installation die Funktion install_github() aus dem remotes Package anstelle der üblichen Funktion install.packages() verwendet werden. Das remotes Package muss hierbei vorher installiert werden. Wir werden im Rahmen dieses Buches vor allem diese vier Packages verwenden, weswegen zu Beginn jedes Skriptes die vier Packages geladen werden müssen. library(tidyverse) library(here) library(rio) library(remp) In diesem Fall ist die Reihenfolge des Ladens nicht entscheidend. Falls verschiedene Packages jedoch gleichnamige Funktionen beinhalten, führt dies zu Problemen, auf die im folgenden Kapitel näher eingegangen wird. 2.5.3 Namespace Beim Laden mehrerer Packages kann es sein, dass diese Funktionen mit demselben Namen verwenden (siehe Kapitel 6.1). Während beim tidyverse lediglich zwei selten verwendete base R Funktionen überschrieben werden, kann es beim Arbeiten mit vielen verschiedenen nicht aufeinander abgestimmten Packages durchaus häufiger zur Namensgleichheit kommen. Das ist eine schwierig zu identifizierende Fehlerquelle, weil sich die Funktion mitunter plötzlich nicht mehr so verhält wie erwartet. Dabei verwendet man automatisch die Funktion, die aus dem zuletzt geladenen Package stammt. Lädt man beispielsweise zuerst das Package tidyverse und anschließend data.table, erhält man folgende Meldung: library(tidyverse) library(data.table) Attaching package: ‘data.table’ The following objects are masked from ‘package:dplyr’: between, first, last The following object is masked from ‘package:purrr’: transpose Drei Funktionen (between(), first(), last()) aus dem Package dplyr und eine Funktionen (transpose()) aus dem Package purrr werden von data.table überschrieben. Es ist also wichtig, diese Meldungen beim Laden eines Packages nicht zu ignorieren. Im Notfall kann dies durch die Verwendung von Doppelpunkten package::funktion() verhindert werden. So teilt man R explizit mit, welche Funktion aus welchem Package man meint. Um trotz des späteren Ladens von data.table auf die between() Funktion von dplyr zuzugreifen, würde man also beim Aufrufen der Funktion folgendes schreiben: dplyr::between(1:12, 7, 9) Eine Ausnahme stellt dabei das tidyverse dar. Weil das tidyverse nur andere Packages lädt, kann man nicht tidyverse::funktion() schreiben. Stattdessen muss man das Package, aus dem die Funktion stammt (z.B. dplyr), direkt ansprechen. Für genauere Informationen zum Thema Namespace und die Hintergründe der damit verbundenen Environments sei auf das Buch Advanced R verwiesen. 2.6 Fehler- und Warnmeldungen 2.6.1 Der Unterschied Es gibt einen großen Unterschied zwischen Fehler- und Warnmeldungen. Wie der Name bereits suggeriert, stoppen Fehlermeldungen den Code, während Warnmeldungen ein Ergebnis zurückgeben und nur auf mögliche Probleme hinweisen. Es ist also sehr wichtig, die roten Meldungen in der Konsole genau zu lesen, anstatt direkt in Panik zu geraten. Ein Beispiel für eine Fehlermeldung sehen wir, wenn wir die Zahl 1 mit dem Buchstaben c summieren möchten. 1 + &quot;c&quot; Error in 1 + &quot;c&quot;: non-numeric argument to binary operator Hier ist die Fehlermeldung eindeutig. Wir versuchen einen nicht-numerisches Buchstaben (das c) mit einem numerischen zu addieren. Leider sind Fehlermeldungen in R keineswegs immer so eindeutig zu interpretieren. Nicht selten sind sie kryptisch und vor allem am Anfang wird man oft im Internet nach einer Lösung suchen müssen. Warnmeldungen in R haben zwar dieselbe erschreckende rote Schrift wie Fehlermeldungen, allerdings starten sie mit Warning Message und stoppen den Code nicht. Warnmeldungen sind für dich als Benutzer gedacht, um auf mögliche Probleme bei deiner Eingabe hinzuweisen. Gerade bei der statistischen Auswertung können Warnungen dir schon einmal häufiger über den Weg laufen und sollten keinesfalls blind ignoriert werden. Die Sprache der Fehler- und Warnmeldungen muss dabei Englisch sein, da sonst nicht vernünftig im Internet danach gesucht werden kann. Bitte beachte die dafür notwendigen Anpassungen bei der Installation, die in Kapitel 2.1.1 erklärt wurden. 2.6.2 Wo bekomme ich Hilfe? Während der ersten Kontakte mit einer Programmiersprache dauert das Warmwerden möglicherweise eine gewisse Zeit. Damit man nicht gleich die Motivation verliert und aufgibt, sind die richtigen Quellen für eine schnelle Hilfe essentiell. Glücklicherweise ist dies einer der großen Vorteile von R. Es existieren nicht nur ausführliche Dokumentationen der verschiedenen Funktionen mit Anwendungsbeispielen. Darüber hinaus ist die R Community auch besonders hilfsbereit. Falls du verzweifelt vor deinem Computer oder Laptop sitzt und nicht weißt, wieso dein Code schon wieder nicht funktioniert, solltest du besonders an vier Orten nach Antworten suchen. Package Dokumentation. Das naheliegendste ist die Dokumentation der R Funktionen, die auch ohne Internet direkt in R aufgerufen werden können. Dafür kannst du entweder ein Fragezeichen vor die Funktion schreiben und diese ausführen oder mit dem Cursor auf der Funktion F1 drücken. Wenn wir zum Beispiel mehr über die Argumente der Funktion install.packages() erhalten möchten, können wir dies so erreichen: ?install.packages Die meisten modernen Packages stellen außerdem so genannte Vignetten zur Verfügung, in denen häufige Probleme ausführlich diskutiert und erklärt werden. Diese können mit vignette(\"nameDerVignette\") auch direkt innerhalb von R aufgerufen werden. Suchmaschine. In die Suchmaschine gibst du einfach r gefolgt von der Fehlermeldung oder dem Problem ein, an dem du aktuell festhängst. Es gibt kaum eine Fehlermeldung, bei der das Programmierforum StackOverflow nicht an erster Stelle angezeigt wird. Denn meistens hat jemand anderes schon einmal genau dasselbe Problem gehabt hat. Stackoverflow. Dies ist wohl das mit Abstand größte Forum für Programmierfragen. Allerdings kann es einschüchternd sein, dort als absoluter Anfänger selbst eine Frage zu stellen. Voraussetzung zum Fragestellen ist dort das Erstellen eines kurzes reproduzierbares Beispiel für den Fehler. Du erreichst die Seite unter https://stackoverflow.com/. RStudio Community. Eine etwas kleinere Alternative zu StackOverflow ist die RStudio Community. Statte ihr bei Bedarf unter https://community.rstudio.com/ einen Besuch ab. 2.6.3 Fehler beheben Während deiner ganzen Zeit beim Programmieren wirst du immer wieder Code schreiben, der unweigerlich zu einem Fehler führt. Ob nun ein Package nicht geladen oder eine Klammer zu wenig gesetzt ist. Irgendetwas läuft häufig schief – so mag es zu Beginn erscheinen. Richtig um Hilfe fragen, ist dabei gar nicht so einfach. Es ist zum Beispiel wenig informativ, wenn du jemandem schreibst: “RStudio funktioniert nicht”. Was funktioniert nicht? Wann tritt der Fehler auf? Hat es vorher funktioniert? Alle diese Informationen müssen dann erst einmal mühselig erfragt werden. Nun können die bereitzustellenden Informationen grundsätzlich in drei Abschnitte gegliedert werden. Eine kurze Problembeschreibung. Stelle ein minimales, reproduzierbares Beispiel bereit. Erkläre, was du bereits probiert hast. Während Punkt 1 und 3 soweit verständlich sind, bedarf es eine Erklärung für das reproduzierbare Beispiel. Ein reproduzierbares Beispiel enthält alle Informationen, die jemand anderes zum exakten Replizieren des Fehlers benötigt. Es müssen also zum Beispiel alle geladenen Packages angegeben werden. Außerdem ist es essentiell, den Datensatz in einer vereinfachten Kurzform zur Verfügung zu stellen. Wenn du beim Analysieren deines eigenen Datensatzes auf ein Problem stößt, kann natürlich niemand anderes auf diesen Datensatz zugreifen. Entweder erstellt man dann einen kleinen Datensatz innerhalb von R, mit dem das Problem repliziert wird oder man lässt die Datenstruktur des eigenen Datensatzes ausgeben. Angenommen, wir haben eine Fehlermeldung bei der Auswertung eines Datensatzes namens demogr. demogr # A tibble: 4 × 3 ID Sex Alter &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 AX161095 m 28 2 NM020683 f 47 3 IO240576 f 40 4 JH051199 m 24 Dieser Datensatz ist relativ kompakt und kann mit der Funktion dput() in ein Format gebracht werden, welches ohne Zugriff auf die Originaldatei von Anderen in R aufgerufen werden kann. dput(demogr) structure(list(ID = c(&quot;AX161095&quot;, &quot;NM020683&quot;, &quot;IO240576&quot;, &quot;JH051199&quot; ), Sex = c(&quot;m&quot;, &quot;f&quot;, &quot;f&quot;, &quot;m&quot;), Alter = c(28, 47, 40, 24)), class = c(&quot;tbl_df&quot;, &quot;tbl&quot;, &quot;data.frame&quot;), row.names = c(NA, -4L)) Bei größeren Datensätzen sollte man nur einen Teil der Daten auswählen (siehe Kapitel 6.2 und 6.3). Bei sensiblen Daten bietet es sich an, einen kleinen Datensatz innerhalb von R neu zu erstellen, der anstelle der Originaldaten strukturell ähnliche Werte in den Spalten beinhaltet (siehe Kapitel 5.3). Häufig kommt man von ganz alleine auf die Lösung, während man Schritt für Schritt die durchgeführten Zeilen Code auseinander nimmt, um das Problem innerhalb eines minimalen Beispiels zu reproduzieren. Bevor du allerdings die Frage an jemand anderes richtest, solltest du diese häufigen Fehlerquellen bereits ausgeschlossen haben: Tippfehler. Ein Package ist nicht installiert oder geladen. Ein oder mehrere Packages sind zu alt. Eine Klammer ist zu viel oder zu wenig. Anführungszeichen bei wurden vergessen oder an falsche Stelle gesetzt. Ein Komma anstelle eines Punktes wurden füri Dezimalzahlen verwendet. Numerische Spalten im Datensatz wurden als Character eingelesen (häufig bei Excel Dokumenten). Character Spalten sind fälschlicher Weise als Faktoren dargestellt. Das R Skript wurde nicht innerhalb eines R Projekts geöffnet, sodass der Datensatz nicht gefunden wird. "],["project.html", "Kapitel 3 R Projekte 3.1 Die Probleme der Pfade 3.2 Projekte in RStudio erstellen 3.3 Der Pfad zum Datensatz", " Kapitel 3 R Projekte Woher weiß der Computer, an welchem Ort sich mein Datensatz befindet? Die Antwort auf diese Frage war lange umständlich und je nach Betriebssystem unterschiedlich. Das Konzept der Projekte innerhalb von R stellt die Basis zum einfachen Einlesen deines Datensatzes dar. 3.1 Die Probleme der Pfade Erinnere dich an das letzte Mal zurück, als du eine Datei irgendwo hochgeladen hast. Normalerweise öffnet sich dann ein kleines Dialogfenster, durch das du bis zu deiner Datei navigieren kannst. Das hat den Hintergrund, dass dein Betriebssystem den genauen Ort der Datei – den so genannten Pfad – wissen muss, um diese finden und hochladen zu können. Das gleiche kannst du beobachten, wenn du gefragt wirst, wo genau du auf deinem Computer eine heruntergeladene Datei speichern möchtest. In R war das Einlesen von Datensätzen genau deswegen lange ein Problem. Dabei gibt es vor allem vier zentrale Probleme hervorzuheben: Wenn jemand auf einem anderen Computer die Analysen innerhalb deines R Skripts nachvollziehen möchte, ist der Pfad auf seinem oder ihrem Computer anders. Der Dateipfad ist oft lang, weil die Zieldatei in vielen verschachtelten Unterordnern liegt. Häufig verschiebt man den Ordner mit der Zeit an einen anderen Ort. Zwischen den Betriebssystemen ist die Art, den Pfad darzustellen, unterschiedlich. Zum Ersten Punkt kommt hinzu, dass die wenigsten überhaupt wissen, was genau ein Pfad ist und wie man diesen korrekt angeben müsste. Punkt zwei und drei ist vor allem hinsichtlich Reproduzierbarkeit ein Problem. Auch wenn du deine Analysen an KollegInnen oder BetreuerInnen schicken möchtest, wird der Code ohne Anpassungen nicht funktionieren. Glücklicherweise gibt es mittlerweile R Projekte, so dass du dich niemals mit Pfaden und daraus resultierenden fehlenden Reproduzierbarkeit auseinander setzten musst. Durch Projekte kann eine Funktion zum Einlesen des Datensatzes unabhängig vom Ort des Ordners sehen, wo sich die Datei befindet. Die einzigen beiden Voraussetzungen sind, dass der Datensatz im selben Ordner oder Unterordner wie die R Projektdatei liegt und dass man das here Package lädt. 3.2 Projekte in RStudio erstellen Nehmen wir einmal an, auf unserem Desktop liegt ein Ordner namens Beispiel. Wie in Abbildung 3.1 ersichtlich, befinden sich in diesem Ordner drei Dateien und ein Unterordner namens Daten. Abbildung 3.1: Beispielhafte Ordnerstruktur mit R Skript, Projektdatei und Datensatz. Auswertung.R ist unser R Skript, Beispiel.Rproj unsere Projektdatei und video.xlsx der Datensatz, den wir zur Auswertung einlesen wollen. Die Projektdatei muss manuell vor dem Einlesen erstellt werden. Dafür benötigt man nur ein paar Klicks. Oben rechts befindet sich ein Reiter namens Project: (None), wenn kein Projekt geöffnet ist und ansonsten der Projektname (zum Beispiel das Projekt Beispiel). Öffne zuerst das Dropdown Menu. Abbildung 3.2: Erster Schritt beim Erstellen eines neuen Projektes. Uns interessieren zum einen New Project... und Open Project... und zum anderen sind weiter unten andere Projekte aufgelistet, die vorher geöffnet wurden (hier 07_Buch und remp). Dadurch kann man mit einem einfachen Klick zwischen den eigenen Projekten wechseln. Dieses Feature erleichtert die Arbeit ungemein, da man auf dem Computer nicht mehr diverse Ordner nach den richtigen Dateien durchsuchen muss. Zum Erstellen eines neuen Projekts klicke auf New Project..., wodurch ein neues Fenster erscheint. Abbildung 3.3: Zweiter Schritt beim Erstellen eines neuen Projektes. Wir entscheiden uns exemplarisch für die Option Existing Directory. Das bedeutet, unser Ordner Namens Beispiel existiert bereits auf dem Desktop. Ob dieser Ordner leer oder bereits mit anderen Dateien gefüllt ist, ist nicht weiter von Bedeutung. Abbildung 3.4: Letzter Schritt zur Erstellung eines neuen Projektes. Mit einem Klick auf Create Project wird nun eine Projektdatei mit der Endung .Rproj in den gewählten Ordner gespeichert. Projekte bieten übrigens bezüglich Reproduzierbarkeit einen weiteren Bonus. Bei jedem Start von RStudio wird eine neue und in sich abgeschlossene R Umgebung geladen. So kann garantiert werden, dass der Code genau so auch auf anderen Computern ausgeführt werden kann. Beachte, beim Öffnen eines R Projects in dem Ordner nicht auf das R Skript (hier Auswertung.R) sondern auf die Projektdatei zu klicken und erst im Anschluss das R Skript zu öffnen. Für alle zukünftigen Öffnungen kannst du in Zukunft einfach RStudio öffnen und in dem eingangs beschrieben Dropdown Menü rechts oben das Projekt auswählen. Damit R die Position der Projektdatei auch findet, brauchen wir nun außerdem das here Package. Beim Arbeiten in einer Cloud wie Dropbox kann es zu einer Fehlermeldung kommen, die besagt, dass RStudio nicht auf die Datei zugreifen kann. Um das zu umgehen, muss die Synchronisierung der Cloud für die Dauer des Arbeitens mit R angehalten werden. 3.3 Der Pfad zum Datensatz Die Magie im Kontext von Projekten passiert, wenn du das here Package lädst. Das Package findet selbstständig den relativen Pfad zu deiner Projektdatei heraus. Was bedeutet das? Während man früher beispielsweise auf Windows mit C:\\Users\\J-PhN\\Desktop\\Beispiel den absoluten Pfad zum Ordner eingeben musste, findet das here Package den Ordner Beispiel mit der Projektdatei unabhängig von der Lage des Ordners. In der Praxis sieht das beim Laden wie folgt aus: &gt; library(here) here() starts at C:/Users/J-PhN/Desktop/Beispiel Würden wir den Ordner verschieben, hätte das keine Auswirkungen auf unseren Code, denn das Package würde wieder zum Projektordner finden. Der erste Schritt ist also immer das Erstellen eines R Projekts und das Laden des here Packages am Anfang jedes neuen Skripts, mit dem man einen Datensatz einlesen möchte. Alternativ kann der Pfad zum Datensatz auch mit setwd() manuell festgelegt werden. Da der Pfad allerdings zwischen den Betriebssystemen unterschiedlich ist und man nach jedem Verschieben der Dateien erneut setwd() anpassen muss, wird ausdrücklich davon abgeraten. "],["vars.html", "Kapitel 4 Wichtiges Grundlagenwissen 4.1 Schritt für Schritt beginnen 4.2 Variablen speichern und verwenden 4.3 Datentypen 4.4 Struktur von Datensätzen 4.5 Der Dollar-Operator", " Kapitel 4 Wichtiges Grundlagenwissen Bevor wir richtig loslegen können, müssen wir einige Grundlagen besprechen. Das Abspeichern von Zwischenergebnissen in Form von Variablen ist genauso essentiell wie die verschiedenen Datentypen, die in den jeweiligen Spalten deines Datensatzes enthalten sind. Auch einzelne Spalten mithilfe des Dollar-Operators aus einem Datensatz herauszuziehen ist ein zentrales Konzept, auf das wir im Verlauf dieses Buches häufig zurückgreifen werden. 4.1 Schritt für Schritt beginnen 1. Schritt: RStudio starten. Nach der Installation von R und RStudio (siehe Kapitel 2.1.1 und 2.1.2) kann RStudio in Windows durch Tippen der Windows-Taste mit anschließender Eingabe von RStudio und in macOS über den Finder gestartet werden. In der Konsole wird dabei automatisch die installierte R Version angezeigt. Abbildung 4.1: Starten von RStudio. 2. Schritt: R Projekt erstellen. Als nächster Schritt sollte ein in sich abgeschlossenes Projekt erstellt werden (siehe Kapitel 3). Das erfolgreiche Erstellen und Öffnen des Projektes erkennt man daran, dass oben rechts in RStudio anstelle von Project: (None) der Name des Projektes steht (z.B. Beispiel). Manchmal wird, wie in Abbildung 4.2 gezeigt, der Überordner der Projektdatei mit angezeigt (hier der Ordner R Skripte). Wir sehen auch, dass unten rechts im Reiter Files jetzt die im Projektordner befindlichen Dateien angezeigt werden. Abbildung 4.2: Innerhalb von RStudio ein neues R Projekt erstellen. 3. Schritt: R Skript erstellen. Da die Funktionsaufrufe in der Konsole nur einmalig ausgeführt und nicht gespeichert werden, muss anschließend das R Skript entweder durch Klicken des Pluszeichens links oben oder durch die Tastenkombination Strg / Cmd + Shift + N erstellt werden (siehe Kapitel 2.1.2). Abbildung 4.3: Ein neues R Skript für die Analysen erstellen. 4. Schritt: Benötigte Packages laden. Bei jedem Start von RStudio müssen zunächst alle verwendeten Packages neu geladen werden. Dafür markieren wir die verschiedenen library() Aufrufe (hier vier Stück) und führen diese mit der Tastenkombination Strg/Cmd + Enter aus. Anders als in der Konsole werden die Funktion in einem R Skript also nicht alleine mit Enter sondern mit der Kombination Strg / Cmd + Enter ausgeführt. Um einzelne Zeilen auszuführen, genügt es, den Cursor auf der Zeile zu haben und dabei Strg / Cmd + Enter auszuführen. Manche Packages geben beim Laden Benachrichtigungen zurück. Was die Benachrichtigungen des tidyverse in Abbildung 4.4 bedeuten, wird in Kapitel 6 erläutert. Abbildung 4.4: Packages nach jedem Start neu markieren und ausführen. 5. Schritt: Datensatz einlesen und Analysen durchführen. Nach Laden der Packages kann der Datensatz eingelesen werden (siehe Kapitel 5.1). Durch das Einlesen und Speichern mit Zuweisungspfeil erscheint der Datensatz rechts oben in der Environment (siehe Kapitel 4.2). Man kann also im weiteren Verlauf auf den big_five Datensatz namens daten zugreifen. Auch dieser muss bei Neustart von RStudio erneut durch Auswahl der Zeile (hier Zeile 7) und Betätigen der Tastenkombination Strg / Cmd + Enter eingelesen werden. Anschließend sollte man im Rahmen der weiteren Auswertung der Daten immer Kommentare einbauen, die mit einer führenden Raute markiert werden (siehe Zeile 9 in Abbildung 4.5). Exemplarisch schauen wir uns hier die Spalten Extraversion und Neurotizismus als ersten Schritt unserer Datenanalyse an (siehe Kapitel 6.2). Abbildung 4.5: Datensatz einlesen und Analysen durchführen. 4.2 Variablen speichern und verwenden Ein zentrales Konzept in R ist das Speichern von Variablen mithilfe des Zuweisungspfeils. Dies ist vor allem für all jene ungewöhnlich, die das Erstellen von Variablen aus anderen Programmiersprachen mit dem Gleichheitszeichen kennengelernt haben. Wenn man das Ergebnis der durchgeführten Operation nicht speichert, ist es sofort weg und muss erneut ausgeführt werden. Würde man nun 2 + 2 [1] 4 rechnen, gibt R zwar 4 zurück, allerdings kann man später nicht mehr auf diese 4 zurückgreifen. Wenn man beispielsweise einen Datensatz einliest, ohne diesen mit dem Zuweisungspfeil zu speichern, kann man auf diesen im weiteren Verlauf nicht zugreifen. Mithilfe des Zuweisungspfeils wird die Variable in die lokale Environment gespeichert. Wir erinnern uns, die Environment ist in der Standardeinstellung nach Installation von RStudio im Fenster oben rechts. Möchten wir beispielsweise die Rechenoperation von vorhin namens rechnung speichern, würde man wie folgt vorgehen: rechnung &lt;- 2 + 2 Im Nachfolgenden könnte man nun diese Variable jederzeit wieder aufrufen. rechnung [1] 4 Auch ist es nun möglich, weitere Rechenoperationen mit dem vorherigen Ergebnis auszuführen. Zum Beispiel könnte man unser Ergebnis namens rechnung mit der Zahl 4 multiplizieren. rechnung * 4 [1] 16 Variablen kann man grundsätzlich fast so benennen, wie man möchte. Man darf nur nicht mit einer Zahl anfangen oder nach einem Punkt direkt eine Zahl als Namen wählen wie bspw. bei .2VariablenName. Auf Umlaute sollte im Zusammenhang mit Programmiersprachen aufgrund verschiedener Zeichenkodierungen ebenfalls immer verzichtet werden. In den Variablen können sämtliche Datenstrukturen (siehe Kapitel 11) verstaut werden. Für den Moment reicht es für uns zu wissen, dass wir Datensätze und Zwischenergebnisse in den Variablen abspeichern müssen, um weiter darauf zugreifen zu können. Variablen können einfach überschrieben werden, indem man der Variable einen anderen Wert zuweist. Gerade in der Datenvorbereitung kann es schon einmal verlockend sein, die Änderungen unter demselben Variablennamen zu speichern. Wenn man allerdings eine unbeabsichtigte Änderung abspeichert, kann dies nicht rückgängig gemacht werden. Der Datensatz muss als Resultat erneut eingelesen werden. Es sei also vor allem am Anfang Vorsicht geboten. Auf der anderen Seite sollte man auch nicht jeden einzelnen Schritt in der Datenvorbereitung mit einem bedeutungslosen Namen versehen. Schließlich hätten die Zwischenergebnisse rechnung1, rechnung2, rechnung3 und rechnung4 keine Information im Namen, welches Ergebnis nun welche Änderung enthält. Aussagekräftige Namen helfen anderen, deinen Code zu verstehen. Wenn du dir nun denkst, ohnehin nicht mit anderen zusammenarbeiten zu werden, lass dir gesagt sein: der oder die Andere bist in den meisten Fällen du selbst einige Wochen oder Monate später. Ohne Dokumentation und vernünftige Namensgebung sieht dein R Skript Monate später schnell so aus, als hätte es irgendein Fremder geschrieben. Dein zukünftiges Ich wird dir dankbar sein. Behalte immer im Hinterkopf, dass der Zuweisungspfeil zwar die Variable speichert, aber keinen direkten Output in der Konsole ausgibt. Oft erweckt das den Eindruck, als wäre nichts passiert. Es hilft dann, den Namen der Variable, wie zuvor gezeigt, explizit aufzurufen. Wenn man etwas im Code kommentieren möchte, muss eine führende Raute hinzugefügt werden. Das eignet sich nicht nur für kurze Beschreibungen, sondern auch als Gliederung eines langen R Skriptes. Beispielsweise könnte man so den Abschnitt der Berechnung vom Erstellen von Visualisierungen optisch trennen. Die Anzahl der Rauten spielt dabei keine Rolle. # Berechnung I # Dieser Code summiert 2 und 4 2 + 4 [1] 6 4.3 Datentypen Grundsätzlich gibt es in R vier verschiedene Grunddatentypen: Integer, Double, Character und Logical (siehe Abbildung 4.6). Dabei lassen sich Integer und Double zum Datentyp Numeric zusammenfassen, da die Unterscheidung dieser beiden in R selten von Bedeutung ist. Schauen wir uns die Datentypen nun etwas genauer an. Numeric (kurz: &lt;num&gt;) beschreibt numerische Werte, also Zahlen. Integer (kurz: &lt;int&gt;) sind ganze Zahlen und Doubles (kurz: &lt;dbl&gt;) Dezimalzahlen. Beachte dabei, dass Dezimalzahlen in R mit Punkten und nicht mit Kommata dargestellt werden. Abbildung 4.6: Schematische Übersicht über die wichtigsten Datentypen in R. 4.3.1 Zahlen, Buchstaben und logische Abfragen Beispiele für Numerics wären zum Beispiel Alter, Gehalt oder der Blutdruck. Wenn wir später Datentypen aus einem echten Datensatz ansehen, wirst du schnell merken, dass beinahe alle Zahlen als Double deklariert werden. Das liegt an der Eigenheit von R, ein L hinter die Zahl setzen zu müssen, wenn es sich um eine ganze Zahl hat. Dies hat allerdings keinerlei Auswirkung auf die in diesem Buch vorgestellten Funktionen. Double: 3.14 42 Integer: 42L Character (&lt;chr&gt;) ist der Datentyp, der Text enthalten kann – also einzelne Buchstaben, Zeichen, Wörter oder ganze Sätze. Dabei muss der Text immer in Anführungszeichen stehen. Solange die Anführungszeichen verwendet werden, kann mit Ausnahme vom Backslash (\\) alles geschrieben werden. Beispiele für Characters wären zum Beispiel die Blutgruppe, das Herkunftsland oder Allergien. &quot;Hallo Welt&quot; Logical oder auch logische Datentypen sind etwas abstrakter und kommen in Datensätzen seltener vor. Sie werden dann benötigt, wenn wir aufgrund von bestimmten Bedingungen manche Operationen durchführen möchten und andere wiederum nicht. Beispiele dafür wären die Auswahl derjenigen Personen, die über 50 Jahre alt sind oder eine neue Spalte namens Geschlecht zu erstellen, die nur bei weiblichen Personen eine 1 und ansonsten eine 0 einträgt. Dabei wird nämlich geprüft, ob die Aussage (zum Beispiel Person A ist älter als 50) wahr oder falsch ist. Das heißt, es gibt dabei zwei Zustände: TRUE oder FALSE (immer in Großbuchstaben). Eine Bedingung kann entweder zutreffen oder eben nicht. Es gibt verschiedene Funktionen, die TRUE oder FALSE zurückgeben, auf die wir im Verlaufe des Buches noch stoßen werden. Grundsätzlich gibt es dabei nur wenige verschiedene Grundoperatoren, die man kennen sollte. Um zu schauen, ob zwei Werte gleich sind, benutzen wir ein doppeltes Gleichheitszeichen (==). 2 == 2 [1] TRUE Gleiches Prinzip gilt für größer gleich (&gt;=) und kleiner gleich (&lt;=). Für größer (&gt;) oder kleiner (&lt;) reicht hingegen das einzelne mathematische Zeichen. Möchten wir nun logische Operationen kombinieren, verwenden wir UND (&amp;) oder ODER (|). Bei UND müssen beide Aussagen wahr sein, 1 &lt; 2 &amp; 1 == 2 [1] FALSE bei ODER hingegen nur mindestens eine. Man würde es wie folgt lesen: Entweder ist 1 kleiner 2 ODER 1 ist gleich 2. Da die erste Aussage wahr ist, wird TRUE zurückgegeben. 1 &lt; 2 | 1 == 2 [1] TRUE So können beliebig viele logischen Operationen miteinander kombiniert werden. Ein besonderer Fall logischer Datentypen ist NA (Akronym für Not Available), also die Bezeichnung für einen fehlenden Wert. Wir können einen Wert oder eine Variable auf seinen Datentyp überprüfen. Zurückgegeben wird uns nur TRUE oder FALSE. Die für uns interessanten Funktionen hierfür heißen is.numeric(), is.character(), is.logical(), is.factor(), is.Date(), is.POSIXct() und is.na(). Natürlich gibt es auch is.double() und is.integer(), allerdings genügt uns für die Anwendungen in diesem Buch is.numeric(). Möchte man generell herausfinden, mit welchem Datentyp man es zu tun hat, verwendet man typeof(). typeof(&quot;Kontrollgruppe&quot;) [1] &quot;character&quot; Da es unpraktisch ist, bei diversen Spalten eines Datensatzes einzeln den Typ abzufragen, wird dieser in tibbles (siehe Kapitel 11.3) – dem Datensatzformat, welches wir innerhalb von R konsistent im gesamten Buch verwenden – direkt unter dem Spaltennamen angezeigt. big5 # A tibble: 200 × 7 Alter Geschlecht Extraversion Neurotizismus O1 O2 O3 &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 36 m 3 1.9 5 1 5 2 30 f 3.1 3.4 5 3 5 3 23 m 3.4 2.4 3 3 5 4 54 m 3.3 4.2 2 5 3 # … with 196 more rows Da dort nur die Spalten angezeigt werden, die auf den Bildschirm passen, bietet glimpse() eine übersichtlichere Möglichkeit, einen schnellen Überblick über sämtliche Datentypen zu erhalten. glimpse(big5) Rows: 200 Columns: 7 $ Alter &lt;dbl&gt; 36, 30, 23, 54, 24, 14, 32, 20, 29, 17, 30, 15, 14, 23, 27, 15, 1964, 2… $ Geschlecht &lt;chr&gt; &quot;m&quot;, &quot;f&quot;, &quot;m&quot;, &quot;m&quot;, &quot;f&quot;, &quot;f&quot;, &quot;m&quot;, &quot;m&quot;, &quot;f&quot;, &quot;m&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;m&quot;, &quot;… $ Extraversion &lt;dbl&gt; 3.0, 3.1, 3.4, 3.3, 3.0, 2.8, 3.5, 3.5, 3.0, 3.1, 3.2, 3.5, 3.0, 3.2, 2… $ Neurotizismus &lt;dbl&gt; 1.9, 3.4, 2.4, 4.2, 2.8, 3.5, 3.1, 2.6, 3.7, 3.6, 3.6, 2.8, 3.8, 2.0, 3… $ O1 &lt;dbl&gt; 5, 5, 3, 2, 5, 5, 3, 2, 4, 4, 5, 4, 2, 5, 4, 2, 5, 3, 5, 5, 3, 4, 2, 3,… $ O2 &lt;dbl&gt; 1, 3, 3, 5, 1, 1, 1, 1, 1, 3, 2, 3, 3, 1, 2, 3, 1, 2, 4, 1, 1, 1, 4, 3,… $ O3 &lt;dbl&gt; 5, 5, 5, 3, 5, 5, 5, 3, 5, 4, 5, 4, 3, 5, 4, 5, 5, 5, 4, 4, 1, 5, 3, 2,… Möchten wir nun mehrere Werte eines Datentypens aneinanderreihen, um sie zum Beispiel in eine Spalte eines Datensatzes zu schreiben, können wir c() (Abkürzung für Combine, engl. für kombinieren) verwenden. Möchtest du beispielsweise die Werte 1, 4, 5, und 10 kombinieren, erstellt dir c() einen entsprechenden Vektor (siehe Kapitel 11.1). Die Feinheiten und Merkmale von Vektoren brauchen dich an dieser Stelle nicht zu interessieren. Allerdings brauchen wir die Funktion c() des Öfteren, um Werte aneinander zu reihen. vec &lt;- c(1, 4, 5, 10) Wenn du verschiedene Datentypen innerhalb von c() miteinander kombinierst, werden die Datentypen ineinander umgewandelt. Dabei gilt Character &gt; Integer &gt; Logical. Wenn Zahlen mit Buchstaben kombiniert werden, wird also alles zu Buchstaben, auch wenn eigentlich Zahlen gemeint sind. Es gibt diverse Datentypen, die auf diesen vier Grundtypen aufbauen. Zwei wichtige, Faktoren und Zeitdaten, werden wir uns im Folgenden noch anschauen. Es kann passieren, dass Zahlen von R als Buchstaben interpretiert werden. Das kommt vor allem beim Einlesen von schlecht formatierten Datensätzen vor. Wenn eine Berechnung nicht so funktioniert, wie sie sollte, lohnt es sich, die Datentypen der jeweiligen Spalten zu überprüfen. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 4.3.2 Faktoren Wenn wir wissen, wie viele Ausprägungen Characters (Zeichenketten) annehmen können, verwenden wir Faktoren. Ein illustratives Beispiel hierfür wäre die Aufteilung in Experimental- und Kontrollgruppen. Bereits bei der Versuchsplanung weißt du, wie viele Gruppen du haben möchtest (beispielsweise eine Experimental- und zwei Kontrollgruppen), damit du eine entsprechende Stichprobenplanung durchführen kannst. Schauen wir uns das ganze mal etwas konkreter an. Angenommen, die Information über die Bedingung (Experimental, Kontrolle) befindet sich in der Variable namens Bedingung als Characters. bedingung &lt;- c(&quot;exp&quot;, &quot;kont1&quot;, &quot;exp&quot;, &quot;exp&quot;, &quot;kont2&quot;, &quot;kont1&quot;) Mit der Funktion factor() können nun Faktoren daraus gemacht werden. Zusätzlich sollte man das optionale levels Argument verwenden, um die Reihenfolge der Faktorstufen festzulegen. factor(bedingung, levels = c(&quot;exp&quot;, &quot;kont1&quot;, &quot;kont2&quot;)) [1] exp kont1 exp exp kont2 kont1 Levels: exp kont1 kont2 Das levels Argument ist außerdem wichtig, wenn wir nicht alle Faktorstufen beobachtet haben. Wenn beispielsweise eine der Gruppen in der Erhebung nicht vorkam, möchten wir eine Häufigkeit von 0 angezeigt bekommen. Würden wir die Faktorstufen nicht explizit definieren, würde die fehlende Gruppe in den im weiteren Verlauf des Buches verwendeten Funktionen schlichtweg nicht angezeigt werden. bedingung &lt;- c(&quot;exp&quot;, &quot;kont1&quot;, &quot;exp&quot;, &quot;exp&quot;, &quot;kont1&quot;) factor(bedingung, levels = c(&quot;exp&quot;, &quot;kont1&quot;, &quot;kont2&quot;)) [1] exp kont1 exp exp kont1 Levels: exp kont1 kont2 Die Ausgabe der Funktion zeigt uns, dass die Stufe kont2 vorliegen könnte und innerhalb des Faktors gespeichert ist. Wenn die als Faktor zu kodierende Spalte numerisch ist, können mit dem Argument labels die Namen der verschiedenen Ausprägungsgrade spezifiziert werden. Ein häufiges Beispiel hierfür wäre die Variable Geschlecht mit drei Ausprägungsgeraden. geschlecht &lt;- c(1, 1, 2, 3, 1, 3) Die Umkodierung geht mit dem labels Argument intuitiv, sofern man auf die Reihenfolge der Labels achtet. factor(geschlecht, labels = c(&quot;m&quot;, &quot;f&quot;, &quot;d&quot;)) [1] m m f d m d Levels: m f d Grundsätzlich sollte man Faktoren nur bei Bedarf erstellen (zum Beispiel unmittelbar vor der ANOVA oder vor Erstellen einer Abbildung), da Faktoren nicht mit allen Funktionen erwartungsgemäß harmonieren. Dies hängt damit zusammen, dass Faktoren als Zahlen gespeichert werden. So erhalten wir für den Faktor fact1 als class() den Datentyp des Faktors, fct1 &lt;- factor(bedingung, levels = c(&quot;exp&quot;, &quot;kont1&quot;, &quot;kont2&quot;)) class(fct1) [1] &quot;factor&quot; während uns typeof() den Datentyp Integer zurückgibt. typeof(fct1) [1] &quot;integer&quot; Tatsächlich behandelt R Faktoren als Integer (Zahlen), was zu überraschenden Outputs führen kann. Verwende Faktoren also am besten nur dann, wenn du sie wirklich brauchst. Beispielsweise zum Rechnen inferenzstatistischer Verfahren oder unmittelbar vor dem Erstellen von Visualisierungen. Wie man mit Faktoren konkret umgehen kann, wird in Kapitel 6.10 erklärt. 4.3.3 Zeitdaten Wie bereits in Abbildung 4.6 illustriert, interessieren uns die Datentypen Date und POSIXct. Letzteres ist im Regelfall ein unerwünschtes Format, welches häufig beim Einlesen von Excel Dokumenten entsteht. Der Datentyp POSIXct ist ein Akronym für Portable Operating System Inferface calendar time (in der Ausgabe von tibbles und der Funktion glimpse() mit dttm für Datetime abgekürzt). Enthalten ist das Datum (Jahr.Monat.Tag) und die Uhrzeit. Die Uhrzeit ist allerdings in den wenigstens Forschungskontexten von Interesse. date_time &lt;- as.POSIXct(&quot;2024-01-09 08:30&quot;) date_time [1] &quot;2024-01-09 08:30:00 CET&quot; In das gewünschte Date Format können wir mit as.Date() umwandeln. as.Date(date_time) [1] &quot;2024-01-09&quot; Hier haben wir nur Informationen über das Jahr, den Monat und den Tag. Wenn wir ein Datum ausgeben, sieht es zunächst wie eine Buchstabenfolge aus. date_past &lt;- as.Date(&quot;2002-02-15&quot;) date_past [1] &quot;2002-02-15&quot; Wir können uns aber mit is.Date() vergewissern, dass wir den Datentype Date vorliegen haben. is.Date(date_past) [1] TRUE Ähnlich wie bei Faktoren müssen wir auch hier zum Verständnis zwischen der Klasse des Datums class(date_past) [1] &quot;Date&quot; und dem Datentyp unterscheiden. typeof(date_past) [1] &quot;double&quot; Der zugrundeliegende Datentyp des Datums ist eine Dezimalzahl (Double). Intern speichert R das Datum als Anzahl von Tagen seit einem bestimmten Datum ab. Meistens ist dieses Datum der 1. Januar 1900. Von diesem Datum bis zum 15. Februar 2002 sind 37300 Tage vergangen. Überprüfen können wir das durch Subtrahieren der beiden Daten. date_past - as.Date(&quot;1900-01-01&quot;) Time difference of 37300 days Dieses Format ist eine sogenannte difftime (engl. für Zeitdifferenz). Es passiert tatsächlich öfter als man denkt, dass das Datum nicht als Datum sondern als Zahl angezeigt wird. Dann können wir unter Angabe des Startdatums (origin), die Zahl wieder in ein Datum umwandeln. as.Date(37300, origin = &quot;1900-01-01&quot;) [1] &quot;2002-02-15&quot; Die Gründe hierfür können vielfältig sein. Wenn man bspw. bei unbekanntem Tag des Datums \"UN.06.2022\" in eine Zelle einträgt. Beim Einlesen kann die Spalte dann nicht als Datum eingelesen werden. Dies zu korrigieren, kann unter Umständen sehr mühsam sein. Einige Methoden zum konkreten Umgang mit diesen und weiteren Problemstellungen im Kontext von Zeitdaten wird in Kapitel 6.11 erläutert. 4.3.4 Datentypen konvertieren Datentypen können auch umgewandelt werden. Die Namen sind ähnlich wie beim Abfragen des Datentypes, nur dass der Präfix hier nicht is, sondern as ist. Um den vorhin erstellten Vektor vec in den Typ Character umzuwandeln, würde man dementsprechend as.character() verwenden. ` as.character(vec) [1] &quot;1&quot; &quot;4&quot; &quot;5&quot; &quot;10&quot; Wie man sieht, stehen nun sämtliche Zahlen in Anführungszeichen, weswegen man zum Beispiel nicht mehr eine Zahl ohne Weiteres addieren könnte. as.numeric() as.character() as.factor() as.Date() Beachte hier, dass nur bei Date ein Großbuchstabe verwendet wird. Wenn leere Character in Numerics umgewandelt werden, generiert R automatisch fehlende Werte (NAs). 4.4 Struktur von Datensätzen Bis auf wenige Ausnahmen setzen sämtliche im Buch verwendete Funktionen eine bestimmte Struktur der Daten voraus: Jede Zeile bezieht sich auf eine Beobachtung (z.B. jede Zeile enthält die Werte von einem Proband oder einer Patientin). Jede Spalte enthält eine Variable (z.B. Alter, Familienstand oder Überlebenszeit). Jede Zelle beinhaltet einen einzigen Wert, der genau einer Variable einer Beobachtung zuzuordnen ist. Wenn diese Voraussetzungen erfüllt sind, spricht man auch von einem tidy (engl. für aufgeräumten) Datensatz. Achte also am besten bereits beim Erheben der Daten auf eine richtige Struktur, da sonst die Funktionen, die wir in Kapitel 6 kennenlernen werden, nicht ohne Weiteres anwendbar sind. Als ein Praxisbeispiel betrachten wir den big_five Datensatz. Darin entspricht jede Zeile einem Proband oder einer Probandin, der oder die einen Fragebogen zu den Big5 Persönlichkeitsfaktoren beantwortet haben. Die Spalten sind dabei eine Mischung aus demographischen Variablen (z.B. Alter) und den Werten der eigentlichen Fragen (z.B. O1 für die erste Frage der Dimension Offenheit für neue Erfahrungen). big5 # A tibble: 200 × 7 Alter Geschlecht Extraversion Neurotizismus O1 O2 O3 &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 36 m 3 1.9 5 1 5 2 30 f 3.1 3.4 5 3 5 3 23 m 3.4 2.4 3 3 5 4 54 m 3.3 4.2 2 5 3 # … with 196 more rows 4.5 Der Dollar-Operator Manche Funktionen benötigen jedoch nicht den gesamten Datensatz im vorherigen Kapitel beschriebenen Format als Argument, sondern lediglich eine Spalte daraus. Diese Spalte können wir mit dem sogenannten Dollar-Operator aus dem Datensatz extrahieren. Das Praktische an dem Dollar-Operator im Vergleich zu anderen Methoden zum Extrahieren der Spalte ist die Möglichkeit der automatischen Vervollständigung durch RStudio. Wenn wir den Namen des Datensatzes big5 gefolgt von einem Dollar-Zeichen angeben, werden uns alle enthaltenen Spalten in einem Dropdown-Menu angezeigt. Dies ist vor allem bei langen Namen der jeweiligen Spalten äußerst praktisch und schützt uns vor Tippfehlern. Hier wählen wir exemplarisch die Spalte Alter aus. big5$Alter Hier würden uns alle 200 Alterswerte in einer Wertereihe bzw. als sogenannter Vektor zurückgegeben werden (siehe Kapitel 11.1). Um das ganze übersichtlich zu halten, lassen wir uns mit head() das Alter der ersten 6 Personen ausgeben. head(big5$Alter) [1] 36 30 23 54 24 14 "],["io.html", "Kapitel 5 Datensätze 5.1 Einlesen externer Dateien 5.2 Datensätze aus Packages laden 5.3 Datensätze in R erstellen 5.4 Speichern und Konvertieren", " Kapitel 5 Datensätze Mit einer Funktion alle erdenklichen Dateiformate einzulesen, klingt fast zu schön, um wahr zu sein. Durch ein Package ist dies in R tatsächlich bereits lange Realität. Neben den Einlesen externer Datensätze wird außerdem gezeigt, wie man Datensätze aus Packages laden oder direkt in R erstellen kann. Auch das Abspeichern der in R modifizierten Daten wird abschließend erklärt. 5.1 Einlesen externer Dateien Weißt du, was Projekte sind und kannst diese innerhalb von RStudio erstellen? Wenn nicht, lies dir das Konzept der Projektorientierung genau durch (siehe Kapitel 3.3). Ansonsten kann R die Datei, die deinen Datensatz enthält, nicht finden und somit auch nicht einlesen. Es muss also immer zunächst ein neues R Projekt erstellt werden. Der Datensatz muss sich dabei im gleichen Ordner wie die Projektdatei befinden. Im Regelfall möchte man den Datensatz nicht direkt in R erstellen, sondern einen bereits existierenden Datensatz zur Auswertung einlesen. Datensätze können dabei in verschiedenen Formaten vorliegen. Dies ist vor allem abhängig davon, mit welchen Programmen Unternehmen, Universitäten oder KollegInnen zur Datenerhebung arbeiten. Einige Beispiele für Dateientypen, in denen Daten häufig gespeichert werden, sind: R (.RData | .rda | .rds) Excel (.xlsx | .xls) SPSS (.sav) Stata (.dta) Comma separated values (.csv) Tabular separated values (.tsv) Sämtliche Datentypen können wir mit import() aus dem rio Package einlesen. Wir laden also zunächst das Package. library(rio) Um auch exotischere Dateiformate einlesen zu können, solltest du einmal den Befehl install_formats() ausführen. Es ist generell empfohlen, diese Funktion einmalig auszuführen, da sonst jedes Mal beim Laden des Packages eine entsprechende Meldung angezeigt wird. Beim Einlesen erkennt die Funktion import() die Art der Datei anhand der Endung und übernimmt hinter den Kulissen alles Weitere. Damit der Datensatz als sogenannter tibble eingelesen wird, solltest du zusätzlich das Argument setclass = \"tbl\" setzen. Weshalb wir die Sonderform der tibbles verwenden und was dies genau ist, wird im Verlaufe des Buches klar. Für den Moment musst du dir beim setclass Argument allerdings noch nichts denken, es aber trotzdem verwenden. Würden wir nur die import() Funktion aufrufen, würde der Datensatz zwar eingelesen, aber sofort wieder verschwinden, da dieser in R nicht abgespeichert wäre. Daher müssen wir den eingelesenen Datensatz, so wie in Kapitel Kapitel 4.2 beschrieben, einer Variable zuordnen. Der Name dieser Variable ist dabei nicht wichtig. Falls mit mehr als einem Datensatz gearbeitet wird, sollte ein aussagekräftigerer Name als der hier verwendete Name daten verwendet werden. Der Name des Datensatzes muss dabei in Anführungszeichen gesetzt werden. In unserem Beispiel heißt das Excel Dokument big_five.xlsx. Damit wir den Datensatz in R angezeigt bekommen, müssen wir den Namen des gespeicherten Datensatzes anschließend separat ausführen (siehe Kapitel 4.2). Dabei wird der Variablenname (hier daten) und nicht der Name der eigentlichen Datei (hier big_five.xlsx) verwendet. daten &lt;- import(&quot;big_five.xlsx&quot;, setclass = &quot;tbl&quot;) daten # A tibble: 200 × 16 Alter Gesch…¹ Extra…² Neuro…³ Vertr…⁴ Gewis…⁵ O1 O2 O3 O4 O5 O6 O7 O8 &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 36 m 3 1.9 3.4 3.3 5 1 5 1 4 1 5 5 2 30 f 3.1 3.4 3.1 2.7 5 3 5 3 4 1 3 5 3 23 m 3.4 2.4 3.6 3 3 3 5 3 4 1 4 2 4 54 m 3.3 4.2 3.6 3 2 5 3 4 3 3 1 1 # … with 196 more rows, 2 more variables: O9 &lt;dbl&gt;, O10 &lt;dbl&gt;, and abbreviated variable names # ¹​Geschlecht, ²​Extraversion, ³​Neurotizismus, ⁴​Vertraeglichkeit, ⁵​Gewissenhaftigkeit Die Datei (hier das Excel Dokument) muss sich innerhalb desselben Ordners wie die Projektdatei befinden. Falls die Datei in einem Unterordner ist, muss man den relativen Pfad – also den Weg bis zur Datei innerhalb der Unterordner (hier namens Daten) des Ordners (hier namens Beispiel) – zusätzlich der R Funktion mitteilen. Abbildung 5.1: Beispielshafte Ordnerstruktur mit Unterordner für Datensätze, R Skript und Projektdatei. Dabei nutzen wir die Funktion here() aus dem gleichnamigen Package. Dort können wir als separate Argumente den gesamten relativen Pfad eintragen. In diesem Beispiel liegt innerhalb des Ordners Daten der Datensatz indonesisch.xlsx. daten &lt;- import( file = here(&quot;Daten&quot;, &quot;indonesisch.xlsx&quot;), setclass = &quot;tbl&quot; ) Manchmal liegen Daten jedoch nicht in einer, sondern in vielen verschiedenen Dateien vor. Das ist vor allem häufig bei biophysiologischen Messungen wie beim Eye Tracking der Fall, bei denen die erhobenen Daten pro Person abgespeichert werden. Da wir nicht 20 Mal import() kopieren möchten (da Copy &amp; Paste sehr fehleranfällig ist), gibt es die Funktion import_list(). Angenommen, im Ordner Daten wären unsere 20 Excel Dokumente, in denen jeweils die Daten pro Person liegen. Dann könnte man zuerst mit dir() die Dateinamen herausfinden, um diese dann mit import_list() einzulesen. Mit dem Zusatzargument rbind = TRUE können wir die Datensätze direkt zusammenfügen. Voraussetzung dafür ist natürlich, dass die Datensätze dieselben Spalten haben. Da die Dateien in einem Unterordner liegen, müssen wir import_list() zusätzlich mit der Funktion here() mitteilen, wo sich die Datensätze befinden. dateien &lt;- dir(&quot;Daten&quot;, pattern = &quot;.xlsx$&quot;) daten &lt;- import_list( file = here(&quot;Daten&quot;, dateien), setclass = &quot;tbl&quot;, rbind = TRUE ) Das Dollar-Zeichen signalisiert in diesem Fall nur, dass wir am Ende des Dateinamens die Endung .xlsx (also ein Excel Dokument) erwarten. Dasselbe funktioniert übrigens für den Fall, verschiedene Excel Sheets innerhalb eines Excel Workbooks zu haben. Mit import_list() können alle auf einen Schlag eingelesen werden. Die in diesem Kapitel kennengelernten Funktionen können wir praktisch für alle Dateienarten verwendet werden. Falls also anders als in unserem Beispiel die Daten nicht in einem Excel Dokument, sondern einer Datei mit der Endung .csv enthalten sind, müssen wir lediglich die Endung verändern (z.B. big_five.csv). 5.2 Datensätze aus Packages laden Zum Bearbeiten dieses Buches brauchst du keine externen Datensätze, sondern nur jene, die im remp Package enthalten sind. So kannst du das Gelernte sofort begleitend in RStudio nachvollziehen und ausprobieren. Nach Laden des Packages hast du grundsätzlich sofort Zugriff auf alle enthaltenden Datensätze, allerdings werden diese erst nach Aufrufen der Funktion data() in R gespeichert. Zum Einlesen des big_five Datensatzes, müsste man demnach lediglich den Namen des Datensatzes der Funktion data() übergeben. library(remp) data(big_five) Sollte das Package vorher nicht geladen sein, kann alternativ auch zusätzlich das Argument package zur Spezifizierung des Ursprungs des Datensatzes verwendet werden. data(big_five, package = &quot;remp&quot;) Da der Befehl etwas länger ist und beim Üben das remp Package sowieso geladen werden sollte, ist allerdings der zuvor dargestellte Weg empfohlen. 5.3 Datensätze in R erstellen Direkt innerhalb von R Datensätze zu erstellen, ergibt nur in wenigen Anwendungsfällen wirklich Sinn. Der womöglich Wichtigste ist das Erstellen eines minimalen reproduzierbaren Beispiels, falls man auf einen Fehler stößt, den man selbst nicht lösen kann. Für größere Datensätze sollte man die Daten jedoch besser in Datenformaten wie .csv oder .xlsx kreieren. Möchte man einen Datensatz erstellen, muss man lediglich der Funktion tibble() Werte übergeben. In diesem Beispiel speichern wir den neuen Datensatz mit den zwei Spalten Extraversion und Geschlecht als my_tbl. Die Funktion c() (engl. für combine) kombiniert die einzelnen Werte eines Datentyps und kettet selbige aneinander. my_tbl &lt;- tibble( Extraversion = c(1.2, 2.7, 1.5, 4.8), Geschlecht = c(&quot;m&quot;, &quot;f&quot;, &quot;f&quot;, &quot;m&quot;) ) my_tbl # A tibble: 4 × 2 Extraversion Geschlecht &lt;dbl&gt; &lt;chr&gt; 1 1.2 m 2 2.7 f 3 1.5 f 4 4.8 m 5.4 Speichern und Konvertieren Das Speichern von Datensätzen funktioniert durch das rio Package ähnlich intuitiv wie das Importieren von Dateien. Anstelle von import() benutzen wir dafür stattdessen export(). Das erste Argument der Funktion ist der Datensatzname und das zweite Argument ist der gewünschte Dateiname. Der Dateientyp wird durch die gewählte Endung festgelegt. Möchte man beispielsweise den fertig aufbereiteten Datensatz video_clean als csv Datei abspeichern, würde man export(big_five_clean, &quot;big_five_clean.csv&quot;) schreiben. Manchmal ist es nützlich, den Datensatz unabhängig vom Einlesen umzuwandeln. Das kann zum Beispiel der Fall sein, wenn deine Kollegen dir eine SPSS Datei schicken (.sav) und du selbst kein SPSS hast, aber trotzdem einen Blick in die Daten werfen möchtest. Die Entwickler des rio Packages haben auch daran gedacht und die Funktion convert() geschrieben. Als erstes Argument übergibst du der Funktion den ursprünglichen Dateinamen (mit Endung) und als zweites denselben oder einen anderen Dateinamen mit der Endung des gewünschten Dateientypen. Sinnvoll wäre in diesem Kontext das Umwandeln in ein Excel Dokument, da dieses mit MS oder Libre Office problemlos geöffnet werden kann. convert(&quot;big_five.sav&quot;, &quot;big_five.xlsx&quot;) Die neue Datei wird sowohl bei export() als auch bei convert() in deinem Projektverzeichnis gespeichert. Besonders wichtig ist auch das Abspeichern von kategorealen Variablen als Buchstaben oder Wörter (Datentyp Character) und nicht als Zahlen. Nach spätestens einem Jahr kann kein Mensch mehr nachvollziehen, ob beispielsweise eine 1 nun für weiblich und 0 für männlich oder eine 1 für männlich und eine 0 für weiblich verwendet wurde. # A tibble: 4 × 2 Extraversion Geschlecht &lt;dbl&gt; &lt;dbl&gt; 1 1.2 0 2 2.7 1 3 1.5 1 4 4.8 0 Stattdessen sollte man die Zahlen in Character umwandeln. Wie das geht, wird in Kapitel 6.4.3 gezeigt. # A tibble: 4 × 2 Extraversion Geschlecht &lt;dbl&gt; &lt;chr&gt; 1 1.2 m 2 2.7 f 3 1.5 f 4 4.8 m Stelle vor dem Abspeichern des Datensatzes immer sicher, dass alle Variablen unmissverständlich kodiert sind. Kategorien sollten immer explizit benannt werden. "],["datenvorbereitung.html", "Kapitel 6 Datenvorbereitung 6.1 Einführung 6.2 Spalten auswählen, umbenennen und umsortieren 6.3 Zeilen auswählen und umsortieren 6.4 Spalten hinzufügen und Spalteninhalte verändern 6.5 Umgang mit fehlenden Werten und Duplikaten 6.6 Breites und langes Datenformat 6.7 Spalten trennen 6.8 Datensätze zusammenführen 6.9 Buchstaben und Wörter bearbeiten 6.10 Faktoren verändern 6.11 Mit Zeitdaten arbeiten 6.12 Binäre Antwortmatrix erstellen", " Kapitel 6 Datenvorbereitung Spalten oder Zeilen auswählen und umbenennen, Spalten hinzufügen und entfernen, Funktion erstellen und Spalteninhalte unter Bedingungen verändern, Spalten trennen oder das Zusammenfügen von Datensätzen sind nur ein kleiner Auszug aus den benötigen Werkzeugen für die Aufbereitung und Bereinigung der eigenen Daten. 6.1 Einführung Die Datenvorbereitung oder auch Datenaufbereitung ist in der Regel der mit Abstand aufwendigste und zeitintensivste Teil der Datenanalyse. Selten hat man nach der Datenerhebung bereits einen perfekt formatierten Datensatz vorliegen, den man statistisch auswerten kann. Mit den Funktionen des tidyverse ist die Datenvorbereitung unkompliziert und schnell zu bewerkstelligen. Das tidyverse ist ein Sammelsurium an Packages, die die gleiche Philosophie teilen. Dabei steht die Abkürzung tidy universe (engl. für aufgeräumtes Universum). Beim Laden des tidyverse werden neun Packages gemeinsam bereitgestellt, womit man sich im Prinzip nur das einzelne Aufrufen der neun Packages spart. Ausgeführt in R sieht das wie angeführt aus. Unter Conflicts werden Funktionen genannt, die denselben Namen wie andere R Funktionen haben und die von hier an überschrieben werden. library(tidyverse) -- Attaching core tidyverse packages ------------ tidyverse 2.0.0 -- ✔ dplyr 1.1.0 ✔ readr 2.1.4 ✔ forcats 1.0.0 ✔ stringr 1.5.0 ✔ ggplot2 3.4.1 ✔ tibble 3.1.8 ✔ lubridate 1.9.2 ✔ tidyr 1.3.0 ✔ purrr 1.0.1 -- Conflicts --------------------- tidyverse_conflicts() -- ✖ dplyr::filter() masks stats::filter() ✖ dplyr::lag() masks stats::lag() ℹ Use the conflicted package to force all conflicts to become errors ggplot2: Erstellen von Visualisierungen (siehe Kapitel 8). tibble: Erweiterung des klassischen data.frames (siehe Kapitel 11.3). tidyr: Wechsel zwischen langem und breitem Datenformat (siehe Kapitel 6.6). readr: Einlesen von Dateien (siehe Kapitel 5). purrr: Wiederholtes Anwenden von Funktionen (siehe Kapitel 12). dplyr: Funktionen zur Datenvorbereitung. stringr: Veränderung von Buchstaben und Wörtern (siehe Kapitel 6.9). forcats: Manipulation von Faktoren (siehe Kapitel 6.10). lubridate: Arbeiten mit Zeitdaten (siehe Kapitel 6.11). Die in diesem Kapitel eingeführten Funktionen zur Datenaufbereitung sind in sich konsistent. Man muss das Prinzip also nur einmal verstehen, um sämtliche Funktionen anwenden zu können. Dabei sind diese durch eine ausdrucksstarke Namensgebung beinahe schon selbsterklärend. Schauen wir uns zunächst eine typische Aneinanderreihung von Befehlen an: big5 |&gt; select(Geschlecht, Extraversion) |&gt; filter(Geschlecht == &quot;m&quot;) |&gt; mutate(Extraversion_lg = log(Extraversion)) # A tibble: 82 × 3 Geschlecht Extraversion Extraversion_lg &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; 1 m 3 1.10 2 m 3.4 1.22 3 m 3.3 1.19 4 m 3.5 1.25 # … with 78 more rows Gelesen würde es wie folgt: Man nehme den Datensatz big5 UND DANN wähle die Spalten Geschlecht und Extraversion UND DANN wähle die Zeilen, in denen Geschlecht gleich “m” (für männlich) ist UND DANN mutiere oder verändere die (neue) Spalte Extraversion_lg, wie in diesem Fall beschrieben, durch die logarithmierten Werte der Extraversion. Die anderen Funktionen sind ähnlich intuitiv und nahe an der englischen Sprache benannt. Besonders ist an dieser Stelle die sogenannte Pipe (|&gt;), welche für das Weiterreichen des modifizierten Datensatzes an die nächste Funktion zuständig ist. Der Name des Datensatzes muss nicht in jeder Funktion stehen, da dieser immer das erste Argument der hier behandelten Funktionen darstellt. In dem obigen Beispiel werden zuerst zwei der Spalten ausgewählt. Dann wird das Ergebnis dieses Befehls – also der Datensatz mit den zwei Spalten Geschlecht und Extraversion – im nächsten Schritt der Funktion filter() übergeben. Das Verbindungssymbol |&gt; wird als Pipe bezeichnet. Es kann mit dem Shortcut strg + shift + M (bzw. auf macOS mit cmd + shift + M) direkt eingefügt werden. Zuerst muss allerdings innerhalb von RStudio unter Tools/Global options .../Code der Haken bei Use native pipe operator, |&gt; (requires R 4.1+) gesetzt werden. Das Verwenden der in R integrierten Pipe (|&gt;) ist erst ab der R Version 4.1.0 möglich. Die Verwendung der Pipe hat zwei große Vorteile: Die Verschachtelung mehrerer Funktionen ineinander wird verhindert. Wir müssen nicht jedes Ergebnis der verschiedenen Funktionen einzeln zwischenspeichern. Trotzdem müssen wir das Ergebnis dieser aneinandergeketteten Funktion irgendwann mit dem Zuweisungspfeil speichern. daten &lt;- big5 |&gt; select(Geschlecht, Extraversion) |&gt; filter(Geschlecht == &quot;m&quot;) |&gt; mutate(Extraversion_lg = log(Extraversion)) Beachte, dass sämtliche Änderungen, die du am Datensatz vollziehst, erst gespeichert werden, wenn du sie mit dem Zuweisungspfeil einer Variable zuweist (siehe Kapitel 4.2). Falls der gewählte Variablenname bereits vergeben ist (z.B. der bisherige Datensatzname), wird dieser überschrieben. Um das rückgängig zu machen, muss der Datensatz dann wieder neu eingelesen werden. Es empfiehlt sich bei einschneidenden Änderungen einen neuen Variablennamen zu wählen. Ein zentrales Konzept ist die sogenannte Pipe (|&gt;), die verschiedenste Funktionsaufrufe aneinanderbinden kann. Dabei wird der modifizierte Datensatz jeweils an die nächste Funktion weitergeben. In diesem Buch verwenden wir die Pipe (|&gt;), welche seit der Version 4.1.0 direkt in R integriert ist. Älter ist die Pipe innerhalb des tidyverse, die mit %&gt;% geschrieben wird. Die Funktionsweise der beiden Operatoren unterscheidet sich für die meisten NutzerInnen nicht nennenswert und langfristig wird die Base R Pipe (|&gt;) weiter verbreitet sein. 6.2 Spalten auswählen, umbenennen und umsortieren Die Funktionen in diesem Kapitel beschäftigen sich mit der Auswahl, Umbenennung und Umordnung von Spalten. Wir haben die Funktion select() bereits im vorherigen Abschnitt kennengelernt. Es können beliebig viele Spalten ausgewählt werden. Dies ist vor allem nützlich, wenn der Datensatz groß ist und man übersichtlich nur die Spalten haben möchte, die zur Auswertung verwendet werden. Zur Auswahl einer Spalte muss nur der Name (ohne Anführungszeichen) der Funktion übergeben werden. Man kann auch direkt in der Funktion die Spalte umbenennen. Dabei muss auf der linken Seite des Gleichheitszeichens der neue Name stehen. big5 |&gt; select(Extraversion, Neuro = Neurotizismus) # A tibble: 200 × 2 Extraversion Neuro &lt;dbl&gt; &lt;dbl&gt; 1 3 1.9 2 3.1 3.4 3 3.4 2.4 4 3.3 4.2 # … with 196 more rows Zur Auswahl der Spalten von Extraversion bis O2 verwendet man einen Doppelpunkt. big5 |&gt; select(Extraversion:O2) Soll nur die Spalte Geschlecht entfernt und der Rest ausgegeben werden, erreicht man dies mit einem Minus vor dem Spaltennamen. Bei mehreren zu entfernenden Spalten müsste man diese zwischen Klammern einbetten (z.B. -(Extraversion:O2)). big5 |&gt; select(-Geschlecht) Darüber hinaus können wir sogenannte Helferfunktionen verwenden. Diese können nur in Kombination mit einer anderen Funktion verwendet werden. Ein nützliches Beispiel ist where(), womit beispielsweise alle numerischen Spalten ausgewählt werden können. big5 |&gt; select(where(is.numeric)) Eine weitere nützliche Helferfunktion ist starts_with(). So könnte man in diesem Fall beispielsweise alle Fragen zum Persönlichkeitsfaktor Offenheit auswählen, da diese alle mit dem Buchstaben O beginnen. big5 |&gt; select(starts_with(&quot;O&quot;)) Mit der Helferfunktion ends_with() können auf dieselbe Art und Weise Spalten ausgewählt werden, die mit einem bestimmten Character enden (z.B. eine Spalte endend mit dem Buchstaben A), während die Helferfunktion contains() prüft, ob ein Character im Spaltennamen enthalten ist . Darüber hinaus gibt es noch all_of(), um alle zuvor ausgewählten Variablen (Spaltennamen als Character) auszuwählen. Möchte man hingegen die Spalten nur umbenennen und dabei den gesamten Datensatz behalten, verwendet man anstelle von select() die Funktion rename(). Die Schreibweise der Argumente beim Umbenennen bleibt dabei im Vergleich zu select() gleich. big5 |&gt; rename(Sex = Geschlecht) # A tibble: 200 × 7 Alter Sex Extraversion Neurotizismus O1 O2 O3 &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 36 m 3 1.9 5 1 5 2 30 f 3.1 3.4 5 3 5 3 23 m 3.4 2.4 3 3 5 4 54 m 3.3 4.2 2 5 3 # … with 196 more rows Während beide Funktionen Spalten umbenennen können, gibt select() nur die ausgewählten Spalten und rename() hingegen alle Spalten zurück. Außerdem können Funktionen zur Umbenennung von Spalten verwendet werden. Dafür müssen wir rename_with() einfach nur die gewünschte Funktion (ohne Klammern) übergeben. In diesem Beispiel werden alle Buchstaben der Spaltennamen in Großbuchstaben umgewandelt. Alternativ könnten auch neue anonyme Funktion direkt innerhalb von rename_with() erstellt werden (siehe Kapitel 6.4.4). big5 |&gt; rename_with(toupper) # A tibble: 200 × 7 ALTER GESCHLECHT EXTRAVERSION NEUROTIZISMUS O1 O2 O3 &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 36 m 3 1.9 5 1 5 2 30 f 3.1 3.4 5 3 5 3 23 m 3.4 2.4 3 3 5 4 54 m 3.3 4.2 2 5 3 # … with 196 more rows Bei sehr großen Datensätzen mit vielen Spalten ist die Funktion relocate() äußerst nützlich. Eine neue Spalte wird zum Beispiel immer ans Ende des Datensatzes angefügt. Um diese trotzdem direkt am Anfang betrachten zu können, übergeben wir den Spaltennamen unserer Funktion. big5 |&gt; relocate(O1) # A tibble: 200 × 7 O1 Alter Geschlecht Extraversion Neurotizismus O2 O3 &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 5 36 m 3 1.9 1 5 2 5 30 f 3.1 3.4 3 5 3 3 23 m 3.4 2.4 3 5 4 2 54 m 3.3 4.2 5 3 # … with 196 more rows Wenn die Spalte nicht zu Beginn, sondern nach einer bestimmten anderen Spalte eingeordnet werden soll, können wir dies mit dem .after Argument festlegen. Hier würde die Spalte O1 hinter der Spalte Alter ausgegeben werden. big5 |&gt; relocate(O1, .after = Alter) Auch hier können wir wieder Helferfunktionen wie where() verwenden. Man könnte beispielsweise alle numerischen Spalten hinter alle character Spalten einfügen. big5 |&gt; relocate(where(is.numeric), .after = where(is.character)) Eine weitere nützliche Funktion bei sehr breiten Datensätzen mit vielen Spalten ist colnames(). So können wir auf einem Blick alle Spaltennamen ausgegeben bekommen. colnames(big5) [1] &quot;Alter&quot; &quot;Geschlecht&quot; &quot;Extraversion&quot; &quot;Neurotizismus&quot; &quot;O1&quot; [6] &quot;O2&quot; &quot;O3&quot; Von Zeilennamen (rownames()) sollte hingegen grundsätzlich Abstand genommen werden. Falls der Datensatz Zeilennamen enthält, die tatsächlich von Bedeutung sind, sollte man diese mit der Funktion rownames_to_column(\"Spaltenname\") aus dem tibble Package in eine eigene Spalte befördern. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 6.3 Zeilen auswählen und umsortieren Anders als im vorherigen Kapitel beschäftigen sich diese beiden Funktionen mit der Auswahl und Umordnung von Zeilen. Der Funktion filter() muss dabei ein logischer Ausdruck übergeben werden. Das Ergebnis der Abfrage muss also immer TRUE oder FALSE zurückgeben (siehe Kapitel 4.3). Zur Auswahl aller männlichen Probanden würde man Geschlecht == \"m\" schreiben. Beachte an dieser Stelle das doppelte Gleichheitszeichen. big5 |&gt; filter(Geschlecht == &quot;m&quot;) # A tibble: 82 × 7 Alter Geschlecht Extraversion Neurotizismus O1 O2 O3 &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 36 m 3 1.9 5 1 5 2 23 m 3.4 2.4 3 3 5 3 54 m 3.3 4.2 2 5 3 4 32 m 3.5 3.1 3 1 5 # … with 78 more rows Um Zeilen neu anzuordnen, benutzt man arrange(). Wenn die Zeilen nach aufsteigendem Alter sortiert werden sollen, muss man lediglich den Spaltennamen übergeben. big5 |&gt; arrange(Alter) Für eine absteigende Anordnung muss der Spaltennamen innerhalb der Helferfunktion desc() geschrieben werden. big5 |&gt; arrange(desc(Alter)) # A tibble: 200 × 7 Alter Geschlecht Extraversion Neurotizismus O1 O2 O3 &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 1995 f 2.5 3.7 4 1 4 2 1964 f 3.2 2.3 5 1 5 3 60 f 3 2.7 5 1 5 4 59 m 2.7 2.3 5 1 5 # … with 196 more rows So sehen wir hier beispielsweise zwei falsch eingetragene Alterswerte. Hier haben zwei Probandinnen nicht das Alter sondern das jeweilige Geburtsjahr in den Datensatz eingetragen. Das müsste vor einer Auswertung noch entsprechend korrigiert werden. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 6.4 Spalten hinzufügen und Spalteninhalte verändern 6.4.1 Einzelne Spalten Die Funktion mutate() ist eine sehr vielseitig einsetzbare Funktion zum Verändern bestehender oder zum Hinzufügen neuer Spalten. Dabei wird der neue oder bereits bestehende Spaltenname auf die linke Seite des Gleichheitszeichens geschrieben. Auf der rechten Seite kann so ziemlich alles stehen, solange die Funktion eine Spalte zurückgibt, die genauso lang ist wie der Datensatz. Einen Mittelwert über eine ganze Spalte könnte mit mutate() also nicht berechnet werden, da dabei nur ein einziger Wert zurückgeben werden würde. Mit der Funktion log() logarithmieren wir hingegen die Extraversionsausprägungen für jede Person, sodass wir 200 Werte erhalten. big5 |&gt; mutate(Extraversion_lg = log(Extraversion)) Standardmäßig wird die neue erstellte Spalte hinten als letzte Spalte zum Datensatz hinzugefügt. Möchte man die neue Spalte an einer anderen Position haben, können wir dies mit dem zusätzlichen Argument .after erreichen. So könnte man die neue Spalte namens Extraversion_lg bspw. direkt hinter der Spalte Extraversion einfügen. Dem .after Argument können ebenfalls die in Kapitel 6.2 eingeführten Helferfunktion wie starts_with() und ends_with() übergeben werden. big5 |&gt; mutate(Extraversion_lg = log(Extraversion), .after = Extraversion) # A tibble: 200 × 8 Alter Geschlecht Extraversion Extraversion_lg Neurotizismus O1 O2 O3 &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 36 m 3 1.10 1.9 5 1 5 2 30 f 3.1 1.13 3.4 5 3 5 3 23 m 3.4 1.22 2.4 3 3 5 4 54 m 3.3 1.19 4.2 2 5 3 # … with 196 more rows Möchten wir die bestehende Spalte Extraversion mit den logarithmierten Werten überschreiben, wählen wir auf der linken Seite des Gleichheitszeichens ebenfalls den Spaltennamen Extraversion. Es wird folglich keine neue Spalte hinzugefügt, sondern nur eine bestehende verändert. big5 |&gt; mutate(Extraversion = log(Extraversion)) # A tibble: 200 × 7 Alter Geschlecht Extraversion Neurotizismus O1 O2 O3 &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 36 m 1.10 1.9 5 1 5 2 30 f 1.13 3.4 5 3 5 3 23 m 1.22 2.4 3 3 5 4 54 m 1.19 4.2 2 5 3 # … with 196 more rows Innerhalb eines mutate() Aufrufes können wir auch mehrere Spalten einzeln neu erstellen oder verändern. Die verschiedenen Spalten müssen dabei lediglich mit einem Komma voneinander getrennt werden. Hier logarithmieren wir exemplarisch die mittlere Ausprägung von Extraversion und Neurotizismus. Der Abstand der öffnenden Klammer oben und der schließenden Klammer unten ist aus funktioneller Sicht nicht relevant. Es ist allerdings im Sinne der Lesbarkeit bei Benutzung mehrerer Argumenten unter Umständen sinnvoller, die Argumente auf mehrere Zeilen zu verteilen. Um unsere Berechnung überprüfen zu können, bringen wir noch unsere neuen mit lg endenden Spalten an den Anfang des Datensatzes (siehe Kapitel 6.2). Dies ist vor allem beim reinen Überprüfen nützlich, da der relocate() Aufruf im Anschluss übersichtlich wieder gelöscht werden kann. Möchte man die Anordnung dauerhaft verändern, ist das zuvor erwähnte Argument .after zu bevorzugen. big5 |&gt; mutate( Extraversion_lg = log(Extraversion), Neurotizismus_lg = log(Neurotizismus) ) |&gt; relocate(ends_with(&quot;lg&quot;)) # A tibble: 200 × 9 Extraversion_lg Neurotizismus_lg Alter Geschlecht Extraversion Neurotizis…¹ O1 O2 O3 &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 1.10 0.642 36 m 3 1.9 5 1 5 2 1.13 1.22 30 f 3.1 3.4 5 3 5 3 1.22 0.875 23 m 3.4 2.4 3 3 5 4 1.19 1.44 54 m 3.3 4.2 2 5 3 # … with 196 more rows, and abbreviated variable name ¹​Neurotizismus 6.4.2 Mehrere Spalten Wenn man eine Funktion auf mehrere Spalten anwenden möchte, kann man die Berechnung, wie im vorherigen Kapitel gezeigt, entweder für jede Spalte separat vornehmen oder mithilfe von across() (engl. für herüber) den Prozess abkürzen. Wir wollen schließlich eine Funktion über mehrere Spalten anwenden. Innerhalb von across() erfolgt die Auswahl der Spalten dabei genau wie in select() (siehe Kapitel 6.2). So kann bspw. der Doppelpunkt zur Auswahl eines mehrere Spalten umfassenden Bereiches oder c() zur Auswahl einzelner Spalten verwendet werden. Wichtig ist das Setzen der Klammern an der richtigen Stelle, da die Funktion log() innerhalb von across() aufgerufen wird. big5 |&gt; mutate(across( .cols = Extraversion:Neurotizismus, .fns = log, .names = &quot;{.col}_lg&quot;) ) # A tibble: 200 × 9 Alter Geschlecht Extraversion Neurotizismus O1 O2 O3 Extraversion_lg Neurotizismus…¹ &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 36 m 3 1.9 5 1 5 1.10 0.642 2 30 f 3.1 3.4 5 3 5 1.13 1.22 3 23 m 3.4 2.4 3 3 5 1.22 0.875 4 54 m 3.3 4.2 2 5 3 1.19 1.44 # … with 196 more rows, and abbreviated variable name ¹​Neurotizismus_lg Das .names Argument verhindert dabei das Überschreiben der Spalten. Innerhalb der geschweiften Klammern wird hier der Spaltenname für jede in .cols gewählten Spalte nacheinander übergeben und die Endung _lg angehängt. Würden wir den Namen der neu zu erstellenden Spalten nicht explizit mit .names definieren, würden die ursprünglichen Spalten Extraversion und Neurotizismus mit den logarithmierten Werten überschrieben werden. Die eigentlichen Werte wären also nach Abspeichern dieses Zwischenergebnisses nicht mehr im Datensatz enthalten, sondern nur noch die Spalten mit den logarithmierten Werten. Die auf mehrere Spalten anzuwendende Funktion muss innerhalb von across() übergeben werden. Falls ein Fehler auftritt, ist dieser in der Regel auf falsche Positionierung der Klammern zurückzuführen. Ein weiterer Unterschied besteht in der manuellen Auswahl einzelner Spalten. Hier müssen wir die einzelnen Spalten im Gegensatz zur Anwendung bei select() in diesem Fall innerhalb von c() übergeben. An dieser Stelle würden die eigentlichen Werte der Spalten Extraversion und Neurotizismus mit den logarithmierten Werten überschrieben werden, da das zuvor beschriebene .names Argument nicht definiert ist. big5 |&gt; mutate(across( .cols = c(Extraversion, Neurotizismus), .fns = log) ) Auch andere bereits in Kapitel 6.2 besprochene Helferfunktionen wie starts_with(), ends_with(), contains() oder where() können zur Variablensauswahl für das .cols Argument verwendet werden. big5 |&gt; mutate(across( .cols = where(is.numeric), .fns = log) ) Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 6.4.3 Änderungen unter Bedingungen Häufig möchte man Funktionen nicht auf alle Zeilen innerhalb der ausgewählten Spalten gleichermaßen anwenden. Wenn wir bspw. eine bestehende Spalte auf bestimmte Art und Weise nur dann verändern wollen, wenn eine bestimmte Bedingung zutrifft, erreichen wir dies mit der Funktion if_else(). Wir haben in Kapitel 6.3 gesehen, dass zwei Probandinnen ihr Geburtsjahr anstelle des Alters in Jahren angegeben haben. Wenn unsere Bedingung (condition) zutrifft, also das Alter in Jahren größer als 120 ist, soll das Jahr der Erhebung (2020) Minus das Alter gerechnet werden. Ansonsten (else bzw. false) wird nur das unveränderte Alter zurückgegeben. Anschließend überprüfen wir noch unsere Berechnung, indem wir das Alter wieder absteigend anordnen. big5 |&gt; mutate(Alter = if_else( condition = Alter &gt; 120, true = 2020 - Alter, false = Alter) ) |&gt; arrange(desc(Alter)) # A tibble: 200 × 7 Alter Geschlecht Extraversion Neurotizismus O1 O2 O3 &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 60 f 3 2.7 5 1 5 2 59 m 2.7 2.3 5 1 5 3 59 m 2.8 1.6 4 2 5 4 58 m 2.3 2.9 5 1 4 # … with 196 more rows Auf dieselbe Art und Weise könnte man Variablen vor dem Abspeichern umkodieren. Schließlich kann sich spätestens nach 2 Jahren niemand mehr erinnern, ob die 1 bei der Kodierung für Geschlecht nun für männlich oder weiblich stand. Deswegen ist es besser, diese direkt in m oder f abzuspeichern. Wenn das Geschlecht gleich 1 ist, schreibe in die Spalte ein m und ansonsten ein f. big5 |&gt; mutate(Geschlecht = if_else( condition = Geschlecht == 1, true = &quot;m&quot;, false = &quot;f&quot;) ) Bei mehr als zwei Bedingungen können wir anstelle von if_else() die Funktion case_when() verwenden. Auf der linken Seite der Tilde (~) ist dabei immer die Bedingung angegeben, während auf der rechten Seite steht, was bei zutreffender Bedingung in die Spalte geschrieben werden soll. Allen Werten, auf die keine der explizit genannten Bedingungen zutrifft, wird NA (Akronym für Not Available, engl. für nicht vorhanden) zugewiesen. Dies kann vermieden werden, indem man am Ende das Argument .default als Bedingung hinzufügt. Achtung, hier wird ein Gleichheitszeichen verwendet, da es sich um ein gewöhnliches Argument handelt. Somit werden in diesem Beispiel alle ProbandInnen, die bisher keiner Bedingung zugeordnet sind, in die ältesten Altersgruppe kategorisiert. Am Ende ordnen wir unsere neu erstellte Spalte zum Kontrollieren unserer Berechnung wie gewohnt nach vorne. big5 |&gt; mutate(Gruppe = case_when( Alter &lt;= 25 ~ &quot;Jungspund&quot;, Alter &gt; 25 &amp; Alter &lt;= 45 ~ &quot;Mittel&quot;, between(Alter, 46, 65) ~ &quot;Erfahren&quot;, .default = &quot;Weise&quot;) ) |&gt; relocate(Gruppe) # A tibble: 200 × 8 Gruppe Alter Geschlecht Extraversion Neurotizismus O1 O2 O3 &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Mittel 36 m 3 1.9 5 1 5 2 Mittel 30 f 3.1 3.4 5 3 5 3 Jungspund 23 m 3.4 2.4 3 3 5 4 Erfahren 54 m 3.3 4.2 2 5 3 # … with 196 more rows Die Helferfunktion between() ist eine übersichtliche Alternative zum kombinierten logischen Begriff eine Zeile darüber. Wichtig ist an dieser Stelle, dass der Datentyp auf der linken Seite der Tilde immer logisch sein muss. Der Ausdruck der linken Seite muss also entweder TRUE oder FALSE zurückgeben. Auf der rechten Seite der Tilde muss über alle Bedingungen hinweg immer der gleiche Datentyp sein. Wenn wir also wie hier den Datentyp Character haben, muss bei allen diesen Zuweisungen auf der rechten Seite der Datentyp übereinstimmen. Ein weiterer praktischer Anwendungsfall ist die Umkodierung von Antwortoptionen bei Fragebogendaten. Angenommen, wir messen auf einer Skala von 1 (trifft gar nicht zu) bis 5 (trifft vollkommen zu) die Ausprägung der Offenheit für neue Erfahrungen. Um Verzerrungen zu vermeiden, sind in einem derartigen Fragebogen immer einige Items verneint gestellt. Normalerweise würde beispielsweise gefragt, ob man gerne neue Sportarten ausprobiert. Würden wir allerdings fragen, ob man ungerne neue Sportarten ausprobiert, trifft unsere Skala natürlich nicht mehr zu. Hier wäre 5 trifft gar nicht zu und 1 trifft vollkommen zu. Stellen wir uns vor, dies würde für die erste Frage zur Offenheit O1 zutreffen. Zum Vergleich erstellen wir eine neue Spalte namens O1_neu, welche die umkodierten Werte enthält. Um die Ausgabe zu überprüfen lassen wir die originale und neue Spalte mithilfe von relocate() zu Beginn ausgeben (siehe Kapitel 6.2). big5 |&gt; mutate(O1_neu = case_when( O1 == 1 ~ 5, O1 == 2 ~ 4, O1 == 3 ~ 3, O1 == 4 ~ 2, O1 == 5 ~ 1) ) |&gt; relocate(O1, O1_neu) # A tibble: 200 × 8 O1 O1_neu Alter Geschlecht Extraversion Neurotizismus O2 O3 &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 5 1 36 m 3 1.9 1 5 2 5 1 30 f 3.1 3.4 3 5 3 3 3 23 m 3.4 2.4 3 5 4 2 4 54 m 3.3 4.2 5 3 # … with 196 more rows Immer wenn die Spalte O1 den Werte 1 hat, wird eine 5 daraus gemacht und immer wenn eine 2 angekreuzt wurde, diese mit einer 4 ersetzt. Die 3 können wir so belassen und die 4 und 5 wandeln wir auf die gleiche Art und Weise um. Beachte auch hier, dass wir auf der linken Seite immer eine logische Abfrage und rechts denselben Datentyp (hier Double) vorliegen haben. Auch hier können wir die nützlichen Helferfunktionen contains(), starts_with(), ends_with() und where() auf der linken Seite der Tilde verwenden. Zum Verändern von Spalteninhalten des Datentyps Character können wir die Funktion case_match() verwenden. Hiermit können wir beispielsweise die Bezeichnung für Gruppen schnell verändern. Soll das Geschlecht bspw. nicht als \"f\" und \"m\" sondern als weiblich und maennlich gespeichert werden, müssen wir wie bei case_when() die alte Bedingung auf die linke Seite der Tilde und das neue Ergebnis aus die rechte Seite schreiben. big5 |&gt; mutate(Geschlecht = case_match( Geschlecht, &quot;f&quot; ~ &quot;weiblich&quot;, &quot;m&quot; ~ &quot;maennlich&quot;) ) # A tibble: 200 × 7 Alter Geschlecht Extraversion Neurotizismus O1 O2 O3 &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 36 maennlich 3 1.9 5 1 5 2 30 weiblich 3.1 3.4 5 3 5 3 23 maennlich 3.4 2.4 3 3 5 4 54 maennlich 3.3 4.2 2 5 3 # … with 196 more rows Mit dieser Funktion können auch verschiedene Schreibweisen beim Ausfüllen von Fragebögen korrigiert werden. In diesem Beispiel gab es in der Spalte Kontakt vier Arten das Wort täglich zu schreiben und zwei für wöchentlich. daten |&gt; mutate(Kontakt = case_match( Kontakt, c(&quot;taeglich&quot;, &quot;Taeglich&quot;, &quot;täglich&quot;, &quot;Täglich&quot;) ~ &quot;Taeglich&quot;, c(&quot;wöchentlich&quot;, &quot;Wöchentlich&quot;) ~ &quot;Woechentlich&quot;) ) Nach gleichem Schema könnte man auch eine neue Spalte für Medikament A erstellen, die eine 1 bei Medikamenteneinnahme enthält und sonst eine 0. In der Spalte Medikamente wären bspw. bei manchen PatientInnen der Wirkstoff und bei manchen der Markenname des Medikaments enthalten. Auch hier wird mithilfe des .default Arguments der Wert festgelegt, welcher bei nicht-zutreffen der Bedingung in die Spalte geschrieben wird. Das Beispiel kann um beliebig viele Bedingungen erweitert werden. daten |&gt; mutate(MedikamentA = case_match( Medikamente, c(&quot;A_Wirkstoff&quot;, &quot;A_Markenname&quot;) ~ 1, .default = 0) ) Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 6.4.4 Eigene Funktionen erstellen Obwohl in R selbst oder in zusätzlichen Packages bereits eine Vielzahl von Funktionen enthalten sind, braucht man doch immer wieder eigene Funktionen für spezifische Anwendungsfälle. Dies versuchen wir anhand einer neuen Funktion zu illustrieren, die den Logarithmus einer der Funktion übergebenen Zahl mit zwei summiert. Diese Funktion soll den Namen new_log() haben. Eine Funktion wird mit function() erstellt. Innerhalb der runden Klammern können wir mit einem Komma getrennt beliebig viele Argumente festlegen. An dieser Stelle nehmen wir nur x. Der Name dieses Arguments ist grundsätzlich egal, solange er wie hier in dem Beispiel sowohl innerhalb von function() als auch in log() miteinander übereinstimmt. Die eigentliche Berechnung findet innerhalb der geschweiften Klammern statt. Es ist wichtig, dass wir einmal vor Benutzung diese Funktion durch Ausführen (strg + enter) lokal als Variable speichern. new_log &lt;- function(x) { log(x) + 2 } Eigene Funktionen müssen genau wie Packages nach Neustart von R immer wieder neu geladen werden. Dies erreicht man durch einmaliges Ausführen des obigen Befehls zu Beginn der Auswertung. Es gibt in dieser Hinsicht also keinen Unterschied zum Speichern gewöhnlicher Variablen. Eine Funktion mit zwei Argumenten, wenn wir beispielsweise zusätzlich noch die zu addierende Zahl innerhalb der Funktion anpassen möchten, könnte wie folgt aussehen. new_log &lt;- function(x, zahl = 2) { log(x) + zahl } Durch das zweite Argument könnte man mit new_log(c(2, 4, 1), zahl = 5) den Logarithmus der drei Zahlen jeweils mit 5 (anstelle von 2) addieren. Da innerhalb der Funktion bereits ein Standardwert (hier 2) angegeben ist, ist die explizite Angabe des Arguments zahl optional. So könnte man zum Logarithmieren und addieren mit 2 einfach new_log(c(2, 4, 1)) verwenden. Einmal erstellt und abgespeichert, können wir die eigene Funktion, wie in Kapitel 6.4.1 bereits gelernt, direkt innerhalb von mutate() anwenden. big5 |&gt; mutate(across(Extraversion:Neurotizismus, new_log)) # A tibble: 200 × 7 Alter Geschlecht Extraversion Neurotizismus O1 O2 O3 &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 36 m 3.10 2.64 5 1 5 2 30 f 3.13 3.22 5 3 5 3 23 m 3.22 2.88 3 3 5 4 54 m 3.19 3.44 2 5 3 # … with 196 more rows Eine Kurzschreibweise zum Definieren eigener Funktionen sind sogenannte Lambda Funktionen. Dies sind anonyme Funktionen, die keinen Funktionsnamen erhalten und daher auch nur einmalig bei Verwendung aufgerufen werden können. Dabei sind zwei Sachen hervorzuheben: Auf der einen Seite muss man immer einen führenden Backslash gefolgt von runden Klammern (\\()) hinzufügen. Innerhalb der Klammern wird der Name des Arguments (hier innerhalb von log()) übergeben. Im vorherigen Beispiel haben wir die Werte mit x und die zu addierende Zahl mit zahl bezeichnet. Bei anonymen Funktionen können wir entweder ebenfalls x oder einen beliebigen anderen Namen (z.B. wert) verwenden. Die folgenden zwei Funktionsaufrufe sind äquivalent. big5 |&gt; mutate(across(Extraversion:Neurotizismus, \\(x) log(x) + 2)) big5 |&gt; mutate(across(Extraversion:Neurotizismus, \\(wert) log(wert) + 2)) Als zweites Beispiel verwenden wir die z-Transformation bzw. Standardisierung einer Variable. Die dafür in R integrierte Funktion namens scale() gibt noch zusätzliche Informationen wieder, weswegen der Funktionsaufruf innerhalb von as.numeric() (Umwandlung in einen rein numerischen Datentypen) stehen sollte. Da wir die Spalten Extraversion und Neurotizismus nicht überschreiben, sondern zwei neue Spalten erstellen wollen, wird zusätzlich das .names Argument verwendet. Die neuen Spalten mit den standardisierten Werten würden so die Endung z erhalten. big5 |&gt; mutate(across( .cols = Extraversion:Neurotizismus, .fns = \\(wert) as.numeric(scale(wert)), .names = &quot;{.col}_z&quot;) ) Innerhalb des tidyverse kann eine alternative, nicht mehr empfohlene Schreibweise mit einer führenden Tilde verwendet werden. Dabei muss das Argument der Funktion immer mit .x benannt werden. big5 |&gt; mutate(across( .cols = Extraversion:Neurotizismus, .fns = ~ as.numeric(scale(.x)), .names = &quot;{.col}_z&quot;) ) Anonyme Funktionen sind eine praktische Möglichkeit, schnell eigene wenig komplexe Funktionen zu erstellen, die man nur an einer Stelle benötigt. So spart man sich das eigenständige Erstellen einer neuen Funktion. Für komplexere Anwendungen ist jedoch das Erstellen einer eigenen Funktion mit function() {} der übersichtlichere und damit empfohlene Weg. Seit der R Version 4.1.0 sind anonyme Funktionen mit der \\() Syntax ohne zusätzliche Packages direkt in R integriert. Für welche der beiden Optionen man sich letzten Endes entscheidet, hängt von der persönlichen Präferenz ab. Mithilfe der Lambda Funktionen könnten wir auf einen Schlag anders als zuvor in Kapitel 6.4.3 nicht nur eine Spalte, sondern so viele wie wir wollen, umkodieren. Wir erinnern uns, eine Spalte könnten wir mithilfe von case_when() umkodieren. big5 |&gt; mutate(O1_neu = case_when( O1 == 1 ~ 5, O1 == 2 ~ 4, O1 == 3 ~ 3, O1 == 4 ~ 2, O1 == 5 ~ 1) ) Möchten wir in einem Zug die Spalten O1, O2 und O3 in die richtige Reihenfolge bringen, können wir across() mit case_when() kombinieren. Durch die Lambda Funktion ändert sich der Spaltenname zum Backslash mit der Bezeichnung des Arguments (hier Auspraegung) in Klammern. Dieses Argument wird dann für alle ausgewählten Spalten umkodiert. big5 |&gt; mutate(across(c(O1, O2, O3), \\(Auspraegung) case_when( Auspraegung == 1 ~ 5, Auspraegung == 2 ~ 4, Auspraegung == 3 ~ 3, Auspraegung == 4 ~ 2, Auspraegung == 5 ~ 1) )) # A tibble: 200 × 7 Alter Geschlecht Extraversion Neurotizismus O1 O2 O3 &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 36 m 3 1.9 1 5 1 2 30 f 3.1 3.4 1 3 1 3 23 m 3.4 2.4 3 3 1 4 54 m 3.3 4.2 4 1 3 # … with 196 more rows Alternativ könnten die Variablen innerhalb von across() in diesem Fall auch mit O1:O3 oder starts_with(\"O\") ausgewählt werden. Beachte an dieser Stelle auch, dass die schließende Klammer von across() hinter dem vollständigen Funktionsaufruf von case_when() platziert wird. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 6.4.5 Zeilenweise berechnen Für Berechnungen pro Beobachtung muss die Funktion rowwise() mit c_across() kombiniert werden. Durch die separate Berechnung für jede Zeile über mehrere Spalten können bspw. Mittelwerte für jede Person in einem bestimmten Merkmal berechnet werden. Um das Konzept zu illustrieren, soll der Mittelwert pro Person für den Persönlichkeitsfaktor Offenheit berechnet werden. Dieser ergibt sich aus drei einzelnen Fragen zur Offenheit (O1, O2, O3). Zuerst müssen wir die Funktion rowwise() aufrufen, um R das zeilenweise Berechnen zu signalisieren. Innerhalb von mutate() müssen unsere drei Fragen zur Offenheit nun der Funktion c_across() übergeben werden. Beachte das Präfix c_ an dieser Stelle. Nach der Berechnung muss die zeilenweise Betrachtung des Datensatzes noch mit ungroup() aufgehoben werden. Zur Kontrolle holen wir uns die neu erstellte Spalte namens Offenheit wieder an den Anfang des Datensatzes. Auf diesen Aufruf von relocate() kann natürlich beim Abspeichern verzichtet werden. big5 |&gt; rowwise() |&gt; mutate(Offenheit = mean(c_across(O1:O3))) |&gt; ungroup() |&gt; relocate(Offenheit) # A tibble: 200 × 8 Offenheit Alter Geschlecht Extraversion Neurotizismus O1 O2 O3 &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 3.67 36 m 3 1.9 5 1 5 2 4.33 30 f 3.1 3.4 5 3 5 3 3.67 23 m 3.4 2.4 3 3 5 4 3.33 54 m 3.3 4.2 2 5 3 # … with 196 more rows Hinter die Spaltenauswahl mithilfe von c_across() können wir mit einem Komma getrennt wie gewohnt weitere Argumente der jeweiligen Funktion übergeben. Hier sei exemplarisch die Entfernung fehlender Werte mit na.rm = TRUE illustriert. big5 |&gt; rowwise() |&gt; mutate(Offenheit = mean(c_across(O1:O3), na.rm = TRUE)) |&gt; ungroup() Alternativ könnte man auf diese Weise mit sum() auch die Summe über bestimmte Spalten berechnen. Grundsätzlich können wir so jede Funktion aufrufen, die einen Wert pro Beobachtung zurückgibt (z.B. einen Mittelwert oder einen Median). Falls diese zusammenfassenden Berechnungen nicht pro Beobachtung sondern pro Gruppe oder über alle Beobachtungen ausgegeben werden soll, muss stattdessen summarise() verwendet werden (siehe Kapitel 7). Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 6.5 Umgang mit fehlenden Werten und Duplikaten Zur besseren Illustration der verschiedenen Möglichkeiten verwenden wir an dieser Stelle einen kleinen selbst erstellten Datensatz namens df. df &lt;- tibble( Alter = c(34, NA, 45, 999), Geschlecht = c(NA, &quot;m&quot;, &quot;f&quot;, &quot;&quot;), Extraversion = c(4, 3, 999, 2) ) df # A tibble: 4 × 3 Alter Geschlecht Extraversion &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 34 &lt;NA&gt; 4 2 NA &quot;m&quot; 3 3 45 &quot;f&quot; 999 4 999 &quot;&quot; 2 Enthalten sind zum einen fehlende Werte als NA und zum anderen als 999 kodiert. NA ist dabei ein besonderer Datentyp, der für Not Available (engl. für nicht verfügbar) steht. Die Kodierung als 999 ist typisch für SPSS-Nutzer, da dort kein dedizierter Datentyp für fehlende Werte existiert. Wir sind also daran interessiert, diese 999 oder andere nicht passende Werte in NAs sowie umgekehrt NAs in bestimmte Zahlen umzuwandeln. Einen ersten Überblick über die Anzahl der fehlenden Werte in allen Spalten erhalten wir mit colSums() und is.na(). Erstere Funktion bildet die Summe pro Spalte und letztere fragt ab, ob der Wert fehlend ist. colSums(is.na(df)) Alter Geschlecht Extraversion 1 1 0 Hier sehen wir richtiger Weise, dass ein Wert in der Altersspalte und zwei Werte in der Geschlechtsspalte fehlen. Möchten wir sehen, auf welche Beobachtungen das genau zutrifft, können wir das in Kapitel 6.3 kennengelernte filter() verwenden. Zum Beispiel könnte man so sehen, wer keine Geschlechtsangabe gemacht hat. df |&gt; filter(is.na(Geschlecht)) # A tibble: 1 × 3 Alter Geschlecht Extraversion &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 34 &lt;NA&gt; 4 Zum Umwandeln von Werten in NA können wir die Funktion na_if() aus dem dplyr Package verwenden. Wenn bspw. in der Spalte Alter die Zahl 999 vorkommt, soll stattdessen NA geschrieben werden. Das ganze müssen wir natürlich innerhalb von mutate() verwenden (siehe Kapitel 6.4). df |&gt; mutate(Alter = na_if(Alter, 999)) # A tibble: 4 × 3 Alter Geschlecht Extraversion &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 34 &lt;NA&gt; 4 2 NA &quot;m&quot; 3 3 45 &quot;f&quot; 999 4 NA &quot;&quot; 2 Dasselbe können wir natürlich mit across() auch gleich auf mehrere Spalten anwenden (siehe Kapitel 6.4.2). Hierbei müssen jedoch die Datentypen gleich sein. df |&gt; mutate(across(c(Alter, Extraversion), \\(x) na_if(x, 999))) # A tibble: 4 × 3 Alter Geschlecht Extraversion &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 34 &lt;NA&gt; 4 2 NA &quot;m&quot; 3 3 45 &quot;f&quot; NA 4 NA &quot;&quot; 2 So könnte man auch ein NA in jene Zellen schreiben, die einen leeren Character beinhalten. df |&gt; mutate(across(where(is.character), \\(x) na_if(x, &quot;&quot;))) # A tibble: 4 × 3 Alter Geschlecht Extraversion &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 34 &lt;NA&gt; 4 2 NA m 3 3 45 f 999 4 999 &lt;NA&gt; 2 Umgekehrt zur Umwandlung von NAs z.B. in die Zahl 999, können wir replace_na() aus selbigen Package benutzen. Wenn in der Spalte Alter ein NA steht, soll dieses mit 999 ersetzt werden. df |&gt; mutate(Alter = replace_na(Alter, 999)) # A tibble: 4 × 3 Alter Geschlecht Extraversion &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 34 &lt;NA&gt; 4 2 999 &quot;m&quot; 3 3 45 &quot;f&quot; 999 4 999 &quot;&quot; 2 Man könnte NAs auch in Abhängigkeit einer Bedingung mithilfe von if_else() oder case_when() zuweisen. So würde bspw. bei allen Personen mit einer Altersangabe über 120 ein fehlender Wert mit NA eingetragen werden. df |&gt; mutate(Alter = if_else(condition = Alter &gt; 120, true = NA, false = Alter)) # A tibble: 4 × 3 Alter Geschlecht Extraversion &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 34 &lt;NA&gt; 4 2 NA &quot;m&quot; 3 3 45 &quot;f&quot; 999 4 NA &quot;&quot; 2 Die meisten Statistikfunktionen haben im Regelfall ein Argument namens na.rm (Akronym für not available remove), welches die fehlenden Werte der entsprechenden Spalte direkt entfernt. Genauer gesagt verwenden diese Funktionen an dieser Stelle die sogenannten Pairwise complete observations. Im letzten Kapitel haben wir die Anwendung bereits im Kontext von zeilenweisen Mittelwertsberechnungen kennengelernt. big5 |&gt; rowwise() |&gt; mutate(Offenheit = mean(c_across(O1:O3), na.rm = TRUE)) |&gt; ungroup() Eine weitere Möglichkeit ist das Entfernen von Zeilen, die fehlende Werte enthalten. Dies erreichen wir mit drop_na() aus dem dplyr Package. Allerdings entfernt diese Funktion die gesamte Zeile von allen Beobachtungen, in denen auch nur ein NA vorkommt. Wenn du also zwei Spalten auswerten möchtest und in einer dritten für die Auswertung irrelevanten Spalte ist ein fehlender Wert, würde die entsprechende Zeile trotzdem entfernt werden. Hier ist also Vorsicht geboten, um keine Informationen zu verlieren. df |&gt; drop_na() # A tibble: 2 × 3 Alter Geschlecht Extraversion &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 45 &quot;f&quot; 999 2 999 &quot;&quot; 2 Alternativ können wir mithilfe von filter() und der logischen Abfrage is.na() das Entfernen von NAs auch auf eine bestimmte Spalte begrenzen (hier Geschlecht). Der Unterschied zum Aufruf zuvor ist das Ausrufezeichen vor is.na(). Es sollen schließlich jene Zeilen ausgegeben werden, die keinen fehlenden Wert in der Spalte Geschlecht haben. df |&gt; filter(!is.na(Geschlecht)) # A tibble: 3 × 3 Alter Geschlecht Extraversion &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 NA &quot;m&quot; 3 2 45 &quot;f&quot; 999 3 999 &quot;&quot; 2 Exemplarische sei eine doppelte Zeile in den Datensatz df hinzugefügt. df &lt;- tibble( Alter = c(34, NA, 45, 45), Geschlecht = c(NA, &quot;m&quot;, &quot;f&quot;, &quot;f&quot;), Extraversion = c(4, 3, 999, 999) ) df # A tibble: 4 × 3 Alter Geschlecht Extraversion &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 34 &lt;NA&gt; 4 2 NA m 3 3 45 f 999 4 45 f 999 Mit distinct() können derartige Duplikate entfernt werden. df |&gt; distinct() # A tibble: 3 × 3 Alter Geschlecht Extraversion &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 34 &lt;NA&gt; 4 2 NA m 3 3 45 f 999 Der Funktion können auch Spaltennamen übergeben werden. Dies ist nützlich, wenn zwei Beobachtungen von derselben Person vorhanden sind, man aber bspw. nur die Erstdiagnose behalten möchte. Für dieses Beispiel würde mit arrange() erst die Reihenfolge so verändert, dass die Erstdiagnose bei doppelten Personeneinträgen an erster Stelle steht und anschließend nur die erste Zeile behalten wird. daten |&gt; arrange(Name, Vorname, Erstdiagnose) |&gt; distinct(Name, Vorname, .keep_all = TRUE) Das Argument .keep_all sorgt dafür, dass jeweils die erste Spalte von Duplikaten behalten wird. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 6.6 Breites und langes Datenformat Grundsätzlich unterscheidet man ein sogenanntes breites Datenformat von einem langen Datenformat. Im breiten Datensatz ist jede Spalte eine Variable, jede Zeile eine Beobachtung und jede Zelle ein Wert. Für die meisten Fälle ist das unser gewünschtes Datenformat. In Abbildung 6.1 ist ein einfaches Beispiel für einen breiten Datensatz mit drei Personen und zwei Variablen illustriert. Abbildung 6.1: Breites Datenformat mit drei Personen und drei Variablen. Für das Erstellen mehrfaktorieller Abbildungen und hierarchischer statistischer Modellierung benötigen wir allerdings das lange Datenformat. In Abbildung 6.2 ist der zuvor gezeigte Datensatz in ein langes Format umgewandelt. Abbildung 6.2: Langes Datenformat mit Persönlichkeitsfaktor als Innersubjektfaktor. Im tidyr Package sind zwei Funktionen für genau diese Umwandlungen enthalten. Mit pivot_longer() (engl. für Drehpunkt länger) können wir ein breites Datenformat in ein langes verändern. Die Funktion pivot_wider() fungiert umgekehrt für die Transformation vom langen ins breite Datenformat. Erstere Funktion findet deutlich häufiger Anwendung, da die Daten häufig initial im breiten Format vorhanden sind. Für das Umformatieren ins lange Datenformat ist es essentiell, einen eindeutigen Personenidentifikator im breiten Datensatz zu haben. Ansonsten wird es nicht funktionieren. Hier entscheiden wir uns einfach für die Zeilennummer, die wir mit der Funktion row_number() in die Spalte VPN (Akronym für Versuchspersonennummer) schreiben. In der Realität hat man im Regelfall pseudo-anonymisierte Identifikatoren. wide_big5 &lt;- big5 |&gt; mutate(VPN = row_number()) |&gt; select(VPN, Geschlecht, Extraversion, Neurotizismus) wide_big5 # A tibble: 200 × 4 VPN Geschlecht Extraversion Neurotizismus &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; 1 1 m 3 1.9 2 2 f 3.1 3.4 3 3 m 3.4 2.4 4 4 m 3.3 4.2 # … with 196 more rows Nun müssen wir in der Funktion pivot_longer() nur noch die gewünschten Spalten auswählen. Im obigen Beispiel wären das Extraversion und Neurotizismus. Beachte, dass genau wie bei across() auch hier die Spalten bei einzelner Auswahl der Funktion innerhalb von c() übergeben werden müssen. Es werden zwei neue Spalten erstellt, die erst noch benannt werden müssen. Wie man diese benennt, ist einem selbst überlassen. Der Name für die Spalte mit den Werten wird mit dem Argument values_to und die Spalte mit den Spaltennamen mit names_to festgelegt. Hier entscheiden wir uns für die neuen Spaltennamen \"Auspraegung\" und \"Faktor\". Die Namen müssen hier unbedingt in Anführungszeichen geschrieben werden, da die Spalten noch nicht existieren. Das Ergebnis speichern wir an dieser Stelle als long_big5 ab. long_big5 &lt;- wide_big5 |&gt; pivot_longer( cols = c(Extraversion, Neurotizismus), values_to = &quot;Auspraegung&quot;, names_to = &quot;Faktor&quot; ) long_big5 # A tibble: 400 × 4 VPN Geschlecht Faktor Auspraegung &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 1 m Extraversion 3 2 1 m Neurotizismus 1.9 3 2 f Extraversion 3.1 4 2 f Neurotizismus 3.4 # … with 396 more rows Zur Auswahl der Spalten können dieselben Helferfunktionen verwendet werden, die in Kapitel 6.2 beschrieben sind (z.B. starts_with(), ends_with() oder everything()). Umgekehrt können wir mithilfe von pivot_wider() den Datensatz long_big5 wieder ins breite Datenformat bringen. Dafür müssen wir hier nur festlegen, aus welcher Spalte die Werte (values_from) und woher die Spaltennamen (names_from) kommen sollen. Hier benötigen wir keine Anführungszeichen, da die Spalten bereits in unserem Datensatz enthalten sind. long_big5 |&gt; pivot_wider( values_from = Auspraegung, names_from = Faktor ) # A tibble: 200 × 4 VPN Geschlecht Extraversion Neurotizismus &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; 1 1 m 3 1.9 2 2 f 3.1 3.4 3 3 m 3.4 2.4 4 4 m 3.3 4.2 # … with 196 more rows Als grobe Daumenregel kann man sich merken, dass man nicht vorhandene Spalten mit Anführungszeichen übergeben muss. Auf bereits im Datensatz vorhandene Spalten kann man hingegen im Regelfall ohne Anführungszeichen zugreifen. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 6.7 Spalten trennen Mit den Funktionen namens separate_wider_*() aus dem tidyr Package können Spalten getrennt werden. Dabei unterscheiden wir drei Szenarien, für die jeweils eine eigene Funktion existiert. Die Informationen innerhalb einer Spalte sind getrennt durch einen Trenner (z.B. Unterstrich, Komma, Punkt): separate_wider_delim(), eine genaue Position: separate_wider_position(), einen Regex (siehe Kapitel 6.9): separate_wider_regex(). Falls die Spalten anstelle des weiten Datenformates in ein langes gebracht werden sollen, existieren äquivalent dazu die Funktionen separate_longer_delim(), separate_longer_position() und separate_longer_regex(). Exemplarisch sei hier der im remp Package enthaltene Datensatz big5_zeit geladen. big5_zeit # A tibble: 5 × 5 VPN Extrav_T1 Extrav_T2 NeurotFA NeurotFB &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 1 3.2 3.3 2.8 3.2 2 2 1.7 1.5 4.1 3.2 3 3 2.8 2.7 3.2 2.8 4 4 4.7 4.2 1.7 2.4 # … with 1 more row Um das hier bestehende Problem klarer zu machen, wandeln wir diesen erst einmal in ein langes Datenformat um (siehe Kapitel 6.6). zeit1 &lt;- big5_zeit |&gt; select(-NeurotFA, -NeurotFB) |&gt; pivot_longer( cols = Extrav_T1:Extrav_T2, names_to = &quot;Faktor&quot;, values_to = &quot;Auspraegung&quot; ) zeit1 # A tibble: 10 × 3 VPN Faktor Auspraegung &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; 1 1 Extrav_T1 3.2 2 1 Extrav_T2 3.3 3 2 Extrav_T1 1.7 4 2 Extrav_T2 1.5 # … with 6 more rows Die Spalte Faktor enthält hier zwei Informationen: den Persönlichkeitsfaktor (Extrav) und den entsprechenden Messzeitpunkt (T1, T2). Es muss mit dem names Argument festgelegt werden, wie die neuen Spalten mit den getrennten Informationen heißen sollen. Die beiden Informationen sind durch einen Unterstrich (_) getrennt, weswegen wir dem delim Argument innerhalb der Funktion separate_wider_delim() diesen Unterstrich als Character übergeben. Würde die Spalte Faktor mehr als zwei Informationen getrennt durch mehrere Unterstriche enthalten, müssten wir dem Argument names entsprechend drei Spaltennamen übergeben. zeit1 |&gt; separate_wider_delim( cols = Faktor, names = c(&quot;Faktor&quot;, &quot;Zeitpunkt&quot;), delim = &quot;_&quot; ) # A tibble: 10 × 4 VPN Faktor Zeitpunkt Auspraegung &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 1 Extrav T1 3.2 2 1 Extrav T2 3.3 3 2 Extrav T1 1.7 4 2 Extrav T2 1.5 # … with 6 more rows Falls die Informationen innerhalb einer Spalten nicht mit einem Unterstrich, sondern durch unterschiedliche Wortlängen, getrennt sind, verwendet man stattdessen die Funktion separate_wider_position(). Hierbei muss dem widths Argument innerhalb von c() die Anzahl der Buchstaben der ersten und zweiten Information übergeben werden. Der Persönlichkeitsfaktor Neurot hat sechs Buchstaben und die Information über den Messzeitpunkt zwei. big5_zeit |&gt; select(-Extrav_T1, -Extrav_T2) |&gt; pivot_longer( cols = NeurotFA:NeurotFB, names_to = &quot;Faktor&quot;, values_to = &quot;Auspraegung&quot; ) |&gt; separate_wider_position( cols = Faktor, widths = c(Faktor = 6, Zeitpunkt = 2) ) # A tibble: 10 × 4 VPN Faktor Zeitpunkt Auspraegung &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 1 Neurot FA 2.8 2 1 Neurot FB 3.2 3 2 Neurot FA 4.1 4 2 Neurot FB 3.2 # … with 6 more rows 6.8 Datensätze zusammenführen In der Praxis hat man häufig nicht nur einen Datensatz vorliegen, der alle notwendigen Informationen enthält. Stattdessen sind oft die eigentlichen Daten der Studie in einem Datensatz, die demographischen Daten wie Geschlecht und Alter in einem zweiten und Laborwerte wiederum in einem anderen Datensatz. Andere mögliche Szenarien sind mehrere Untersucher oder verschiedenen Messzeitpunkte. Welcher Grund auch immer für separate Datensätze verantwortlich ist, vor der Auswertung müssen diese zusammengeführt werden. Um dieses Prinzip zu illustrieren, haben wir zwei Datensätze mit Informationen über den Puls, Vorhandensein einer Blasenentleerungsstörung und die Anzahl an Infektionen innerhalb von zwei Jahren. Diese wurden von zwei Untersuchern erhoben, weswegen diese in dem Datensatz df_oben und df_unten vorliegt. df_oben # A tibble: 3 × 4 ID Puls Blasenstoerung Infekt_2j &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 AX161095 83 0 1 2 NM020683 108 1 7 3 IO240576 60 0 2 df_unten # A tibble: 3 × 4 ID Puls Blasenstoerung Infekt_2j &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 EW180265 53 1 5 2 CB280682 92 0 0 3 JH051199 65 0 1 Der Datensatz demogr enthält darüber hinaus demographische Daten in Form des biologischen Geschlechts und Alters. demogr # A tibble: 4 × 3 ID Sex Alter &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 AX161095 m 28 2 NM020683 f 47 3 IO240576 f 40 4 JH051199 m 24 Solange in beiden Datensätzen dieselben Spalten vorhanden sind, könnte man beide zeilenweise zusammenfügen. In Kapitel 5.1 haben wir bereits gesehen, dass mehrere Datensätze mit gleichem Format mithilfe des zusätzlichen Arguments rbind (row bind) verbunden werden können. import_list(dateien, rbind = TRUE) Mit der Funktion bind_rows() kann diese Operation auch mit bereits in R geladenen Datensätzen durchgeführt werden. Die einzigen Argumente sind dabei die Namen der Datensätze. bind_rows(df_oben, df_unten) # A tibble: 6 × 4 ID Puls Blasenstoerung Infekt_2j &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 AX161095 83 0 1 2 NM020683 108 1 7 3 IO240576 60 0 2 4 EW180265 53 1 5 5 CB280682 92 0 0 6 JH051199 65 0 1 Problematisch ist bei dieser Funktion, dass nicht überprüft wird, ob Beobachtungen mehrfach vorkommen. Mit einem sogenannten Join (engl. für aneinanderfügen) können zwei Datensätze kontrolliert zusammengefügt werden. Die Funktion full_join() kombiniert alle Informationen aus beiden Datensätzen. full_join(df_oben, df_unten) Joining with `by = join_by(ID, Puls, Blasenstoerung, Infekt_2j)` # A tibble: 6 × 4 ID Puls Blasenstoerung Infekt_2j &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 AX161095 83 0 1 2 NM020683 108 1 7 3 IO240576 60 0 2 4 EW180265 53 1 5 5 CB280682 92 0 0 6 JH051199 65 0 1 Da in diesem Beispiel alle Spalten aus beiden Datensätzen integriert werden sollen, muss zusätzlich das by Argument nicht spezifiziert werden. Es wird eine Benachrichtigung ausgegeben, dass nach den Spalten ID, Puls, Blasenstoerung und Infekt_2j zusammengefügt wurde. Vorsicht ist geboten, wenn es Überschneidung in den Datensätzen gibt (z.B. die gleiche Person in beiden Datensätzen aber mit unterschiedlichen Werten in einer gleichnamigen Spalte). Daher sollte bspw. ein zweiter Messzeitpunkt direkt innerhalb des Spaltennamens entsprechend gekennzeichnet werden (z.B. Puls_T1 und Puls_T2). Sollen in den linken Datensatz (1. Argument, hier df_oben) die Informationen eines zweiten Datensatzes (2. Argument, hier demogr) in Abhängigkeit der Übereinstimmung einer dritten Spalte (by Argument, hier ID) eingefügt werden, verwenden wir left_join(). left_join(df_oben, demogr, by = &quot;ID&quot;) # A tibble: 3 × 6 ID Puls Blasenstoerung Infekt_2j Sex Alter &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 AX161095 83 0 1 m 28 2 NM020683 108 1 7 f 47 3 IO240576 60 0 2 f 40 Obwohl in demogr die demographischen Informationen von vier Personen enthalten sind, werden an dieser Stelle nur jene drei an df_oben angehängt, deren ID mit der in df_oben übereinstimmt. Wenn der linke Datensatz in den rechten integriert werden soll, kann man äquivalent dazu right_join() benutzen. Wenn hingegen alle IDs vorhanden sind, allerdings einige demographische Informationen fehlen, werden diese mit NA (not available, engl. für nicht vorhanden) angegeben. Um das zu illustrieren, werden erst df_oben und df_unten zusammengefügt. df_alle &lt;- full_join(df_oben, df_unten) Joining with `by = join_by(ID, Puls, Blasenstoerung, Infekt_2j)` Anschließend joinen wir wie zuvor eingeführt in Abhängigkeit der ID. left_join(df_alle, demogr, by = &quot;ID&quot;) # A tibble: 6 × 6 ID Puls Blasenstoerung Infekt_2j Sex Alter &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 AX161095 83 0 1 m 28 2 NM020683 108 1 7 f 47 3 IO240576 60 0 2 f 40 4 EW180265 53 1 5 &lt;NA&gt; NA 5 CB280682 92 0 0 &lt;NA&gt; NA 6 JH051199 65 0 1 m 24 Wenn wir nur diejenigen Werte integrieren möchten, die in beiden Datensätzen enthalten sind, verwenden wir inner_join(). Abschließend gibt es noch zwei Funktionen, die nicht direkt zusammenführen, sondern nur eine Bedingung prüfen und davon abhängig den ersten (linken) Datensatz zurückgeben. Die Funktion semi_join() gibt nur jene Werte aus dem ersten Datensatz zurück, welche im ersten (linken) und zweiten (rechten) vorkommen. Die Funktion anti_join() hingegen gibt nur die Werte aus dem ersten (linken) Datensatz zurück, die nicht im zweiten (rechten) Datensatz enthalten sind. Das einfache Zusammenfügen von mehreren Zeilen mit bind_rows() ist risikoreich und sollte genau überprüft werden. Kontrollierter ist das Kombinieren mithilfe der Joins. Diese fügen Datensätze nur dann zusammen, wenn es Übereinstimmungen in weiteren Spalten gibt. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 6.9 Buchstaben und Wörter bearbeiten Oft muss man entweder die Spaltennamen oder die Inhalte verschiedener Spalten, die Characters enthalten, in irgendeiner Form anpassen. In diesem Kapitel schauen wir uns an, wie man mit Funktionen aus stringr Character ersetzt (str_replace()), extrahiert (str_extract()) und entdeckt (str_detect()). Das Präfix str steht dabei für String – einem anderen Wort für Character. Ein häufiges Ärgernis im Kontext von Programmiersprachen sind Umlaute, da verschiedene Zeichenkodierungen diese intern unter Umständen anders übersetzen, was auf anderen Betriebssystemen zu Kauderwelsch führen kann. Schauen wir uns im Folgenden an, wie man Umlaute ersetzt. Es ist folgender Satz in der Variable char gespeichert. char &lt;- &quot;Österreich hat 28610 schräge Berge&quot; Möchte man nun das eine ä mit ae ersetzen, verwendet man str_replace(). str_replace(string = char, pattern = &quot;ä&quot;, replacement = &quot;ae&quot;) [1] &quot;Österreich hat 28610 schraege Berge&quot; In dem Satz ist allerdings nicht nur ein ä sondern auch ein ö enthalten. Für mehr als eine Anpassung verwendet man str_replace_all(). Die Syntax ist hierbei etwas anders als bisher kennengelernt, da in diesem Fall die alte Bezeichnung auf der linken Seite der jeweiligen Gleichung steht. Alle Änderungen müssen innerhalb von c() übergeben werden. str_replace_all(string = char, c(&quot;ä&quot; = &quot;ae&quot;, &quot;Ö&quot; = &quot;Oe&quot;)) [1] &quot;Oesterreich hat 28610 schraege Berge&quot; Beachte, dass ein Umlaut großgeschrieben ist und die Funktionen case sensitive sind. Das bedeutet, dass wir mit den Befehlen oben nur den kleinen Buchstaben ä und den großen Buchstaben Ö ersetzen. Aber wie geht man vor, wenn Spaltennamen Umlaute enthalten? Um dem auf den Grund zu gehen, erstellen wir uns einen neuen Datensatz, der die Preise für drei verschiedene Sägen in Österreich enthält. umlaut &lt;- tibble( Säge = c(&quot;Häxler&quot;, &quot;Sünde3000&quot;, &quot;Lölf4&quot;), Österreich = c(10.45, 4.60, 9.70) ) umlaut # A tibble: 3 × 2 Säge Österreich &lt;chr&gt; &lt;dbl&gt; 1 Häxler 10.4 2 Sünde3000 4.6 3 Lölf4 9.7 Die Namen enthalten jeweils einen Umlaut. Möchten wir alle Spaltennamen von Umlauten befreien, könnten wir dies mithilfe von rename_with() und str_replace_all() erreichen. An dieser Stelle verwenden wir eine im Kapitel 6.4.4 bereits eingeführte Lambda Funktion, um die Funktion auf alle Spalten anzuwenden. umlaut |&gt; rename_with(\\(x) str_replace_all( string = x, c(&quot;ä&quot; = &quot;ae&quot;, &quot;ö&quot; = &quot;oe&quot;, &quot;ü&quot; = &quot;ue&quot;, &quot;Ä&quot; = &quot;Ae&quot;, &quot;Ö&quot; = &quot;Oe&quot;, &quot;Ü&quot; = &quot;Ue&quot;) )) # A tibble: 3 × 2 Saege Oesterreich &lt;chr&gt; &lt;dbl&gt; 1 Häxler 10.4 2 Sünde3000 4.6 3 Lölf4 9.7 Zum Ändern von Umlauten innerhalb von Spalten muss str_replace_all(), wie in Kapitel 6.4.2 kennengelernt, innerhalb von mutate() in Kombination von across() verwendet werden. So könnte man alle Spalten, die vom Datentyp Character sind, von Umlauten befreien. umlaut |&gt; mutate(across(where(is.character), \\(x) str_replace_all( string = x, c(&quot;ä&quot; = &quot;ae&quot;, &quot;ö&quot; = &quot;oe&quot;, &quot;ü&quot; = &quot;ue&quot;, &quot;Ä&quot; = &quot;Ae&quot;, &quot;Ö&quot; = &quot;Oe&quot;, &quot;Ü&quot; = &quot;Ue&quot;) ))) # A tibble: 3 × 2 Säge Österreich &lt;chr&gt; &lt;dbl&gt; 1 Haexler 10.4 2 Suende3000 4.6 3 Loelf4 9.7 Für das Extrahieren von Buchstaben oder Zahlen können wir str_extract() verwenden. Wir nehmen wieder unseren Beispielsatz von oben, der als char gespeichert ist. Es ist möglich, die Zahl mithilfe eines sogenannten Regex zu erkennen (Akronym für Regular Expression). Regex sind grundsätzlich sehr komplex selbst zu schreiben. In der Praxis muss man in der Regel nur online nach dem gewünschten Regex suchen, ohne die genaue Syntax zu verstehen. Um eine Zahl mit mehr als einer Ziffer herauszuholen, könnte man nach dem Regex \"\\d+\" suchen. In R muss noch ein zusätzlicher Backslash verwendet werden, wodurch wir den Ausdruck \"\\\\d+\" erhalten. Das d steht für digit (engl. für Ziffer) und das Plus für eine oder mehrere Ziffern. str_extract(char, &quot;\\\\d+&quot;) [1] &quot;28610&quot; Angenommen, die Spalten eines Datensatzes mit den Antworten eines Fragebogens starten mit \"Q\" folgend von Nummer, Namen und der genauen Beschreibung. Ein Beispiel hierfür wäre die 12. Frage zur Risikowahrnehmung mit Antwortschema in Klammern \"Q12_Risikowahrnehmung (0 = \"Trifft nicht zu\")\". Für die Auswertung möchten wir aufgrund der Leerzeichen und der redundanten Information den hinteren in Klammern geschriebenen Teil löschen. In anderen Worten soll der gesamte Spaltenname bis zum ersten Leerzeichen extrahiert werden. Ein möglicher Regex dafür wäre ([^\\\\s]+). Beachte auch in diesem Fall, dass bei jedem Backslash für einen Regex aus dem Internet innerhalb von R ein zweiter Backslash hinzugefügt werden muss. daten |&gt; rename_with( .cols = starts_with(&quot;Q&quot;) .fn = \\(x) str_extract(x, &quot;([^\\\\s]+)&quot;), ) Die Funktion str_detect() entdeckt bestimmte Buchstaben, Wörter oder ganze Regex. Dabei gibt die Funktion einen logischen Wert aus (TRUE, FALSE), wenn das Gesuchte gefunden oder nicht gefunden wurde. Das ist daher praktisch, da man diese Funktion für logische Bedingungen innerhalb von if_else(), case_when() oder filter() verwenden kann. str_detect(char, &quot;\\\\d+&quot;) [1] TRUE So ermöglicht str_detect() bspw. genauere Abfragen innerhalb von filter() (siehe Kapitel 6.3. Alle Käufer der Säge namens Häxler auszugeben, benötigt nur die Funktion filter(). umlaut |&gt; filter(Säge == &quot;Häxler&quot;) # A tibble: 1 × 2 Säge Österreich &lt;chr&gt; &lt;dbl&gt; 1 Häxler 10.4 Möchte man alle gekauften Sägen mit dem Buchstaben ä auswählen, könnte man hingegen str_detect() verwenden. umlaut |&gt; filter(str_detect(Säge, &quot;ä&quot;)) # A tibble: 1 × 2 Säge Österreich &lt;chr&gt; &lt;dbl&gt; 1 Häxler 10.4 In der Praxis müssen die Funktionen aus dem stringr Package in der Regel in Kombination mit mutate() oder rename_with() verwendet werden. Einen weiteren Anwendungsfall stellt der Umbruch langer Achsenbeschriftung durch str_wrap() bei der Erstellung von Visualisierungen dar. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 6.10 Faktoren verändern Falls du nicht mehr im Kopf hast, was genau Faktoren sind, schaue dir noch einmal Kapitel 4.3.2 an. Faktoren sind vor allem zur automatischen Erstellung von Dummy Variablen für Regressionsmodelle und das Umbenennen oder Ändern der Reihenfolge beim Erstellen von Visualisierungen nützlich. Im Folgenden schauen wir uns Beispiele an, wie man mit Funktionen aus dem forcats Package Faktoren umbenennen (fct_recode()) und deren Reihenfolge ändern (fct_relevel(), fct_reorder()) kann. Dafür verwenden wir die Spalte Gruppe aus dem big5_mod Datensatz mit den Faktorstufen (oder Level) Jung, Mittel und Weise. big5_mod |&gt; relocate(Gruppe) # A tibble: 200 × 6 Gruppe Alter Geschlecht Extraversion Neurotizismus ID &lt;fct&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; 1 Mittel 36 m 3 1.9 1 2 Jung 30 f 3.1 3.4 2 3 Jung 23 m 3.4 2.4 3 4 Weise 54 m 3.3 4.2 4 # … with 196 more rows Um die Veränderungen der Faktorstufen besser darstellen zu können, ziehen wir uns die Spalte Gruppe aus dem Datensatz heraus (siehe Kapitel 4.5). Zuvor müssen wir die Spalte allerdings noch zum Datentyp Faktor umwandeln. Dafür übergibt man der Funktion factor() den Spaltennamen sowie die Faktorstufen (levels). big5_mod &lt;- big5_mod |&gt; mutate(Gruppe = factor(Gruppe, levels = c(&quot;Jung&quot;, &quot;Mittel&quot;, &quot;Weise&quot;))) faktoren &lt;- big5_mod$Gruppe Alternativ könnte auch as.factor(Gruppe) aufgerufen werden, allerdings werden so nur bestehende Stufen zu Faktoren umgewandelt. Wenn bspw. eine Erkrankung in der eigenen Stichprobe nie vorkommt, würde das später nicht angezeigt werden. Mit dem expliziten Festlegen aller grundsätzlich möglichen Faktorstufen mithilfe des levels Arguments innerhalb von factor() würde bei weiterer Auswertung eine Häufigkeit von 0 für die fehlende Kategorie ausgegeben werden. Zum Anzeigen der Faktorstufen verwenden wir die Funktion levels(). faktoren |&gt; levels() [1] &quot;Jung&quot; &quot;Mittel&quot; &quot;Weise&quot; Dass die Reihenfolge schon der Altersreihenfolge entspricht, liegt nur daran, dass wir die Faktorstufen oben genau spezifiziert haben. Ansonsten können durchaus unerwartete Reihenfolgen der Faktorstufen auftreten. Es lohnt sich also in jedem Fall ein Blick in die Faktorstufen zu werfen, bevor man sie verwendet. Möchte man einzelne Faktoren umbenennen, verwendet man fct_recode(). faktoren |&gt; fct_recode(Alt = &quot;Weise&quot;) |&gt; levels() [1] &quot;Jung&quot; &quot;Mittel&quot; &quot;Alt&quot; Mit der Funktion fct_relevel() kann ein Faktor als erste Stufe definiert werden. faktoren |&gt; fct_relevel(&quot;Mittel&quot;) |&gt; levels() [1] &quot;Mittel&quot; &quot;Jung&quot; &quot;Weise&quot; Zum Ändern der gesamten Reihenfolge kann man beliebig viele weitere Faktorstufen der Funktion übergeben. faktoren |&gt; fct_relevel(&quot;Weise&quot;, &quot;Mittel&quot;, &quot;Jung&quot;) |&gt; levels() [1] &quot;Weise&quot; &quot;Mittel&quot; &quot;Jung&quot; In der Praxis werden sämtlich Funktion aus dem forcats Package meistens innerhalb von mutate() verwendet. So könnte man die Referenzgruppe, also die erste Faktorstufe, für die ältestes Altersgruppe festlegen. big5_mod |&gt; mutate(Gruppe = fct_relevel(Gruppe, &quot;Weise&quot;)) Wenn die Reihenfolge der Faktoren in absteigender (.desc = TRUE) oder aufsteigender (.desc = FALSE) Reihenfolge z.B. in Abhängigkeit des Mittelwertes einer anderen Spalte (wie dem Ausmaß an Extraversion) sortiert werden soll, verwendet man fct_reorder(). Dabei kann man mit dem Argument .fun die gewünschte Funktion zur Auswertung der zweiten Variable (hier Extraversion) festlegen. extraversion &lt;- big5_mod$Extraversion faktoren |&gt; fct_reorder(extraversion, .fun = mean, .desc = TRUE) |&gt; levels() [1] &quot;Mittel&quot; &quot;Jung&quot; &quot;Weise&quot; In unserem Beispiel ist die Ausprägung der Extraversion in der mittleren Altersklasse am höchsten gefolgt von der jüngsten und der ältesten. Zur Verwendung direkt am Datensatz wird auch hier der Befehl innerhalb von mutate() aufgerufen (siehe Kapitel 6.4). Die erste Spalte ist der umzugruppierende Faktor und die zweite (hier Alter) jene, nach der gereiht werden soll. big5_mod |&gt; mutate(Gruppe = fct_reorder(Gruppe, Alter, .fun = mean, .desc = FALSE)) # A tibble: 200 × 6 Alter Geschlecht Extraversion Neurotizismus Gruppe ID &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;int&gt; 1 36 m 3 1.9 Mittel 1 2 30 f 3.1 3.4 Jung 2 3 23 m 3.4 2.4 Jung 3 4 54 m 3.3 4.2 Weise 4 # … with 196 more rows Faktoren sollten erst unmittelbar vor Verwendung erstellt und verändert werden. Es kann im Umgang von Faktoren zu seltsamen Fehlermeldungen kommen, da diese innerhalb von R als Integer (Zahl) und nicht als Character (Buchstabenfolge) behandelt werden. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 6.11 Mit Zeitdaten arbeiten Für das Arbeiten mit Zeitdaten muss das lubridate Package installiert und geladen sein. library(lubridate) In Kapitel 4.3.3 wurden bereits die Datentypen POSIXct, Date und Difftime vorgestellt. Dabei ist POSIXct ein selten erwünschter Datentyp. Wir können mit mutate() in Kombination mit across() aus Kapitel 6.4.2 alle Spalten vom Datentyp POSIXct in den Datentyp Date umwandeln. daten |&gt; mutate(across(where(is.POSIXct), as.Date)) Die Funktion as.Date() stößt an ihre Grenzen, wenn das Datum nicht im Jahr-Monat-Tag Format ist (z.B. \"2002-02-15\"). Daher gibt es im lubridate Package neben ymd() (year month date) mit gleichem Anwendungsfall wie as.Date() auch noch dmy() (day month year). Möchte man nur den Tag, Monat oder das Jahr separat aus dem Datum extrahieren, können wir dies mit day(), month() und year() erreichen. daten |&gt; mutate( Birthday = ymd(Birthday), Age = 2022 - year(Birthday) ) Wenn das genaue Datum bekannt ist, können auch direkt die Daten voneinander subtrahiert werden. Dabei wird die Differenz in Tagen angegeben. Möchte man die Zeitdifferenz in Jahren angegeben haben (z.B. beim Alter), muss man durch die Funktion dyears() teilen. Als Argument wird die Anzahl an zu teilenden Jahren übergeben. Um diesen Wert beispielsweise in die vergangenen Jahre umzuwandeln, können wir durch die Funktion dyears() teilen. Als Argument können die Anzahl der Jahre übergeben werden. Äquivalent dazu können wir auch durch Monate (dmonths()) und Tage (ddays()) teilen. daten1 |&gt; mutate( Alter_Diagnose = (ymd(Erstdiagnose) - ymd(Geburtsdatum)) / dyears(1), OS_zeit = ymd(OS_datum) - ymd(Erstdiagnose), ) Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 6.12 Binäre Antwortmatrix erstellen Im Kontext von Fragebögen ist man häufig an richtiger oder falscher Beantwortung der ProbandInnen interessiert. Mit data_binary() aus dem remp Package kann man den Datensatz in die gewünschte binäre Antwortmatrix umwandeln. Für jede Frage pro Person wird also zurückgegeben, ob das Item richtig (1) oder falsch (0) beantwortet wurde. Exemplarisch nehmen wir die ersten drei Spalten zur Offenheit für neue Erfahrungen aus dem big5 Datensatz. df2 &lt;- big5 |&gt; select(O1:O3) df2 # A tibble: 200 × 3 O1 O2 O3 &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 5 1 5 2 5 3 5 3 3 3 5 4 2 5 3 # … with 196 more rows Stell dir vor, bei Frage 1 ist die Antwort 3 richtig, bei Frage 2 die Antwort 2 und bei Item 3 die Antwort 4. Dann würden diese richtigen Antworten dem answers Argument kombiniert übergeben werden. df2 |&gt; data_binary(answers = c(4, 1, 5)) # A tibble: 200 × 3 O1 O2 O3 &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 0 1 1 2 0 0 1 3 0 0 1 4 0 0 0 # … with 196 more rows "],["descr.html", "Kapitel 7 Deskriptive Statistik 7.1 Lagemaße und Streuungsmaße 7.2 Häufigkeiten und Kontingenztafeln 7.3 Zusammenhangsmaße", " Kapitel 7 Deskriptive Statistik Die beschreibende Statistik bietet neben Informationen über die Verteilungen und Zusammenhänge der interessierenden Merkmale ebenfalls die Möglichkeit, unplausible Werte zu identifizieren, die mit den im vorherigen Kapitel gelernten Methoden entfernt oder korrigiert werden müssen. Die Angabe der in diesem Kapitel eingeführten Lage- und Streuungsmaße, Häufigkeiten und Zusammenhangsmaße dürfen in keiner wissenschaftlichen Arbeit fehlen. 7.1 Lagemaße und Streuungsmaße Wir werden in diesem Kapitel den big5_mod Datensatz ohne die Spalte namens ID verwenden und bezeichnen diesen als big5_mod1. big5_mod1 &lt;- big5_mod |&gt; select(-ID) big5_mod1 # A tibble: 200 × 5 Alter Geschlecht Extraversion Neurotizismus Gruppe &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; 1 36 m 3 1.9 Mittel 2 30 f 3.1 3.4 Jung 3 23 m 3.4 2.4 Jung 4 54 m 3.3 4.2 Weise # … with 196 more rows Einen ersten Überblick über die Daten können wir mit der direkt in R integrierten Funktion summary() erhalten, der wir lediglich den Namen des Datensatzes übergeben müssen. summary(big5_mod1) Alter Geschlecht Extraversion Neurotizismus Gruppe Min. :13.00 Length:200 Min. :2.300 Min. :1.400 Jung :147 1st Qu.:18.75 Class :character 1st Qu.:2.800 1st Qu.:2.700 Mittel: 39 Median :23.00 Mode :character Median :3.000 Median :3.100 Weise : 14 Mean :26.48 Mean :3.076 Mean :3.133 3rd Qu.:31.25 3rd Qu.:3.300 3rd Qu.:3.600 Max. :60.00 Max. :4.300 Max. :4.600 Hier sehen wir einen Vorteil von Faktoren. Während wir die Häufigkeiten der Altersgruppe ausgegeben bekommen, kann R für die Spalte mit Geschlecht lediglich die Anzahl an Character Werten zählen. Für weitere Informationen über Faktoren und deren Umgang schaue dir erneut Kapitel 4.3.2 und 6.10 an. Falls wir gruppierte Lage- und Streuungsmaße erhalten oder andere Werte wie den Standardfehler ausrechnen möchten, müssen wir auf die summarise() Funktion aus dem Package dplyr (enthalten im tidyverse) zurückgreifen. Auch hier werden wir einzelne Befehle mit der Pipe (|&gt;) aneinanderketten (siehe Kapitel 6.1). Exemplarisch soll zunächst der Mittelwert mit der Funktion mean() und die Standardabweichung mit sd() berechnet werden. Beide Funktionen müssen wir dabei innerhalb der Funktion summarise() verwenden. Auf der linken Seite des Gleichheitszeichens stehen auch hier wieder die Namen der neu erstellten Spalten. big5_mod1 |&gt; summarise( M = mean(Extraversion), SD = sd(Extraversion) ) # A tibble: 1 × 2 M SD &lt;dbl&gt; &lt;dbl&gt; 1 3.08 0.347 Zum Gruppieren der Variablen wird die Funktion group_by() verwendet. big5_mod1 |&gt; group_by(Geschlecht) |&gt; summarise( M = mean(Extraversion), SD = sd(Extraversion) ) # A tibble: 2 × 3 Geschlecht M SD &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; 1 f 3.05 0.358 2 m 3.11 0.328 Dabei können der Funktion beliebig viele Spalten übergeben werden. So könnte man bspw. nicht nur nach Geschlecht, sondern auch nach der Altersgruppe gruppieren. big5_mod1 |&gt; group_by(Geschlecht, Gruppe) |&gt; summarise( M = mean(Extraversion), SD = sd(Extraversion) ) # A tibble: 6 × 4 # Groups: Geschlecht [2] Geschlecht Gruppe M SD &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; 1 f Jung 3.07 0.373 2 f Mittel 3.07 0.299 3 f Weise 2.83 0.269 4 m Jung 3.12 0.324 # … with 2 more rows Alternativ können wir zum Gruppieren anstelle von group_by() auch das Argument .by hinzufügen. Während der Datensatz nach group_by() gruppiert ist, was bei weiterer Verwendung mit ungroup() aufgelöst werden müsste, gruppiert das .by Argument nur einmalig. Das Argument kann auch mit der in Kapitel 6.4 kennengelernten Funktion mutate() verwendet werden. Da die Ausgabe von summarise() in der Regel bereits ein Endergebnis darstellt, ist die Wahl zwischen group_by() oder .by größtenteils abhängig von persönlicher Präferenz. big5_mod1 |&gt; summarise( M = mean(Extraversion), SD = sd(Extraversion), .by = c(Geschlecht, Gruppe) ) # A tibble: 6 × 4 Geschlecht Gruppe M SD &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; 1 m Mittel 3.13 0.281 2 f Jung 3.07 0.373 3 m Jung 3.12 0.324 4 m Weise 2.96 0.546 # … with 2 more rows Neben der Funktionen für den Mittelwert und der Standardabweichung gibt es noch diverse weitere: n() für die Anzahl an Beobachtungen, min() und max() für Minimum und Maximum, var() für die Varianz, sqrt() für die Quadratwurzel, median() für den Median und quantile() zur Berechnung der jeweiligen Quantile. Für die Berechnung des Standardfehlers teilen wir direkt innerhalb des Funktionsaufrufes die Standardabweichung durch die Wurzel aus der Anzahl der Personen. big5_mod1 |&gt; summarise( N = n(), Min = min(Alter), Mean = mean(Alter), Median = median(Alter), Max = max(Alter), SD = sd(Alter), SE = SD / sqrt(N) ) Grundsätzlich kann jede Funktion summarise() übergeben werden, die einen einzelnen Wert berechnet. Somit unterscheidet sich die Anwendung maßgeblich vom bereits kennengelernten mutate(). Dort musste die Ausgabe immer eine Reihe von Werten umfassen, die der Anzahl der Zeilen im Datensatz entspricht. Auch hier können wir mehrere Spalten gleichzeitig mithilfe von across() auswerten (siehe Kapitel 6.4.2). Die Syntax ändert sich in dem Fall im Vergleich zu vorher. Hier müssen wir die verschiedenen Funktionen mit entsprechendem Namen innerhalb einer Liste übergeben. Listen als solche werden erst später eingeführt und müssen uns an dieser Stelle nicht weiter interessieren (siehe Kapitel 11.4). big5_mod1 |&gt; summarise(across( .cols = Extraversion:Neurotizismus, .fns = list(M = mean, SD = sd)) ) # A tibble: 1 × 4 Extraversion_M Extraversion_SD Neurotizismus_M Neurotizismus_SD &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 3.08 0.347 3.13 0.682 Bei vielen Lagemaßen kann es schnell umständlich werden, jede einzeln aufzurufen. Wenn man keine Lust hat, dies jedes Mal manuell abzutippen, kann man auch direkt vereinfachte Funktionen zur deskriptiven Statistik verwenden. Das remp Package bietet die Funktion descriptive() an. Dieser muss man kein weiteres Argument übergeben. Es wird die Anzahl, das Minimum, das erste Quartil, der Mittelwert, der Median, das zweite Quartil, die Standardabweichung und der Standardfehler für sämtliche numerische Spalten zurückgegeben. Alle anderen Datentypen werden von dieser Funktion ignoriert. big5_mod1 |&gt; descriptive() # A tibble: 3 × 10 Variable N Min Q1 Mean Median Q3 Max SD SE &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Alter 200 13 18.8 26.5 23 31.2 60 11.4 0.8 2 Extraversion 200 2.3 2.8 3.08 3 3.3 4.3 0.35 0.02 3 Neurotizismus 200 1.4 2.7 3.13 3.1 3.6 4.6 0.68 0.05 Auch hier können wir die Berechnungen auf dieselbe Art und Weise gruppieren. big5_mod1 |&gt; group_by(Geschlecht) |&gt; descriptive() Alternativen für einen schnellen Überblick bieten beispielsweise auch das skimr Package mit der Funktion skim() oder describe() aus dem psych Package. Beide können auch nicht-numerische Spalten auswerten und erstere gibt zu jeder Spalte sogar ein kleines Histogramm aus. Wie dir vielleicht bereits aufgefallen ist, sieht die Ausgabe von descriptive() anders aus als die von summarise(). Während erstere die Variablen untereinander in unterschiedliche Zeilen übersichtlich auflistet, fügt summarise() die Ergebnisse spaltenweise hinzu. Wenn wir denselben Output wie in descriptive() erreichen möchten, müssen wir zuerst den Datensatz in ein langes Format bringen (siehe Kapitel 6.6). Nun gruppieren wir nach der neuen Spalte namens Variable. Anschließend können wir wie gewohnt mit summarise() die deskriptiven Statistiken berechnen. Nichts anderes macht die Funktion descriptive() hinter den Kulissen. big5_mod1 |&gt; pivot_longer( cols = c(Alter, Extraversion, Neurotizismus), names_to = &quot;Variable&quot;, values_to = &quot;Wert&quot; ) |&gt; group_by(Variable) |&gt; summarise( Q1 = quantile(Wert, 0.25), Mean = mean(Wert), Q3 = quantile(Wert, 0.75), Schiefe = skewness(Wert), Kurtosis = kurtosis(Wert) ) # A tibble: 3 × 6 Variable Q1 Mean Q3 Schiefe Kurtosis &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Alter 18.8 26.5 31.2 1.34 3.97 2 Extraversion 2.8 3.08 3.3 0.761 3.95 3 Neurotizismus 2.7 3.13 3.6 -0.132 2.56 Beachte an dieser Stelle, dass für die Funktionen skewness() und kurtosis() das moments Package installiert und geladen sein muss. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 7.2 Häufigkeiten und Kontingenztafeln Eine Möglichkeit Häufigkeiten zu zählen, haben wir bereits mit n() innerhalb von summarise() kennengelernt. Eine Alternative stellt die count() Funktion aus selbigem Package dar. Hier können wir uns group_by() sparen und stattdessen die gruppierenden Spalten direkt in count() schreiben. big5_mod |&gt; count(Geschlecht) # A tibble: 2 × 2 Geschlecht n &lt;chr&gt; &lt;int&gt; 1 f 118 2 m 82 Dabei können beliebig viele Spalten übergeben werden. Um die höchste Anzahl zu Beginn auszugeben, würden wir zusätzlich das sort Argument auf TRUE setzen. big5_mod |&gt; count(Geschlecht, Gruppe, sort = TRUE) # A tibble: 6 × 3 Geschlecht Gruppe n &lt;chr&gt; &lt;fct&gt; &lt;int&gt; 1 f Jung 89 2 m Jung 58 3 f Mittel 20 4 m Mittel 19 # … with 2 more rows Zum Darstellen der Anteile der jeweiligen Gruppen, müssen wir innerhalb von mutate() die einzelnen Häufigkeiten durch Anzahl in der jeweiligen Gruppe teilen (siehe Kapitel 6.4). big5_mod |&gt; count(Geschlecht, Gruppe) |&gt; mutate(Prop = n / sum(n)) # A tibble: 6 × 4 Geschlecht Gruppe n Prop &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; 1 f Jung 89 0.445 2 f Mittel 20 0.1 3 f Weise 9 0.045 4 m Jung 58 0.29 5 m Mittel 19 0.095 6 m Weise 5 0.025 Hier werden die Verhältnisse über alle Häufigkeiten berechnet, da count() keinen gruppierten Datensatz zurückgibt. Sollen die Häufigkeiten innerhalb einer Gruppe berechnet werden, muss zusätzlich mithilfe von group_by() explizit neu gruppiert werden. big5_mod |&gt; count(Geschlecht, Gruppe) |&gt; group_by(Geschlecht) |&gt; mutate(Prop = n / sum(n)) |&gt; ungroup() # A tibble: 6 × 4 Geschlecht Gruppe n Prop &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; 1 f Jung 89 0.754 2 f Mittel 20 0.169 3 f Weise 9 0.0763 4 m Jung 58 0.707 5 m Mittel 19 0.232 6 m Weise 5 0.0610 Für die Erstellung von Kontingenztafeln, die wir mit statistischen Tests auswerten können, benötigen wir allerdings eine andere Funktion namens table(). Damit können wir ähnlich wie mit count() die Häufigkeiten kategorialer Merkmale abbilden. Die Werte müssen dabei als Wertereihe (bzw. Vektor) mit dem Dollar-Operator aus dem Datensatz extrahiert werden (siehe Kapitel 4.5). table(big5_mod$Geschlecht) f m 118 82 Zur Erstellung einer klassischen Vierfeldertafel wird eine zusätzliche Variable in die Funktion geschrieben. Wenn wir also untersuchen möchten, ob es Unterschiede in der Häufigkeit extrovertierter Menschen zwischen den Geschlechtern gibt, wählen wir erst die Spalte Extraversion des Datensatzes big5_mod und anschließend die Spalte Geschlecht. Beachte die logische Abfrage bei der Extraversion: wenn Extraversion größer als 3 ist, wird eine 1 und ansonsten eine 0 zurückgegeben. tb &lt;- table(big5_mod$Extraversion &gt; 3, big5_mod$Geschlecht) tb f m FALSE 66 43 TRUE 52 39 Es können beliebig viele Häufigkeiten von Merkmalen miteinander in Beziehung gesetzt werden. Allerdings sind mehr als drei Dimensionen nur selten sinnvoll zu interpretieren. table(big5_mod$Extraversion &gt; 3, big5_mod$Geschlecht, big5_mod$Neurotizismus &gt; 3.5) , , = FALSE f m FALSE 47 39 TRUE 33 23 , , = TRUE f m FALSE 19 4 TRUE 19 16 Nach Erstellen der Kontingenztafeln mithilfe von table() können die Verhältnisse der Merkmale mit der Funktion prop.table() ausgegeben werden. Dies stellt eine Alternative zur bereits kennengelernten Kombination aus count() und mutate() dar. prop.table(tb) f m FALSE 0.330 0.215 TRUE 0.260 0.195 Der Vorteil ist hier, dass wir zusätzlich bestimmen können, ob wir auf die Zeilen oder Spalten bedingen möchten. Zum Konditionieren auf die Zeilen, muss nur eine 1 hinzugefügt werden. prop.table(tb, 1) f m FALSE 0.6055046 0.3944954 TRUE 0.5714286 0.4285714 Äquivalent dazu wird mit einer zusätzlichen 2 auf die Spalten bedingt. prop.table(tb, 2) f m FALSE 0.5593220 0.5243902 TRUE 0.4406780 0.4756098 Möchte man die Kontingenztafel für jede Spalte ausgeben lassen, kann table() ohne Klammern in der Funktion map() genutzt werden. Diese wendet table() auf jeden Spalte der Reihe nach an und speichert diese in Form einer Liste ab. big5_mod |&gt; map(table) Zur besseren Übersicht schalten wir an dieser Stelle noch ein select() davor, um nur das Geschlecht und die Altersgruppe auszuwählen. Wir könnten aber auf dieselbe Art und Weise sämtlich Spalten in einer Kontingenztafel ausgeben lassen. big5_mod |&gt; select(Geschlecht, Gruppe) |&gt; map(table) $Geschlecht f m 118 82 $Gruppe Jung Mittel Weise 147 39 14 So können auch alle Verhältnisse ausgegeben werden. big5_mod |&gt; select(Geschlecht, Gruppe) |&gt; map(table) |&gt; map(prop.table) $Geschlecht f m 0.59 0.41 $Gruppe Jung Mittel Weise 0.735 0.195 0.070 Diese Art des wiederholten Berechnens einer Funktion wird in Kapitel 12 genauer erläutert. Vom Prinzip her ist die Anwendung von map() in diesem Fall wie das Nutzen von across() innerhalb von mutate() (siehe Kapitel 6.4.2). Allerdings muss die Ausgabe in mutate() oder auch in summarise() das gleiche Format für alle Spalten haben. Wenn wir Kontingenztafeln mit unterschiedlich vielen Kategorien in den jeweiligen Spalten erstellen, ist diese Bedingung jedoch nicht erfüllt. Daher müssen wir in diesem Fall auf map() zurückgreifen. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 7.3 Zusammenhangsmaße Zwei der wichtigsten Zusammenhangsmaße sind die Kovarianz und die darauf basierende Korrelation. Eine Korrelation berechnen wir mit der cor() Funktion, welche standardmäßig die Produkt-Moment-Korrelation berechnet. cor(big5_mod$Extraversion, big5_mod$Neurotizismus) [1] 0.06972529 Für die Rangkorrelation nach Spearman oder die Kendall-Tau Korrelation muss das Argument method auf \"spearman\" oder kendall gesetzt werden. cor(big5_mod$Extraversion, big5_mod$Neurotizismus, method = &quot;spearman&quot;) [1] 0.04874732 Um mehrere Korrelationen auf einmal zu berechnen, übergeben wir der Funktion cor() mehr als zwei Spalten. Dabei können wir der Funktion grundsätzlich unbegrenzt viele numerische Spalten übergeben. Erst wählen wir die gewünschten Spalten aus und bezeichnen das Zwischenergebnis als big5_mod2. big5_mod2 &lt;- big5_mod |&gt; select(Alter, Extraversion, Neurotizismus) Diesen Datensatz mit ausschließlich numerischen Spalten übergeben wir dann der Funktion cor(). cor(big5_mod2) Alter Extraversion Neurotizismus Alter 1.0000000 -0.12250136 -0.23019948 Extraversion -0.1225014 1.00000000 0.06972529 Neurotizismus -0.2301995 0.06972529 1.00000000 Auf dieselbe Art und Weise kann die Kovarianz mithilfe der Funktion cov() berechnet werden. cov(big5_mod2) Alter Extraversion Neurotizismus Alter 128.8837940 -0.48201005 -1.78158291 Extraversion -0.4820101 0.12012462 0.01647437 Neurotizismus -1.7815829 0.01647437 0.46473467 Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). "],["visual.html", "Kapitel 8 Visualisierungen 8.1 Einführung 8.2 Histogramm und Dichte 8.3 Streudiagramm 8.4 Boxplot 8.5 Violin Plot 8.6 Balkendiagramm 8.7 Liniendiagramm 8.8 Quantil-Quantil Plot 8.9 Mehrfaktorielle Abbildungen 8.10 Anpassen des Aussehens 8.11 Anordnen mehrerer Graphen 8.12 Speichern von Abbildungen 8.13 Exemplarische Erweiterungen 8.14 Anwendungsbeispiel", " Kapitel 8 Visualisierungen Eine der informativsten und zugänglichsten Form der Darstellung von Unterschieden oder Zusammenhängen ist ein Diagramm. Optisch ansprechende Abbildungen zu erstellen, die dann auch noch für wissenschaftliche Publikationen geeignet sind, war bisher allerdings oftmals ein Krampf. Innerhalb dieses Kapitels wird ein konsistentes Schema zur Erstellung und Anpassung einfacher bis komplexer Abbildungen verschiedener Art vorgestellt und an vielen praktischen Beispielen gefestigt. 8.1 Einführung Mit R können komplexe und dabei optisch ansprechende Abbildungen erstellt werden, die durch die umfangreichen Anpassungsmöglichkeiten gleichermaßen für wissenschaftlichen Publikationen oder in Unternehmen verwendet werden. Durch das Package ggplot können auf konsistente Art und Weise Histogramme, Streudiagramme, Boxplots, Balkendiagramme, Liniendiagramme und viele mehr erstellt werden. Die zwei g des im tidyverse enthaltenen Packages ggplot stehen für grammar of graphics, was frei als Grammatik der Abbildungen übersetzt werden kann. Für alle Unterkapitel muss folglich das tidyverse installiert und geladen sein. library(tidyverse) Wir werden auch hier mit der leicht modifizierten Variante des Big Five Datensatzes arbeiten. big5_mod # A tibble: 200 × 6 Alter Geschlecht Extraversion Neurotizismus Gruppe ID &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;int&gt; 1 36 m 3 1.9 Mittel 1 2 30 f 3.1 3.4 Jung 2 3 23 m 3.4 2.4 Jung 3 4 54 m 3.3 4.2 Weise 4 # … with 196 more rows In Abbildung 8.1 sind die grundsätzlichen Komponenten einer ggplot Abbildung links und je ein entsprechendes Beispiel rechts abgebildet. Jeder ggplot besteht aus verschiedenen Layern, die untereinander gelegt werden. Um eine Abbildung zu erstellen, muss auf jeden Fall Data, Aestetics und Geometries vorhanden sein. Die Layer namens Scales und Theme sind hingegen optional und passen lediglich das Erscheinungsbild an. Wir werden uns in Kapitel 8.2 bis 8.8 die verschiedenen Geometries Layer anschauen. Erst in Kapitel 8.10 werden die Anpassungsmöglichkeiten mithilfe der Scales und Theme Layer umfangreich erklärt. Abbildung 8.1: Vereinfachte Anordnung der Layer im Rahmen der Grammar of Graphics mit Beispielen. Es ist wichtig zu verstehen, dass die Layer untereinander gelegt werden und man am Ende von unten auf die kreierte Abbildung schaut. Wenn man bspw. mehrere Geometries hintereinander in einen Plot einbaut, kann der zuletzt hinzugefügte den vorherigen vollständig oder teilweise überdecken. Bleiben wir bei dem Beispiel der Erstellung eines Histogramms aus Abbildung 8.1. ggplot(data = big5_mod, mapping = aes(x = Extraversion)) + geom_histogram() Innerhalb der Funktion ggplot() wird dem data Argument der Datensatz big5_mod übergeben. Aus diesem Datensatz möchten wir die Spalte Extraversion auf der x-Achse abbilden. Die ersten beiden Layer sind somit bereits vorhanden. Der Aesthetics Layer wird durch das mapping Argument hinzugefügt. Allerdings können wir die Spalte nicht einfach mit x = Extraversion hinzufügen, sondern benötigen die Helferfunktion aes(), der wir unsere Spalte übergeben. Dabei steht aes() für aesthetics (engl. für Ästhetik). Neben der Spalte, die auf der x-Achse abgebildet werden soll, kann auf dieselbe Art und Weise die y-Achse definiert werden. Welche Variable dabei auf welcher Achse angezeigt werden soll, kann von dir frei entschieden werden. Auch Argumente zur Veränderung des Aussehens wie color (Außenfarbe) oder fill (Füllfarbe) können hier innerhalb von aes() der Funktion ggplot übergeben werden. Der eigentliche Graph wird erst mit den geom_*() Funktionen hinzugefügt (z.B. geom_histogram()). Das Präfix geom ist dabei für jeden Geometry Layer derselbe. Wichtig ist an dieser Stelle noch das Pluszeichen (+), welches sämtliche Layer zusammenbindet und untereinander verbindet. Dies unterscheidet sich grundlegend von den restlichen Funktion innerhalb des tidyverse, die mithilfe der Pipe (|&gt;) kombiniert werden (siehe Kapitel 6). Im Gegensatz zu anderen Funktionen innerhalb des tidyverse können Funktionen aus dem Package ggplot2 nicht mit einer Pipe aneinander gebunden werden. Das hat ausschließlich historische Gründe, da zu der Zeit der Erstellung von ggplot2 die Pipe noch nicht existiert hat. Dies wird sich in Zukunft voraussichtlich auch nicht mehr ändern. Schauen wir uns die einzelnen Befehle einmal genauer an. Der Data Layer kreiert nur eine leere Fläche (siehe Abbildung 8.2 (a)). ggplot(data = big5_mod) Durch das Hinzufügen des Aesthetics Layers wird ein Raster angefertigt und die x-Achse mit der gewünschten Spalte Extraversion beschriftet (siehe Abbildung 8.2 (b)). Allerdings werden noch immer keine Werte angezeigt, da wir dafür den Geometry Layer benötigen. ggplot(data = big5_mod, mapping = aes(x = Extraversion)) Die meisten Funktionen des Geometry Layers beginnen mit dem Präfix geom_ und enden mit dem Namen der Abbildungsart (z.B. geom_histogram() für Histogramme oder geom_boxplot() für Boxplots). Das Ergebnis ist in Abbildung 8.2 (c)) illustriert. ggplot(data = big5_mod, mapping = aes(x = Extraversion)) + geom_histogram() Abbildung 8.2: (a) Nur Data Layer (b) Data und Aesthetics Layer und (c) Data, Aesthetics und Geometry Layer. Die beiden Namen der Argumente data und mapping schreiben wir im Folgenden nicht mehr explizit aus, weil die Reihenfolge dieser Argumente im Verlaufe des Buches dieselbe ist und es ohne übersichtlicher ist. Da das standardmäßige Aussehen mit dem hellgrauen Hintergrund in dieser Form nicht für wissenschaftliche Publikationen geeignet ist, werden wir in Kapitel 8.10 die notwendigen Anpassungsmöglichkeiten besprechen. 8.2 Histogramm und Dichte Das Histogramm wurde exemplarisch bereits zur Erklärung des Aufbau eines ggplots in der Einführung beschrieben. Histogramme verwendet man zur Abbildung von Häufigkeitsverteilungen kontinuierlicher Variablen. Zur Erstellung eines Histograms in R bedarf es nur der Zuweisung der interessierenden Variable für die x-Achse, da auf der y-Achse die Häufigkeiten dargestellt werden. ggplot(big5_mod, aes(x = Extraversion)) + geom_histogram() Für ein schlichteres Aussehen fügen wir in Abbildung 8.3 (b) noch eine schwarze Rahmenfarbe mit dem color Argument und eine weiße Füllungsfarbe mit fill hinzu (siehe Kapitel 8.10.1). Histogramme sind allerdings maßgeblich von der gewählten Breite der Balken abhängig. Bei zu wenigen Balken können Informationen der Verteilung verloren gehen, bei zu vielen hingegen irrelevante Trends erscheinen. Dieses kann entweder direkt mit der Anzahl der Balken (bins Argument) oder mit der Breite (binwidth Argument) verändert werden. Wir werden hier das Argument binwidth verwenden, da diesem auch eine Funktion übergeben werden kann. ggplot(big5_mod, aes(x = Extraversion)) + geom_histogram( color = &quot;black&quot;, fill = &quot;white&quot;, binwidth = 0.2 ) Abbildung 8.3: Histogramme im Vergleich. Es gibt verschiedene Arten, eine möglichst optimale binwidth herauszufinden. Exemplarisch sei hier die Freedman-Diaconis Regel angewandt. Diese können wir mithilfe einer neuen anonymen Funktion dem binwidth Argument übergeben (siehe Kapitel 6.4.4). Das Ergebnis ist in Abbildung 8.4 (a) gezeigt. ggplot(big5_mod, aes(x = Extraversion)) + geom_histogram( color = &quot;black&quot;, fill = &quot;white&quot;, binwidth = \\(x) (max(x) - min(x)) / nclass.FD(x) ) Eine weitere Möglichkeit, die Verteilung der Extraversion unserer Population darzustellen, ist die Wahrscheinlichkeitsdichte. Dazu müssen wir lediglich das Suffix des Geometry Layers zu density (engl. für Dichte) verändern (siehe Abbildung 8.4 (b)). ggplot(big5_mod, aes(x = Extraversion)) + geom_density() Um das Histogramm gemeinsam mit der Wahrscheinlichkeitsdichte abzubilden, müssen sich beide auf derselben Skala befinden. Zum Beispiel könnte man die Häufigkeiten des Histogramms ebenfalls als Dichte ausdrücken. Dafür muss dem height und y Argument jeweils die berechnete Dichte (density) übergeben werden. Diese wird mithilfe der Helferfunktion after_stat() berechnet. Anschließend muss lediglich mit einem weiteren Pluszeichen die Dichtefunktion hinzugefügt werden. Für eine ansprechendere optische Darstellung sei eine graue Füllfarbe ergänzt, welche mithilfe des alpha Argument etwas durchsichtig wird. Das Ergebnis kann in Abbildung 8.4 (c) betrachtet werden. ggplot(big5_mod, aes(x = Extraversion, height = after_stat(density))) + geom_histogram( mapping = aes(y = after_stat(density)), binwidth = 0.2, color = &quot;black&quot;, fill = &quot;white&quot; ) + geom_density(fill = &quot;grey&quot;, alpha = 0.7) Abbildung 8.4: Histogramm und Wahrscheinlichkeitsdichte separat und kombiniert. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 8.3 Streudiagramm Das Erstellen eines Streudiagramms in R benötigt das Festlegen der x-Achse und y-Achse (auch Punktdiagramm oder Scatter Plot genannt). Im Vergleich zum bereits kennengelernten Histogramm ändert sich sonst nur der Geometry Layer zu geom_point(). Exemplarisch sei hier die mittlere Extraversion gegen das Lebensalter in Jahren aufgetragen (siehe Abbildung 8.5 (a)). Auf weitere Parameter wie das Ändern der Farbe (color) oder Form (shape) verzichten wir an dieser Stelle. ggplot(big5_mod, aes(x = Extraversion, y = Alter)) + geom_point() Bei größeren Datensätzen kann es passieren, dass die Punkte sich überlappen. Um das zu verhindern, kann die Position zu jitter verändert werden. Dies bewirkt eine leichte zufällige Variation jedes Datenpunktes (siehe Abbildung 8.5 (b)). ggplot(big5_mod, aes(x = Extraversion, y = Alter)) + geom_point(position = &quot;jitter&quot;) Mit geom_smooth() wird eine am besten passende Linie durch die Punkte gezogen. Wir entscheiden uns an dieser Stelle für eine lineare Regressionsgeraden (method = lm). Außerdem färben wir die Gerade schwarz und fügen ein 95%iges Konfidenzintervall mit se = TRUE hinzu. Damit die Regressionsgerade nicht nur in dem Bereich, in dem Daten beobachtet wurden, abgebildet wird, kann zusätzlich das fullrange Argument auf TRUE gesetzt werden. Um den Effekt dieser Funktion zu illustrieren, greifen wir etwas voraus und definieren mit xlim(c(2, 5)) die untere Grenze der x-Achse mit 2 und die obere mit 5 (siehe Abbildung 8.5 (c)). ggplot(big5_mod, aes(x = Extraversion, y = Alter)) + geom_point(position = &quot;jitter&quot;) + geom_smooth( color = &quot;black&quot;, method = lm, se = TRUE, fullrange = TRUE ) + xlim(c(2, 5)) Abbildung 8.5: Streudiagramm mit und ohne Regressionsgerade. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 8.4 Boxplot Würde man nur einen Boxplot für die mittlere Ausprägung von Extraversion erstellen wollen, könnte man dies genau wie in den beiden zuvor besprochenen Kapiteln durch das Auswechseln des Geometry Layers mit geom_boxplot() erreichen (siehe Abbildung 8.6 (a)). ggplot(big5_mod, aes(y = Extraversion)) + geom_boxplot() Dies stellt allerdings eine seltene Situation dar. Meistens ist man am Vergleich mehrerer Variablen interessiert, die auf der x-Achse aufgetragen werden. An dieser Stelle sollen die Verteilungen von Extraversion und Neurotizismus miteinander verglichen werden. Um dies zu erreichen, müssen wir den Datensatz vom breiten ins lange Datenformat transformieren (siehe Kapitel 6.6). Dafür wird die Funktion pivot_longer() verwendet. big5_long &lt;- big5_mod |&gt; pivot_longer( cols = Extraversion:Neurotizismus, names_to = &quot;Faktor&quot;, values_to = &quot;Auspraegung&quot; ) big5_long # A tibble: 400 × 7 Alter Geschlecht Gruppe ID Faktor Auspraegung Zeitpunkt &lt;dbl&gt; &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; 1 36 m Mittel 1 Extraversion 3 T1 2 36 m Mittel 1 Neurotizismus 1.9 T1 3 30 f Jung 2 Extraversion 3.1 T1 4 30 f Jung 2 Neurotizismus 3.4 T1 # … with 396 more rows Nach der Umwandlung sind in big5_long die Persönlichkeitsfaktoren in der Spalte Faktor und die Extraversions- und Neurotizismusausprägung in der Spalte Auspraegung. Einen Boxplot erstellt man mit geom_boxplot(). Auf der x-Achse möchten wir die Persönlichkeitsfaktoren und auf der y-Achse die mittleren Ausprägungen darstellen (siehe Abbildung 8.6 (b)). ggplot(big5_long, aes(x = Faktor, y = Auspraegung)) + geom_boxplot() Um zusätzlich Fehlerbalken zu erhalten, müssen diese mit stat_boxplot() berechnet werden. Das Argument geom muss auf \"errorbar\" (engl. für Fehlerbalken) gesetzt werden. Die Breite des Fehlerbalkens kann durch das optionale Argument width kontrolliert werden. Zum Ausblenden der Ausreißer setzt man innerhalb von geom_boxplot() die outlier.shape auf NA (Akronym für Not Available, engl. für nicht vorhanden). Das Ergebnis ist in Abbildung 8.6 (c) illustriert. ggplot(big5_long, aes(x = Faktor, y = Auspraegung)) + stat_boxplot(geom = &quot;errorbar&quot;, width = 0.4) + geom_boxplot(outlier.shape = NA) Abbildung 8.6: Boxplots im Vergleich. Beim Hinzufügen von Fehlerbalken ist die Reihenfolge der Funktionsaufrufe entscheidend, da die verschiedenen Layer untereinander gezeichnet werden. Würden wir also zunächst geom_boxplot() und erst anschließend stat_boxplot() zum ggplot hinzufügen, würde die Linie des Fehlerbalkens über dem Boxplot abgebildet werden. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 8.5 Violin Plot Im Vergleich zu Boxplots ändert sich zum einen der Geometry Layer, welcher nun geom_violin() heißt und zum anderen muss noch eine willkürliche Koordinate für die x-Achse gewählt werden (hier 0) (siehe Abbildung 8.7 (a)). ggplot(big5_mod, aes(x = 0, y = Extraversion)) + geom_violin() Für mehrere Violin Plots nutzen wir genau wie zuvor bei den Boxplots den Datensatz im langen Datenformat namens big5_long (siehe Kapitel 8.4 und 6.6). Auch hier werden auf der x-Achse die Persönlichkeitsfaktoren und auf der y-Achse die jeweilige Ausprägung ausgegeben (siehe Abbildung 8.7 (b)). ggplot(big5_long, aes(x = Faktor, y = Auspraegung)) + geom_violin() Optional kann zusätzlich das Argument trim auf FALSE gesetzt werden, um das Abschneiden der Enden des Violin Plots zu verhindern. Mithilfe des Arguments draw_quantiles können wir explizit beliebige Quantile (hier Quartile) einzeichnen lassen. Das Ergebnis ist in Abbildung 8.7 (c) zu sehen. ggplot(big5_long, aes(x = Faktor, y = Auspraegung)) + geom_violin( trim = FALSE, draw_quantiles = c(0.25, 0.5, 0.75) ) Abbildung 8.7: Violin Plots im Vergleich. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 8.6 Balkendiagramm In einem Balkendiagramm werden im Regelfall entweder Häufigkeiten oder Mittelwerte miteinander verglichen (auch Säulendiagramm oder Barplot genannt). Zum Darstellen absoluter Häufigkeiten kategorealer Variablen wird die Funktion geom_bar() verwendet. Wir können dabei frei entscheiden, ob die Balken vertikal oder horizontal angeordnet werden sollen. Für eine vertikale Illustration auf der x-Achse übergeben wir die Spalte Geschlecht dem x Argument (siehe Abbildung 8.8) (a)). ggplot(big5_mod, aes(x = Geschlecht)) + geom_bar() Äquivalent dazu können wir horizontale Balkendiagramme durch Abbildung der entsprechenden Spalte auf der y-Achse mit dem y Argument erstellen (siehe Abbildung 8.8) (b)). ggplot(big5_mod, aes(y = Geschlecht)) + geom_bar() Anstelle von absoluten Häufigkeiten können ebenfalls relative Häufigkeiten verglichen werden. Hierzu müssen wir innerhalb der Helferfunktion after_stat() das Argument prop übergeben und zeitgleich das group Argument auf 1 setzen (siehe Abbildung 8.8) (c)). Diese Helferfunktion haben wir bereits im Kontext der Histogramme in Kapitel 8.2 kennengelernt. ggplot(big5_mod, aes(x = Geschlecht, y = after_stat(prop), group = 1)) + geom_bar() Möchten wir Mittelwerte miteinander vergleichen, müssen wir auf die Funktion geom_col() zurückgreifen. Beim Gegenüberstellen mehrerer Merkmale, wird zunächst, wie bereits in den Kapiteln 8.4 und 8.5 bei den Boxplots und Violin Plots kennengelernt, der Datensatz in ein langes Format gebracht (siehe Kapitel 6.6). big5_long &lt;- big5_mod |&gt; pivot_longer( cols = Extraversion:Neurotizismus, names_to = &quot;Faktor&quot;, values_to = &quot;Auspraegung&quot; ) big5_long # A tibble: 400 × 7 Alter Geschlecht Gruppe ID Faktor Auspraegung Zeitpunkt &lt;dbl&gt; &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; 1 36 m Mittel 1 Extraversion 3 T1 2 36 m Mittel 1 Neurotizismus 1.9 T1 3 30 f Jung 2 Extraversion 3.1 T1 4 30 f Jung 2 Neurotizismus 3.4 T1 # … with 396 more rows Die abzubildenden Mittelwerte und Standardabweichungen berechnen wir vor der Visualisierung und speichern das Zwischenergebnis als big5_means ab. Die Standardabweichungen benötigen wir für die Fehlerbalken. Alternativ könnte man durch Teilen der Standardabweichung durch die Stichprobengröße auch den Standardfehler abbilden. Wie man diese Lage- und Streuungsmaße berechnet, wurde bereits in Kapitel 7.1 eingeführt. big5_means &lt;- big5_long |&gt; group_by(Faktor) |&gt; summarise( Mean = mean(Auspraegung, na.rm = TRUE), SD = sd(Auspraegung, na.rm = TRUE) ) big5_means # A tibble: 2 × 3 Faktor Mean SD &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Extraversion 3.08 0.347 2 Neurotizismus 3.13 0.682 Die Balken werden mit geom_col() erstellt. Auf der x-Achse sind demnach wie zuvor auch die Persönlichkeitsfaktoren und auf der y-Achse die Mittelwerte aufgetragen (siehe Abbildung 8.8 (d)). ggplot(big5_means, aes(x = Faktor, y = Mean)) + geom_col() Verwechsle geom_col() nicht mit geom_bar(). Erstere Funktion stellt genau das dar, was man ihr übergibt (z.B. Mittelwerte). Letztere Funktion hingegen erstellt Balken mit absoluten oder relativen Häufigkeiten. Um das Balkendiagramm zu verschönern, können wir auch hier die Füllfarbe (fill) und die Rahmenfarbe (color) entsprechend anpassen (siehe Abbildung 8.8 (e)). ggplot(big5_means, aes(x = Faktor, y = Mean)) + geom_col(fill = &quot;white&quot;, color = &quot;black&quot;) Zusätzlich bilden wir mit der Funktion geom_errorbar() die Standardabweichung (SD) ab, indem das Minimum des Fehlerbalken als Mittelwert minus der Standardabweichung und das Maximum als Mittelwert plus der Standardabweichung festlegt wird. Die Breite der Fehlerbalken wird mit dem Argument width verändert. Beachte an dieser Stelle, dass die Grenzen der Fehlerbalken (ymin und ymax) im Gegensatz zur Fehlerbalkenbreite innerhalb der Helferfunktion aes() definiert werden müssen. Das Ergebnis ist in Abbildung 8.8 (f) illustriert. ggplot(big5_means, aes(x = Faktor, y = Mean)) + geom_col(fill = &quot;white&quot;, color = &quot;black&quot;) + geom_errorbar( mapping = aes(ymin = Mean - SD, ymax = Mean + SD), width = 0.4 ) Falls du mehr als eine Gruppe innerhalb eines Balkendiagramms vergleichen möchtest, musst du ein Gruppierungsargument verwenden, welches in Kapitel 8.9 eingeführt wird. Abbildung 8.8: Verschiedene Balkendiagramme mit und ohne Fehlerbalken. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 8.7 Liniendiagramm Bei Mittelwertvergleichen in Form von Liniendiagrammen ändert sich im Vergleich zu den Balkendiagrammen nur wenig. Auch hier verwenden wir wieder den Datensatz big5_means, der unsere Mittelwerte und Standardabweichungen für Extraversion und Neurotizismus enthält (siehe Kapitel 8.6. Zum Erstellen der Verbindungslinie zwischen den beiden Persönlichkeitsfaktoren muss das group Argument auf 1 gesetzt werden. Abschließend müssen wir noch die Linie mit geom_line(), die Mittelwerte als Punkte mit geom_point() und die Fehlerbalken mit geom_errorbar() erstellen. Auch bei den Fehlerbalken ändert sich nichts im Vergleich zu den Balkendiagrammen. Das Ergebnis ist in Abbildung 8.9 (a) illustriert. ggplot(big5_means, aes(x = Faktor, y = Mean, group = 1)) + geom_line() + geom_point() + geom_errorbar( mapping = aes(ymin = Mean - SD, ymax = Mean + SD), width = 0.2 ) Ein weiteres klassisches Beispiel eines Liniendiagramms ist die Abbildung von Zeitreihen. Dafür schauen wir uns den Kurs der Bitcoin-Aktie an. bitcoin # A tibble: 731 × 2 Date Price &lt;date&gt; &lt;dbl&gt; 1 2019-01-01 3844. 2 2019-01-02 3943. 3 2019-01-03 3837. 4 2019-01-04 3858. # … with 727 more rows Auf der x-Achse soll das Datum und auf der y-Achse der Preis bei geschlossener Börse in USD abgebildet werden. Die Zeitreihe wird wie zuvor mit geom_line() visualisiert. Wichtig ist hierbei, dass das Datum vom Datentyp Date ist (siehe Kapitel 6.11). Zusätzlich können wir, wie beim Streudiagramm in Kapitel 8.3, mit stat_smooth() eine am besten passendste Kurve zur Kursbeschreibung hinzufügen. Abschließend greifen wir an dieser Stelle etwas vor und verändern noch die Benennung der x-Achse mithilfe von scale_x_date(). Dabei gibt es verschiedene Möglichkeiten der Anzeige, die jeweils mit einem Prozentzeichen angeführt werden müssen. Hier zeigen wir den abgekürzten Monatsnamen (%b) und das entsprechende Jahr (%Y). Das Ergebnis ist in Abbildung 8.9 (b) illustriert. ggplot(bitcoin, aes(x = Date, y = Price)) + geom_line() + stat_smooth(color = &quot;black&quot;) + scale_x_date(date_labels = &quot;%b %Y&quot;) Eine weitere Anwendung finden Liniendiagramme bei sogenannten Scree Plots zur Auswahl der Anzahl der Faktoren für explorative Faktorenanalysen. Dafür benötigen wir den kompletten Big Five Rohdatensatz mit den einzelnen Fragen zu den Persönlichkeitsfaktoren namens big_five_comp. Mit der im remp Package enthaltenen Funktion data_eigen() können die entsprechenden Eigenvalues berechnet werden, die wir im Scree Plot abbilden wollen. big5_erg &lt;- select(big_five_comp, -Geschlecht) big5_scree &lt;- data_eigen(big5_erg) big5_scree # A tibble: 51 × 2 Eigenvalues Dimension &lt;dbl&gt; &lt;int&gt; 1 8.25 1 2 4.59 2 3 3.62 3 4 3.57 4 # … with 47 more rows Auf der x-Achse haben wir unsere verschiedenen Dimensionen und auf der y-Achse die Eigenvalues. Zusätzlich modifizieren wir die Funktionen geom_point() und geom_line() optisch leicht. Neu ist an dieser Stelle die Funktion geom_hline() (für horizontal line), welche eine horizontale Linie beim Schnittpunkt mit der y-Achse von 1 einzeichnet (siehe Abbildung 8.9 (c)). ggplot(big5_scree, aes(x = Dimension, y = Eigenvalues)) + geom_point(shape = 19, size = 2) + geom_line(linewidth = 0.6) + geom_hline( mapping = aes(yintercept = 1), linewidth = 0.8, linetype = &quot;longdash&quot; ) Abbildung 8.9: Abbildung von Liniendiagrammen als (a) Mittelwertsvergleich (b) Zeitreihe und (c) Scree Plot Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 8.8 Quantil-Quantil Plot Zum Berechnen der Residuen muss das broom installiert und geladen werden. library(broom) Um mithilfe eines Q-Q Plots die Quantile zweier Verteilungen zu überprüfen, können wir geom_qq() und geom_qq_line() verwenden. Ein häufiger Anwendungsfall ist die graphische Überprüfung, ob die Residuen eines Modells normalverteilt sind. Daher ist dies auch die Standardeinstellung innerhalb der Funktionen. Die Berechnung der Residuen erfolgt mithilfe von augment(), welche genau wie die lm() erst später eingeführt werden (siehe Kapitel 9.8 und 9.5.1). model &lt;- lm(Extraversion ~ Geschlecht + Alter, data = big5) resid_df &lt;- augment(model) Die interessierende Variable (hier die Residuen .resid) muss dem sample Argument (engl. für Stichprobe) übergeben werden (siehe Abbildung 8.10). ggplot(resid_df, aes(sample = .resid)) + geom_qq() + geom_qq_line() Abbildung 8.10: Q-Q Plots Möchte man die Verteilung einer Spalte mit einer anderen Verteilung vergleichen, können mit dem distribution Argument die Quantile einer anderen Verteilung wie der Binomialverteilung (qbinom) oder der t-Verteilung (qt) ohne Anführungszeichen festgelegt werden. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 8.9 Mehrfaktorielle Abbildungen In den bisherigen Abbildungen haben wir bislang nur jeweils zwei Variablen in Zusammenhang gesetzt, indem eine Variable auf der x-Achse und eine auf der y-Achse visualisiert wurde. Eine dritte Variable kann mit dem Gruppierungselement hinzugefügt werden (siehe Kapitel 8.9.1). Für das zeitgleiche Vergleichen einer vierten und fünften Variable innerhalb einer Abbildungen können sogenannte Facetten erstellt werden (siehe Kapitel 8.9.2). 8.9.1 Gruppierungsargumente Gruppierungen können in Abhängigkeit der gewünschten Darstellung durch die Argumente color, fill, linetype, size oder shape innerhalb der Helferfunktion aes() erstellt werden. Anders als bisher wird diesen Argumenten in diesem Fall kein Character (z.B. color = \"black\"), sondern das gruppierende Argument ohne Anführungszeichen übergeben (z.B. color = Geschlecht). Für einige Abbildungen wie bei Mittelwertsvergleichen in Form von Balken- oder Liniendiagrammen benötigen wir ein zusätzliches position Argument. Dieses spezifiziert, wie die Gruppen zueinander in Verhältnis zu setzen sind. Eine nützliche Wahl ist hierfür die Funktion position_dodge(0.95) (engl. für ausweichen), welche die Gruppen direkt nebeneinander darstellt. Die Zahl in der Klammer steht für den genauen Abstand zwischen den Elementen. Alternativ könnte man bei Balkendiagrammen auch position = \"stack\" für eine aufeinander gestapelte Ansicht pro Kategorie verwenden. Wenn man stattdessen position = \"fill\" verwendet, werden diese übereinander gestapelten Anteile auf 1 standardisiert, sodass man die Verhältnisse besser vergleichen kann. Zum Abbilden der mittleren Ausprägung von Extraversion und Neurotizismus unterteilt nach Geschlecht in Form eines Boxplots verwenden wir den Datensatz big5_long aus dem remp Package. big5_long # A tibble: 400 × 7 Alter Geschlecht Gruppe ID Faktor Auspraegung Zeitpunkt &lt;dbl&gt; &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; 1 36 m Mittel 1 Extraversion 3 T1 2 36 m Mittel 1 Neurotizismus 1.9 T1 3 30 f Jung 2 Extraversion 3.1 T1 4 30 f Jung 2 Neurotizismus 3.4 T1 # … with 396 more rows Die Füllfarbe (fill) machen wir abhängig vom Geschlecht und das Positionsargument wird ebenfalls entsprechend angepasst werden. Das Ergebnis ist in Abbildung 8.11 (a) illustriert. ggplot(big5_long, aes(x = Faktor, y = Auspraegung, fill = Geschlecht)) + geom_boxplot(outlier.shape = NA, position = position_dodge(0.95)) Falls zusätzlich ein Fehlerbalken angezeigt werden soll, muss auch in stat_boxplot() das Positionsargument verwendet werden (siehe Abbildung 8.11 (b)). ggplot(big5_long, aes(x = Faktor, y = Auspraegung, fill = Geschlecht)) + stat_boxplot( geom = &quot;errorbar&quot;, width = 0.4, position = position_dodge(0.95) ) + geom_boxplot(outlier.shape = NA, position = position_dodge(0.95)) Abbildung 8.11: Boxplots mit und ohne Fehlerbalken nach drei Variablen gruppiert. Wenn Mittelwerte in Form von Balken- oder Liniendiagrammen unterteilt nach einer dritten Variable miteinander verglichen werden sollen, müssen diese zuerst berechnet werden (siehe Kapitel 7). Dabei müssen wir zusätzlich nach der dritten Variable (hier Geschlecht) gruppieren. big5_means2 &lt;- big5_long |&gt; group_by(Faktor, Geschlecht) |&gt; summarise( Mean = mean(Auspraegung, na.rm = TRUE), SD = sd(Auspraegung, na.rm = TRUE) ) big5_means2 # A tibble: 4 × 4 # Groups: Faktor [2] Faktor Geschlecht Mean SD &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Extraversion f 3.05 0.358 2 Extraversion m 3.11 0.328 3 Neurotizismus f 3.25 0.633 4 Neurotizismus m 2.96 0.718 Ansonsten ändert sich im Vergleich zum vorherigen Beispiel nichts. Auch hier muss die Füllfarbe (fill = Geschlecht) und die Position der gruppierten Balken definiert werden. Das Ergebnis ist in Abbildung 8.12 (a) illustriert. ggplot(big5_means2, aes(x = Faktor, y = Mean, fill = Geschlecht)) + geom_col(position = position_dodge(0.95), color = &quot;black&quot;) + geom_errorbar( mapping = aes(ymin = Mean - SD, ymax = Mean + SD), width = 0.4, position = position_dodge(0.95) ) Ein weiterer Anwendungsfall sind gruppierte Liniendiagramme. Hierfür ändern wir an dieser Stelle das Argument fill zu linetype. Zusätzlich muss das Gruppierungsargument (hier Geschlecht) den einzelnen Funktionen übergeben werden, da sonst keine Linien zwischen den Gruppen gezeichnet werden würden (siehe Abbildung 8.12 (b)). ggplot(big5_means2, aes(x = Faktor, y = Mean, linetype = Geschlecht)) + geom_line( mapping = aes(group = Geschlecht), position = position_dodge(0.2) ) + geom_point(position = position_dodge(0.2)) + geom_errorbar( mapping = aes(group = Geschlecht, ymin = Mean - SD, ymax = Mean + SD), width = 0.2, position = position_dodge(0.2) ) Abbildung 8.12: Balken- und Liniendiagramme mit drei Variablen. Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 8.9.2 Facetten als weitere Dimensionen Für das Hinzufügen einer vierten Variable ändert sich im Vergleich zu Kapitel 8.9.1 nur die zusätzliche Funktion facet_wrap(), welche die vierte Variable in Form einer sogenannten Facette abbildet. Auch hier verwenden wir den big5_long Datensatz aus dem remp Package. big5_long # A tibble: 400 × 7 Alter Geschlecht Gruppe ID Faktor Auspraegung Zeitpunkt &lt;dbl&gt; &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; 1 36 m Mittel 1 Extraversion 3 T1 2 36 m Mittel 1 Neurotizismus 1.9 T1 3 30 f Jung 2 Extraversion 3.1 T1 4 30 f Jung 2 Neurotizismus 3.4 T1 # … with 396 more rows Innerhalb von facet_wrap() wird erst eine Tilde und anschließend der gewünschte Spaltenname geschrieben. Zusätzliche könnte man mit dem Argument ncol die Anzahl der Spalten festlegen. ggplot(big5_long, aes(x = Faktor, y = Auspraegung, fill = Geschlecht)) + geom_boxplot(outlier.shape = NA, position = position_dodge(0.95)) + facet_wrap(~ Gruppe) Abbildung 8.13: Boxplot mit vier Variablen. Wir sehen in Abbildung 8.13, dass die Altersgruppen in einem Raster als separate Graphen angezeigt werden. Die Anzahl der Spalten in der Anordnung können mit dem ncol Argument angepasst werden (z.B. ncol = 2). Mit dem scales Argument ist es möglich, die x-Achse (scales = \"free_x\") oder y-Achse (scales = \"free_y\") auf unterschiedlichen Skalen anzeigen zu lassen. Äquivalent zum Abbilden von drei Variablen in Kapitel 8.9.1, müssen beim Mittelwertsvergleich in Form von Balken- oder Liniendiagrammen auch hier erst die entsprechenden Werte berechnet werden. Der Unterschied ist die zusätzlich gruppierende Variable (hier Gruppe) innerhalb von group_by() (siehe Kapitel 7). big5_means3 &lt;- big5_long |&gt; group_by(Faktor, Geschlecht, Gruppe) |&gt; summarise( Mean = mean(Auspraegung, na.rm = TRUE), SD = sd(Auspraegung, na.rm = TRUE) ) big5_means3 # A tibble: 12 × 5 # Groups: Faktor, Geschlecht [4] Faktor Geschlecht Gruppe Mean SD &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Extraversion f Jung 3.07 0.373 2 Extraversion f Mittel 3.07 0.299 3 Extraversion f Weise 2.83 0.269 4 Extraversion m Jung 3.12 0.324 # … with 8 more rows Anschließend können auf dieselbe Art und Weise mithilfe von facet_wrap() die Altersgruppen eingefügt werden. ggplot(big5_means3, aes(x = Faktor, y = Mean, fill = Geschlecht)) + geom_col(position = position_dodge(0.95), color = &quot;black&quot;) + geom_errorbar( mapping = aes(ymin = Mean - SD, ymax = Mean + SD), width = 0.4, position = position_dodge(0.95) ) + facet_wrap(~ Gruppe) Auch beim Hinzufügen einer fünften Variable finden wir das gleiche Prinzip vor. Für fünf Variablen ändert sich die Funktion zu facet_grid(). Die Variable, welche in den Zeilen des Rasters (hier Zeitpunkt) abgebildet werden soll, wird auf die linke Seite der Tilde und die Variable für die Spalten (hier Gruppe) auf die rechte Seite geschrieben. ggplot(big5_long, aes(x = Faktor, y = Auspraegung, fill = Geschlecht)) + geom_boxplot(outlier.shape = NA, position = position_dodge(0.95)) + facet_grid(Zeitpunkt ~ Gruppe) Abbildung 8.14: Boxplot mit fünf Variablen. Bei Mittelwertsvergleichen müssen diese mit group_by() und summarise() durch das Hinzufügen einer vierten gruppierenden Variable zunächst berechnet werden. big5_means4 &lt;- big5_long |&gt; group_by(Faktor, Geschlecht, Gruppe, Zeitpunkt) |&gt; summarise( Mean = mean(Auspraegung, na.rm = TRUE), SD = sd(Auspraegung, na.rm = TRUE) ) big5_means4 # A tibble: 24 × 6 # Groups: Faktor, Geschlecht, Gruppe [12] Faktor Geschlecht Gruppe Zeitpunkt Mean SD &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Extraversion f Jung T1 3.08 0.391 2 Extraversion f Jung T2 3.06 0.362 3 Extraversion f Mittel T1 2.93 0.121 4 Extraversion f Mittel T2 3.13 0.336 # … with 20 more rows Anschließend kann auch hier ein Raster mithilfe von facet_grid() erstellt werden. ggplot(big5_means4, aes(x = Faktor, y = Mean, fill = Geschlecht)) + geom_col(position = position_dodge(0.95), color = &quot;black&quot;) + geom_errorbar( mapping = aes(ymin = Mean - SD, ymax = Mean + SD), width = 0.4, position = position_dodge(0.95) ) + facet_grid(Zeitpunkt ~ Gruppe) Das ist ein Platzhalter für eine Übung. Starte die Übung mit hands_on(\"test\"). 8.10 Anpassen des Aussehens Die Standardeinstellungen von ggplot sind praktisch für einen ersten Überblick, aber eignen sich nicht zur Veröffentlichung der Abbildungen in einer wissenschaftlichen Publikation. In den folgenden Kapiteln wird erklärt, wie man Farben, Texte, die Legende, die Achsen und vieles mehr verändert. Wir werden uns anhand der Abbildung aus Kapitel 8.9.1 die verschiedenen Anpassungsmöglichkeiten anschauen. Zusätzlich fügen wir bereits an dieser Stelle das alpha Argument hinzu, welches die Deckkraft mit 0.8 auf 80% hinuntersetzt. Dies sorgt für ein hochwertigeres Aussehen der Farben. Der gruppierte Boxplot wird als p gespeichert und in den folgenden Kapiteln verwendet. p &lt;- ggplot(big5_long, aes(x = Faktor, y = Auspraegung, fill = Geschlecht)) + geom_boxplot(outlier.shape = NA, position = position_dodge(0.95), alpha = 0.8) In Abbildung 8.15 ist die Standardeinstellung von ggplot unserer modifizierten Abbildungen gegenübergestellt. Die verschiedenen Anpassungen können ebenfalls mit einem Pluszeichen (+) aneinandergekettet werden. Wofür welche Funktion genau zuständig ist, wird im weiteren Verlauf kleinschrittig eingeführt. p + scale_fill_viridis_d( begin = 0.27, end = 0.72, option = &quot;C&quot;, name = &quot;Geschlecht (Auswahl):&quot;, labels = c(&quot;Weiblich&quot;, &quot;Männlich&quot;) ) + scale_y_continuous(expand = c(0, 0), limits = c(1, 5.2), breaks = 1:5) + labs(x = &quot;Persönlichkeitsfaktor&quot;, y = &quot;Mittlere Ausprägung&quot;) + theme_classic(base_size = 14, base_family = &quot;sans&quot;) + theme( legend.position = c(0.4, 0.9), axis.title.y = element_text(vjust = 2), axis.title.x = element_text(vjust = 0.5), axis.text = element_text(size = 13) ) Abbildung 8.15: Standardausgabe im Vergleich mit einer publikationsreifen Abbildung. 8.10.1 Farben Beim Verändern der Farben innerhalb einer Abbildung unterscheiden wir zwischen der Rahmenfarbe (color) und Füllfarbe (fill). Während die Rahmenfarbe häufig als schwarz gewählt werden sollte, hat man mit der Füllfarbe mehr Freiheiten. Das Farbschema kann durch verschiedene Farbpaletten adaptiert werden. Häufig sind im wissenschaftlichen Kontext jedoch nur Graustufen erwünscht, welche wir mit scale_fill_grey() erstellen können. Wichtig ist an dieser Stelle das start und end Argument der Farbpalette, da die Grautöne sonst zu dunkel für das Erkennen von Fehlerbalken sein können. Hätten wir in unserem ggplot nicht die Füllfarbe (fill), sondern die Rahmenfarbe (color) verändert, würde man stattdessen die Funktion scale_color_grey() verwenden. Die brewer Paletten enthalten verschiedene Farben wie blau (\"Blues\") oder rot (\"Reds\"). Diese werden mit der Funktion scale_fill_brewer() erstellt. Mithilfe von scale_fill_manual() können Farben in Form von Hexadezimal Farbkodierungen als einzelne Werte übergeben werden. a &lt;- p + scale_fill_grey(start = 0.3, end = 0.7) b &lt;- p + scale_fill_brewer(palette = &quot;Blues&quot;) c &lt;- p + scale_fill_manual(values = c(&quot;#A50F15&quot;, &quot;#FC9272&quot;)) Abbildung 8.16: Vergleich verschiedener Farbpaletten. Bei der Auswahl einzelner Werte sollte ebenfalls auf Farben innerhalb von Paletten zurückgegriffen werden, da diese aufeinander abgestimmt sind. Es ist generell davon abzuraten, eigene Farbkombinationen zu wählen, da diese oft einen unprofessionellen Eindruck erwecken. Die Hexadezimal-Farbkodierung erhält man entweder durch Nachschlagen in einer Suchmaschine oder durch Nachschauen in den Farbpaletten. Dafür müssen die Packages scales und RColorBrewer installiert und geladen werden. library(scales) library(RColorBrewer) Die Rottöne aus Abbildung 8.16 wurden bspw. aus der Brewer Farbpalette ausgewählt. Zum Anzeigen von 9 Farben der roten Farbpalette kombinieren wir die Funktion brewer.pal() mit show_col(). Beachte die Trennung der Funktionsnamen einmal mit Punkt und einmal mit Unterstrich. brewer.pal(9, &quot;Reds&quot;) |&gt; show_col() Abbildung 8.17: Hexadezimalfarben einer roten Farbpalette. In der Abbildung aus Kapitel 8.10 wurde die Farbpalette Viridis verwendet, die Farbenblindheit berücksichtigt. Diese Farbpalette erstellt man mit scale_fill_viridis_d(begin = 0.27, end = 0.72, option = \"C\"). Wie bei den Graustufen zuvor können auch hier die Start- und Entwerte angepasst werden. Das optionale opt Argument wählt hier die dritte von acht möglichen Viridis Paletten. Für kontinuierliche Skalen muss stattdessen auf die Funktion scale_fill_viridis_c() zurückgegriffen werden. 8.10.2 Themen und Achsen Der hellgraue Standardhintergrund und die fehlende Visualisierung der Achsen ist in der Wissenschaft in der Regel nicht erwünscht. Ein gutes minimales Thema ist theme_classic(). Innerhalb der theme_*() Funktionen kann die Textgröße und -art direkt angepasst werden. Relativ zur Basisgröße (base_size) sind andere Elemente wie Überschriften entsprechend größer. Welches die richtige Größe ist, hängt maßgeblich von den Dimensionen der Abbildung und somit der Auflösung ab (siehe Kapitel 8.12). Weitere Themen sind z.B. theme_minimal() oder theme_bw(). a &lt;- p + theme_classic(base_size = 14, base_family = &quot;sans&quot;) b &lt;- p + theme_minimal() c &lt;- p + theme_bw() Abbildung 8.18: Vergleich verschiedener Themen aus ggplot. Neben den direkt in ggplot enthaltenen Themen, stellt das ggthemes Package noch weitere Themen zur Verfügung. Die Beschriftung der x-Achse und y-Achse wird mithilfe der Funktion labs() (Akronym für labels, engl. für Beschriftung) angepasst. p + labs(x = &quot;Persönlichkeitsfaktor&quot;, y = &quot;Mittlere Ausprägung&quot;) Zum Verändern der Textgröße, -ausrichtung und adjustierung, verwenden wir die Funktion theme(). Jedem Argument innerhalb von theme() müssen die Werte (wie z.B. die Textgröße) innerhalb der Helferfunktion element_text() übergeben werden. Das Argument vjust schafft etwas Raum zwischen der Achsenbeschriftung und dem Text der Achsen. p + theme( axis.title.y = element_text(vjust = 2), axis.title.x = element_text(vjust = 0.5), axis.text = element_text(size = 13) ) Mit der Funktion scale_x_discrete() verändert man die Reihenfolge diskreter Merkmale auf der x-Achse. So könnte mithilfe des limits Arguments bspw. zuerst der Boxplot für Neurotizismus angezeigt werden. Mit dem labels Argument gibt es die Möglichkeit, die Namen der Merkmale zu ändern. Dabei befindet sich auf der rechten Seite des Gleichheitszeichens der neue Name (hier Extra und Neuro) und auf der linken Seite die alte Bezeichnung. Äquivalent dazu existiert die Funktion scale_y_discrete(). p + scale_x_discrete( limits = c(&quot;Neurotizismus&quot;, &quot;Extraversion&quot;), labels = c(&quot;Extraversion&quot; = &quot;Extra&quot;, &quot;Neurotizismus&quot; = &quot;Neuro&quot;) ) Für kontinuierliche Skalen gibt es die Funktionen scale_x_continuous() und scale_y_continuous(). Durch das expand Argument wird der zusätzliche Raum zwischen y-Achse und x-Achse entfernt. Außerdem können hier der Anfang und das Ende der Achse (limits) sowie die Anzahl der Beschriftungen eingestellt werden (breaks). p + scale_y_continuous( expand = c(0, 0), limits = c(1, 5.2), breaks = 1:5 ) Eine nützliche Funktion für das breaks Argument stellt seq() dar, welche die Abstände der Unterteilungen mit by festlegt. seq(from = 0, to = 10, by = 2) [1] 0 2 4 6 8 10 Ein häufiges Problem sind zu lange Achsenbeschriftung, die sich überschneiden. Um das Problem zu lösen, gibt es drei Möglichkeiten. Man kann die Beschriftungen mit angle (engl. für Winkel) in Kombination mit hjust (Akronym für horizontal adjustment) in einer 45 Grad Winkel bringen. p + theme(axis.text.x = element_text(angle = 45, hjust = 1)) Eine weitere Möglichkeit ist potentielle Überlappungen innerhalb der Funktion guide_axis() zu überprüfen (check.overlap = TRUE) und die Anzahl der verwendeten Zeilen festzulegen (n.dodge = 2). Dies wurde in mehreren Abbildungen dieses Buches verwendet (z.B. in Abbildung 8.18). p + scale_x_discrete(guide = guide_axis(n.dodge = 2, check.overlap = TRUE)) Als dritte Option können lange Beschriftungen mit str_wrap(), einer Funktion aus dem stringr Package, in mehrere Zeilen gebrochen werden (siehe Kapitel 6.9). Wenn bspw. mehr als zehn Buchstaben (width = 10) vorhanden sind, werden die Beschriftungen in mehrere Zeilen gebrochen. Diese Option ist vor allem für Beschriftungen mit mehr als einem Wort nützlich. p + scale_x_discrete(labels = \\(text) str_wrap(text, width = 10)) Abschließend fokussiert man mit coord_cartesian() einen Ausschnitt der Abbildung. Dies ist bspw. zur explorativen Betrachtung ohne Ausreißer sinnvoll. Im Gegensatz zu scale_y_continuous() wird in diesem Fall kein Wert gelöscht. Es wird lediglich der neu definierte Ausschnitt vergrößert. p + coord_cartesian(xlim = c(1, 4)) 8.10.3 Legende und Facetten Der Titel und Text der Legende wird am besten über die Farbfunktionen verändert. Beim vorherigen Anpassen der Füllfarbe in Abhängigkeit des Geschlechts, können dabei noch das name Argument für den Titel und das labels Argument für die Merkmalsbezeichnungen hinzugefügt werden. p + scale_fill_viridis_d( begin = 0.27, end = 0.72, option = &quot;C&quot;, name = &quot;Geschlecht (Auswahl):&quot;, labels = c(&quot;Weiblich&quot;, &quot;Männlich&quot;) ) Die Reihenfolge der gruppierenden Variable, die in der Legende angezeigt wird, verändern wir mithilfe von lims() (siehe Abbildung 8.19 (b) im Vergleich zur Ausgangslage (a)). p + lims(fill = c(&quot;m&quot;, &quot;f&quot;)) Zum Ändern der Reihenfolge der Füllfarben für die jeweiligen Merkmale müssen die Faktorstufen vor Erstellung der Abbildung verändert werden (siehe Kapitel 6.10). big5_long_rev &lt;- big5_long |&gt; mutate(Geschlecht = fct_relevel(Geschlecht, &quot;m&quot;)) Beim anschließenden Visualisieren verändert sich hingegen nichts im Vergleich zur vorherigen Reihenfolge. Das Ergebnis ist in Abbildung 8.19 (c) illustriert. ggplot(big5_long, aes(x = Faktor, y = Auspraegung, fill = Geschlecht)) + geom_boxplot(outlier.shape = NA, position = position_dodge(0.95), alpha = 0.8) Abbildung 8.19: Verschiedene Reihenfolgen der gruppierenden Variable. Die Textgröße von Legendentitel und -text werden in der bereits eingeführten theme() Funktion angepasst (siehe Kapitel 8.10.2). Ausgeblendet wird der Titel der Legende mit legend.title = element_blank(). Die Position wird am besten über x- und y- Koordinaten festgelegt. Welche Werte hierfür am passendsten sind, hängt direkt von der gewählten Dimension und somit Auflösung der Abbildung beim Speichern ab (siehe Kapitel 8.12). p + theme( legend.title = element_text(size = 14), legend.text = element_text(size = 13), legend.position = c(0.25, 0.9) ) Dem legend.position Argument können außerdem \"top\" und \"bottom\" übergeben werden. Eine horizontale Legende wird mit legend.direction = \"horizontal\" erstellt. Das Anpassen der Facetten erfolgt innerhalb von theme() mit den strip Argumenten. Dabei kann etwa die Textgröße der Überschrift verändert oder der Hintergrund ausgeblendet werden. p + theme( strip.text = element_text(size = 15), strip.background = element_blank() ) 8.11 Anordnen mehrerer Graphen Innerhalb dieses Buches gibt es diverse Graphen, die nebeneinander in einer Abbildung dargestellt wurden. Dafür muss das patchwork Package installiert und geladen sein. library(patchwork) Der erste Schritt ist das Abspeichern der jeweiligen Abbildungen. Exemplarisch nutzen wir an dieser Stelle das Histogramm, das Streudiagramm, den Boxplot und den Q-Q Plot aus den vorherigen Kapiteln und speichern diese jeweils als a, b, c und d. a &lt;- ggplot(big5_mod, aes(x = Extraversion)) + geom_histogram(color = &quot;black&quot;, fill = &quot;white&quot;, binwidth = 0.2) b &lt;- ggplot(big5_mod, aes(x = Extraversion, y = Alter)) + geom_point(position = &quot;jitter&quot;) c &lt;- ggplot(big5_long, aes(x = Faktor, y = Auspraegung)) + geom_boxplot() d &lt;- ggplot(big5_mod, aes(sample = Alter)) + geom_qq() + geom_qq_line() Anschließend addieren wir die vier Graphen in gewünschter Reihenfolge. Die Funktion plot_layout() spezifiziert unter anderem die Anzahl der Spalten (ncol) und plot_annotation() ergänzt mit dem tag_levels Argument Beschriftungen zu jeder Abbildung (siehe Abbildung 8.20). a + b + c + d + plot_layout(ncol = 2) + plot_annotation(tag_levels = &quot;A&quot;) Abbildung 8.20: Anordnung mehrerer Graphen Neben \"A\" kann der Funktion plot_annotation() außerdem \"i\", \"I\", \"a\" und \"1\" übergeben werden. Die tag_levels können durch tag_prefix und tag_suffix weiter an die eigenen Bedürfnisse angepasst werden. Außerdem können Abbildungen auch in unterschiedlicher Anzahl neben- und untereinander gesetzt werden. Dafür muss man lediglich die oben stehenden Abbildungen mit vertikalen Linien unterteilen und diese dann durch die Abbildung, die unten stehen soll, teilen (siehe Abbildung 8.21). (a | b | c) / d + plot_annotation( tag_levels = &quot;a&quot;, tag_prefix = &quot;(&quot;, tag_suffix = &quot;)&quot; ) Abbildung 8.21: Alternative Anordnung mehrerer Graphen Falls alle addierten Graphen dieselbe Legende hätten, könnte diese mit guide_area() und dem guides Argument gesammelt angezeigt werden. Dabei wird mit guide_area() die Position der gemeinsamen Legende festgelegt. plots &lt;- a + b + c + guide_area() + plot_layout(ncol = 2, guides = &quot;collect&quot;) Eine weitere nützliche Funktion ist plot_spacer() zum Freilassen eines Areals in der kombinierten Abbildung. Wenn man kombinierte Abbildungen (hier als plots gespeichert) im Nachhinein verändern möchte, müssen diese einzeln angesprochen werden. Da diese als Liste gespeichert sind, erreichen wir dies mit einer doppelten eckigen Klammern (siehe Kapitel 11.4). Mit plots[[1]] extrahiert man so Abbildung a. plots[[1]] + theme_minimal() plots[[2]] + theme_minimal() plots[[3]] + theme_minimal() Falls dieselbe Änderung alle kombinierten Graphen betrifft, können wir diese mithilfe des &amp;-Operators (anstelle von +) umsetzen. a + b + c &amp; theme_minimal() 8.12 Speichern von Abbildungen Abbildungen werden mit ggsave() in dem aktuellen durch das R Projekt festgelegten Ordner gespeichert. Dabei sind vor allem vier Argumente wichtig. Mit filename wird festgelegt, wie die Abbildung heißen soll und in welchem Dateiformat (z.B. .jpg oder .png) selbige ausgegeben wird. Mit plot wird die zu speichernde Abbildung übergeben. p &lt;- ggplot(big5_long, aes(x = Faktor, y = Auspraegung, fill = Geschlecht)) + geom_boxplot(outlier.shape = NA, position = position_dodge(0.95), alpha = 0.8) ggsave( filename = &quot;plotA.png&quot;, plot = p, width = 5, height = 5 ) Mit width und height legt man die Weite in Zoll fest. Die festgelegte Breite und Höhe hat einen erheblich Einfluss auf die Auflösung. ggsave( filename = &quot;plotB.png&quot;, plot = p, width = 8, height = 7 ) In Abbildung 8.22 (a) ist plotA.png mit einer Breite und Höhe von 5 Zoll abgebildet, während plotB.png in (b) mit 8 x 7 Zoll bedeutend größer gespeichert wurde. Während in (a) die Achsenbeschriftungen groß sind und die Legende sogar mit der y-Achse überlappt, ist dies in (b) nicht zu beobachten. Abbildung 8.22: Auflösungsunterschiede je nach Größe der gespeicherten Abbildung. Die Größe der Abbildung wird durch die Breite (width) und Höhe (height) festgelegt. Durch unterschiedliche Größen wird auch die Auflösung innerhalb der Abbildung beeinflusst, sodass man häufig erneut die Textgrößen der Achsenbeschriftungen anpassen und erneut speichern muss. Die gespeicherte Abbildung hat nicht dasselbe Format wie die angezeigte Ausgabe innerhalb von RStudio. 8.13 Exemplarische Erweiterungen Wir erinnern uns, dass die beiden Gs in ggplot für grammar of graphics stehen. Daraus resultiert nicht nur eine konsistente Anwendung, wie wir es in den bisherigen Kapiteln kennengelernt haben. Zusätzlich gibt es diverse darauf aufbauende Erweiterungen. Durch die gleiche Basis können wir auch die Graphen der Erweiterungen, wie zuvor gelernt, anpassen. Die meisten Erweiterungen halten sich an eine einheitliche Namensgebung. Vor dem Zweck des Packages steht also auch bei den Erweiterungspackages meistens ein gg (z.B. ggfortify oder ggridges). Allerdings halten sich nicht alle an eine konsistente Namensgebung (z.B. beim Erstellen von Kaplan-Meier-Kurven mit dem survival Package). 8.13.1 Kaplan-Meier-Kurve Für dieses Kapitel müssen die Packages survival, survminer und patchwork installiert und geladen werden. library(survival) library(survminer) library(patchwork) Aus dem survival Package schauen wir uns den Datensatz lung an. Dabei interessieren uns die Spalten time, status und sex. Die Variable time gibt die Überlebenszeit in Tagen an, status beinhaltet die Information über den Tod (1) oder für ein zensiertes Ereignis (2). Die Variable sex beinhaltet das biologische Geschlecht in Form von männlich (1) und weiblich (2). lung # A tibble: 228 × 10 inst time status age sex ph.ecog ph.karno pat.karno meal.cal wt.loss &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 3 306 2 74 1 1 90 100 1175 NA 2 3 455 2 68 1 0 90 90 1225 15 3 3 1010 1 56 1 0 90 90 NA 15 4 5 210 2 57 1 1 90 60 1150 11 # … with 224 more rows Gesamte Überlebenszeit. Bevor wir eine Kaplan-Meier-Kurve zur Visualisierung der Überlebenszeiten erstellen können, müssen wir zuerst mithilfe von survfit() aus dem survival Package die Überlebenswahrscheinlichkeiten schätzen. Für genauere Informationen über die Verwendung dieser Funktion sei auf das Kapitel 9.5.8 verwiesen. res &lt;- survfit(Surv(time = time, event = status) ~ 1, data = lung) Mit der Funktion ggsurvplot() aus dem survminer Package können wir anschließend die gesamte Überlebenszeiten visualisieren. Zusätzlich können wir mit conf.int ein Konfidenzinterval und mit risk.table die Anzahl betroffener Personen hinzufügen. ggsurvplot(res, conf.int = TRUE, risk.table = TRUE) Überlebenszeit nach gruppierender Variable. Zuerst werden die Überlebenswahrscheinlichkeiten nach sex unterteilt. res2 &lt;- survfit(Surv(time = time, event = status) ~ sex, data = lung) Zum Erstellen der eigentlichen Kaplan-Meier-Kurve verwenden wir erneut ggsurvplot(). Hier passen wir direkt diverse Argumente an, die innerhalb der Funktion an ggplot übergeben werden. p1 &lt;- ggsurvplot( fit = res2, xlab = &quot;Monate&quot;, ylab = &quot;Überlebenswahrscheinlichkeit&quot;, break.x.by = 100, risk.table = TRUE, risk.table.y.text = FALSE, tables.theme = theme_cleantable(), legend = c(0.15, 0.15), legend.title = &quot;Geschlecht&quot;, legend.labs = c(&quot;Männlich&quot;, &quot;Weiblich&quot;), palette = &quot;nejm&quot; ) Die Abbildung besteht aus zwei Teilen, der Kaplan-Meier-Kurve (plot) und der Tabelle (table). Zum Abspeichern müssen wir aus unserem Ergebnis p1 diese beiden Anteile einzeln mit dem Dollar-Operator ansprechen und mithilfe des patchwork Packages zusammenfügen (siehe Kapitel 8.11). Mit plot_layout() wird festgelegt, dass der Graph und die Tabelle untereinander illustriert werden (ncol = 1) und das Verhältnis der Abbildungen mit dem heights Argument. Letzteres Argument ist wichtig, da der Hauptteil der Abbildung der Kaplan-Meier-Kurve und nicht der Tabelle gewidmet werden soll. kaplan_meier &lt;- p1$plot + p1$table + plot_layout(ncol = 1, heights = c(8, 1)) kaplan_meier Abbildung 8.23: Kaplan-Meier-Kurve mit Tabelle unterteilt nach biologischem Geschlecht. Durch das Ansprechen der einzelnen Bestandteile (z.B. mit kaplan_meier[[1]]) können beiden Bestandteile, wie in Kapitel 8.10 gelernt, angepasst werden. Gespeichert wird das Ergebnis wie gewohnt mit ggsave() (siehe Kapitel 8.12). ggsave(&quot;Kaplan_meier.png&quot;, kaplan_meier, height = 7, width = 9) 8.13.2 Residuen überprüfen Für das schnelle graphische Überprüfen der notwendigen Voraussetzungen in Bezug auf die Residuen, müssen wir erst das ggfortify Package installieren und laden. library(ggfortify) library(patchwork) Zunächst greifen wir an dieser Stelle etwas vor und erstellen ein lineares Regressionsmodell, welches die Variation in der mittleren Extraversionsausprägung durch Geschlecht und Alter erklären soll (siehe Kapitel 9.5.1). model &lt;- lm(Extraversion ~ Geschlecht + Alter, data = big5) Dieses Modell kann im Anschluss der Funktion autoplot() übergeben werden. Dies funktioniert auf dieselbe Art und Weise wie für die meisten Regressionsmodelle. Als weiteres Argument kann mit which ausgewählt werden, welche Abbildungen ausgegeben werden (hier alle 6). Das Argument label.repel sorgt dafür, dass der Text, der die Ausreißer beschriftet, die Linien nicht überschneidet. Als letztes wird mit smooth.colour noch die Farbe der Regressionsgeraden auf schwarz gesetzt. res &lt;- autoplot( model, which = 1:6, label.repel = TRUE, smooth.colour = &quot;black&quot; ) Zum Speichern müssen, wie in Kapitel 8.13.1, die einzelnen Abbildungen ausgewählt und mithilfe des patchwork Packages zusammengefügt werden. Da die Plots mit ggplot erstellt wurden, können wir das Aussehen wie gewohnt anpassen (siehe Kapitel 8.10). Auf die einzelnen Plots wird mit doppelten eckigen Klammern zugegriffen, da diese auch hier als Listen gespeichert wurden (siehe Kapitel 11.4). Anschließend fügen wir die Abbildungen zusammen und verändern das Thema sowie die Schriftgröße für alle Teile der Abbildungen gleichzeitig (siehe Kapitel 8.11). res[[1]] + res[[2]] + res[[3]] + res[[4]] + res[[5]] + res[[6]] + plot_layout(ncol = 2) &amp; theme_classic(base_size = 14) Abbildung 8.24: Graphische Überprüfung der Residuen. 8.13.3 Ridgeline Plot Für dieses Kapitel muss das ggridges Package installiert und geladen sein. library(ggridges) Sogenannte Ridgeline Plots erlauben unter anderem den Vergleich von mehreren Dichtefunktionen innerhalb einer Abbildung. In Kapitel 8.2 haben wir die Wahrscheinlichkeitsdichte und somit die Verteilung der Werte für eine Variable angezeigt. Um mehrere Dichten untereinander innerhalb einer Abbildung zu vergleichen, müssen wir den Datensatz zuerst in das lange Datenformat bringen (siehe Kapitel 6.6). big_five_long &lt;- big_five |&gt; pivot_longer( cols = Extraversion:Gewissenhaftigkeit, values_to = &quot;Auspraegung&quot;, names_to = &quot;Faktor&quot; ) |&gt; relocate(Faktor, Auspraegung) big_five_long # A tibble: 800 × 14 Faktor Auspr…¹ Alter Gesch…² O1 O2 O3 O4 O5 O6 O7 O8 O9 O10 &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Extraversi… 3 36 m 5 1 5 1 4 1 5 5 4 5 2 Neurotizis… 1.9 36 m 5 1 5 1 4 1 5 5 4 5 3 Vertraegli… 3.4 36 m 5 1 5 1 4 1 5 5 4 5 4 Gewissenha… 3.3 36 m 5 1 5 1 4 1 5 5 4 5 # … with 796 more rows, and abbreviated variable names ¹​Auspraegung, ²​Geschlecht Durch die Funktion geom_density_ridges() werden die Verteilungen von Extraversion, Neurotizismus, Verträglichkeit und Gewissenhaftigkeit gegeneinander aufgetragen. Zusätzlich übergeben wir das Argument alpha, welches die Deckkraft auf 80% reduziert. ggplot(big_five_long, aes(x = Auspraegung, y = Faktor, height = after_stat(density))) + geom_density_ridges(stat = &quot;density&quot;, alpha = 0.8) Etwas ungewohnt ist an dieser Stelle, dass wir hier auf der y-Achse die zu vergleichende diskrete Variable abbilden und auf der x-Achse die mittlere Ausprägung des jeweiligen Persönlichkeitsfaktors. Abschließend passen wir noch einige Kleinigkeiten zur ansprechenderen Abbildung an. ggplot(big_five_long, aes(x = Auspraegung, y = Faktor, height = after_stat(density))) + geom_density_ridges(stat = &quot;density&quot;, alpha = 0.8) + labs(x = &quot;Mittlere Ausprägung&quot;, y = &quot;&quot;) + scale_x_continuous(expand = c(0, 0)) + scale_y_discrete(expand = c(0, 0)) + theme_classic(base_size = 14, base_family = &quot;sans&quot;) + theme( axis.text.y = element_text(hjust = 0, color = &quot;black&quot;, size = 12), axis.title.x = element_text(hjust = 1, vjust = 0.2, size = 13) ) Abbildung 8.25: Ridgeline plots mit angepasstem Thema. 8.13.4 Hervorheben bestimmter Werte Im Rahmen dieses Kapitels muss das gghighlight Package installiert und geladen werden. library(gghighlight) Manchmal soll ein besonderes Augenmerk auf einen Teil der Abbildung gelegt werden, welcher für die Beantwortung der Fragestellung eine zentrale Bedeutung hat. Dies schauen wir uns anhand des Beispiels der Balkendiagramme an (siehe Kapitel 8.6). Zuerst müssen wir also die deskriptiven Statistiken in Form des Mittelwerts (Mean) und der Standardabweichung (SD) berechnen. big5_means2 &lt;- big_five_long |&gt; group_by(Faktor) |&gt; summarise( Mean = mean(Auspraegung, na.rm = TRUE), SD = sd(Auspraegung, na.rm = TRUE) ) big5_means2 # A tibble: 4 × 3 Faktor Mean SD &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Extraversion 3.08 0.347 2 Gewissenhaftigkeit 3.16 0.361 3 Neurotizismus 3.13 0.682 4 Vertraeglichkeit 3.2 0.367 Wie gewohnt visualisieren wir die Balken anschließend mit geom_col() (siehe Abbildung 8.26 (a)). ggplot(big5_means2, aes(x = Faktor, y = Mean)) + geom_col() Um einen Balken hervorzuheben, können wir der Funktion gghighlight() eine logische Bedingung übergeben. Ähnlich wie bei filter() muss also der Ausdruck innerhalb der Klammer entweder TRUE oder FALSE zurückgeben. Der Balken, worauf diese Bedingung zutrifft, wird hervorgehoben. In Abbildung 8.26 (b) sehen wir exemplarisch den Balken des Persönlichkeitsfaktors Gewissenhaftigkeit hervorgehoben. ggplot(big5_means2, aes(x = Faktor, y = Mean)) + geom_col() + gghighlight(Faktor == &quot;Gewissenhaftigkeit&quot;) In diesem Package ist die Funktionsbezeichnung abweichend von der in ggplot2. Anstelle des Präfixes geom_*() wird die Funktion hier mit zwei Gs angeführt. Abbildung 8.26: Ein Balkendiagramm mit und ohne Hervorhung. 8.13.5 Directed Acyclic Graphs Zur Abbildung von so genannten Directed Acyclic Graphs (DAGs) müssen die Packages dagitty und ggdag installiert und geladen werden. library(dagitty) library(ggdag) DAGs werden dafür verwendet, vermutete Beziehungen zwischen Variablen explizit und nachvollziehbar darzustellen. Um das Prinzip zu verdeutlichen, soll eine Mediation illustriert werden. Dabei sei X eine Behandlung, M ein Mediator und Y unser Outcome. Die Syntax innerhalb der Funktion dagitty() ist etwas ungewöhnlich, da im Hintergrund auf ein externes Programm zurückgegriffen wird, welches nicht direkt in R geschrieben ist. Wir übergeben also in einem Character (also in Anführungszeichen) die darzustellenden Beziehungen der Variablen. Einmal den indirekten Pfad von X über M zu Y und einmal den direkten Pfad von X zu Y. dag &lt;- dagitty(&quot;dag{X -&gt; M -&gt; Y; X -&gt; Y}&quot;) dag dag { M X Y M -&gt; Y X -&gt; M X -&gt; Y } Bevor wir zur Visualisierung kommen, müssen wir noch die Koordinaten festlegen. Auch hier weichen wir etwas von der bisher kennengelernten Syntax ab. Grundsätzlich müssen für jede der oben definierten Variablen (X, M, Y) die Koordinaten festgelegt werden. Auf der x-Achse soll zuerst X, dann M und als letztes Y abgebildet werden. Auf der y-Achse sollen X und Y auf derselben Höhe sein, während sich M etwas weiter oben befindet. coordinates(dag) &lt;- list( x = c(X = 1, M = 2, Y = 3), y = c(X = 0, M = 1, Y = 0) ) Am schnellsten kann die Abbildung mit ggdag() erstellt werden. Zusätzlich entfernt die Funktion theme_dag() den Hintergrund und die Achsenbeschriftungen der Abbildung. ggdag(dag) + theme_dag() Abbildung 8.27: Directed Acyclic Graph einer Mediation mit M als Mediator. Das ggdag Package bietet außerdem die Möglichkeit das DAG genauer anzuschauen. tidy_dagitty(dag) # A DAG with 3 nodes and 3 edges # # A tibble: 4 × 8 name x y direction to xend yend circular &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;lgl&gt; 1 M 2 1 -&gt; Y 3 0 FALSE 2 X 1 0 -&gt; M 2 1 FALSE 3 X 1 0 -&gt; Y 3 0 FALSE 4 Y 3 0 &lt;NA&gt; &lt;NA&gt; NA NA FALSE Dies können wir uns für komplexere Designs zunutze machen, indem wir auf die klassische ggplot Syntax zurückgreifen. Die Kreise um die Variablen werden mit geom_dag_point(), die Pfeile mit geom_dag_edges() und der Text mit geom_dag_text() erstellt. Das Ergebnis unterscheidet sich in dem Fall zwar nicht von ggdag(), allerdings können damit Modifikationen für komplexere Szenarien vorgenommen werden. ggplot(dag, aes(x = x, y = y, xend = xend, yend = yend)) + geom_dag_point() + geom_dag_edges() + geom_dag_text(col = &quot;white&quot;) + theme_dag() 8.14 Anwendungsbeispiel Wir werden uns abschließend in diesem Kapitel anhand eines Eye-Tracking Datensatzes namens eye_tracking anschauen, wie wir mithilfe der bisher gelernten Funktionen, eine komplexere und optische ansprechende Abbildung kreieren können. In diesem Datensatz wurden zwei Studien miteinander verglichen, die mithilfe von Eye-Tracking die Anzahl der angeschauten Gesichter gezählt haben. Dabei wurde unterschieden, wie viele Einwohner pro Quadratkilometer dargestellt wurden. eye_tracking # A tibble: 125 × 3 Face_sum Density Group &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 1 86 2.30 Study 1 2 44 1.73 Study 1 3 156 3.66 Study 1 4 32 2.55 Study 1 # … with 121 more rows Die Ergebnisse der beiden Studien sollen anhand eines gruppierten Streudiagramms mit Regressionsgeraden verglichen werden (siehe Kapitel 8.3). Zusätzlich werden gruppierte Wahrscheinlichkeitsdichten zur Darstellung der Verteilungen abgebildet (siehe Kapitel 8.2). Das gewünschte Resultat ist in Abbildung 8.28 illustriert. Abbildung 8.28: Anzahl fixierter Gesichter in Abhängigkeit beobachteter Einwohner pro Quadratkilometer. Diese Abbildung besteht im Prinzip aus vier Teilen, welche nacheinander erstellt und dann miteinander kombiniert werden müssen. Links unten ist unsere Hauptabbildung, mit bereits bekannten Komponenten. Um den notwendigen Code besser zu verstehen, gehen wir erst durch, was wir zur Visualisierung benötigen. Erstelle den ggplot mit der Bevölkerungsdichte auf der x-Achse und den fixierten Gesichtern auf der y-Achse, wobei die Farbe gruppiert nach der jeweiligen Studie gewählt werden soll. Füge ein nach Studienart gruppiertes Streudiagramm mit angepasster Größer der Punkte und reduzierter Deckkraft hinzu. Zeichne einen schwarzen Ring um jeden Punkt des Streudiagramms. Berechne die linearen Regressionsgeraden, welche sich über die komplette Abbildung erstrecken sollen und blende dabei die Konfidenzintervalle aus. Anschließend soll die Abbildung noch verschönert werden. Ändere die x-Achsen und y-Achsen Beschriftung. Verwende anstelle der Standardfarben eine Farbpalette (z.B. viridis), welche auch von Menschen mit Farbenblindheit unterschieden werden kann. Im Zuge dessen sollen der Titel der Legende sowie die Namen der Merkmale angepasst werden. Passe die Begrenzungen der x-Achse und y-Achse an. Verändere das generelle Thema sowie die Schriftgrößen. Verschiebe die Legende und ordne sie horizontal an. Die Hauptabbildung wird schließlich als plot1 gespeichert. plot1 &lt;- ggplot(eye_tracking, aes(x = Density, y = Face_sum, color = Group)) + geom_point(size = 3, alpha = 0.8) + geom_point(shape = 1, color = &quot;black&quot;, size = 3) + stat_smooth(method = &quot;lm&quot;, fullrange = TRUE, se = FALSE) + labs( x = &quot;Einwohner pro Quadratkilometer&quot;, y = &quot;Anzahl fixierter Gesichter&quot;, ) + scale_color_viridis_d( begin = 0.2, end = 0.7, option = &quot;D&quot;, name = &quot;Studie:&quot;, labels = c(&quot;1&quot;, &quot;2&quot;) ) + scale_y_continuous( limits = c(0, 225), expand = c(0, 0), breaks = seq(from = 0, to = 225, by = 25) ) + scale_x_continuous( limits = c(0.5, 4), expand = c(0, 0), breaks = seq(from = 0.5, to = 4, by = 0.5) ) + theme_classic(base_size = 14) + theme(legend.position = c(0.25, 0.95), legend.direction = &quot;horizontal&quot;) Bei den beiden Wahrscheinlichkeitsdichten wird erst die Bevölkerungsdichte auf der x-Achse in der einen und die Anzahl fixierter Gesichter auf der y-Achse in der anderen Abbildung übergeben. Beide Abbildungen sollen eine etwas niedriger Deckkraft als die Hauptabbildung haben, da sich beide Verteilungen überschneiden werden. Abschließend müssen wir das Thema (auch die Achsen) mithilfe von theme_void() vollständig ausblenden. Auch die Legende muss manuell entfernt werden. Gespeichert werden die beiden Ergebnisse als dens1 und dens2. dens1 &lt;- ggplot(eye_tracking, aes(x = Density, fill = Group)) + geom_density(alpha = 0.6) + theme_void() + theme(legend.position = &quot;none&quot;) dens2 &lt;- ggplot(eye_tracking, aes(y = Face_sum, fill = Group)) + geom_density(alpha = 0.6) + theme_void() + theme(legend.position = &quot;none&quot;) Als letzten Schritt fügen wir die einzelnen Teile zusammen (siehe Kapitel 8.11). Die Funktion plot_spacer() füllt dabei den leeren Raum oben rechts in der Abbildung aus. Innerhalb von plot_layout() verwenden wir die Argumente widths und heights, welche die Verhältnisse zwischen der Hauptabbildung und den Dichten festlegen. Schließlich soll die Wahrscheinlichkeitsdichte oben links und unten rechts kleiner dargestellt werden als unsere Hauptabbildung unten links. Abschließend muss noch die Füllfarbe für dens1 und dens2 angepasst werden. Beachte an dieser Stelle das Hinzufügen der Funktion mithilfe von &amp; anstelle von +. dens1 + plot_spacer() + plot1 + dens2 + plot_layout(ncol = 2, nrow = 2, widths = c(4, 1), heights = c(1, 4)) &amp; scale_fill_viridis_d(begin = 0.2, end = 0.7, option = &quot;D&quot;) "],["inductive.html", "Kapitel 9 Inferenzstatistik 9.1 Einführung 9.2 Ein- und Zweistichprobenszenarien 9.3 Unterschiede mehrerer Gruppen 9.4 Korrelationskoeffizienten 9.5 Regressionsmodelle 9.6 Kontingenztafeln 9.7 Voraussetzungen überprüfen 9.8 Ergebnisse formatieren", " Kapitel 9 Inferenzstatistik In diesem Kapitel wird die Umsetzung der gängigsten statistischen Modelle in R gezeigt. Dabei liegt der Fokus klar auf der Programmierung und nicht auf dem für die Interpretation notwendigen Statistikwissen. Letzteres sollte aus einem der angegeben Statistikbüchern entnommen werden. Durch diese strikte Trennung können wir in den Unterkapiteln auch fortgeschrittenere Modelle betrachten, die in anderen Programmierbüchern leider häufig ausgelassen werden. Nach diesem Kapitel kannst du (fast) alle deiner Forschungsfragen mit R beantworten. 9.1 Einführung In diesem Kapitel wird die Umsetzung verschiedener in der Praxis häufig verwendeter statistischer Modelle in R gezeigt. Die Ausgabe der Statistikfunktionen sieht dabei immer ähnlich aus und enthält die wesentlichen Informationen. Die Funktionen um diese Ergebnisse so zu formatieren, dass sie als Tabelle nach Word oder in ein PDF exportiert werden können, werden in Kapitel 9.8 eingeführt. In den folgenden Kapiteln werden wir den big5 Datensatz aus dem remp Package verwenden. big5 # A tibble: 200 × 7 Alter Geschlecht Extraversion Neurotizismus O1 O2 O3 &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 36 m 3 1.9 5 1 5 2 30 f 3.1 3.4 5 3 5 3 23 m 3.4 2.4 3 3 5 4 54 m 3.3 4.2 2 5 3 # … with 196 more rows Es gibt mit einer Ausnahme nur sechs verschiedene Arten, den in R enthaltenen Funktionen für statistische Modelle Variablen zu übergeben. Bei der Auflistung steht df für Datensatz, AV für abhängige Variable und UV für unabhängige Variable. Einstichproben-Szenario: x = df$Spalte1 Vergleich zweier Vektoren: x = df$Spalte1, y = df$Spalte2 Vergleich zwischen Kategorien: x ~ Kategorie Untersuchung einer abhängigen Variable und einer unabhängigen Variable: AV ~ UV1 Untersuchung einer abhängigen Variable und mehreren unabhängigen Variablen: AV ~ UV1 + UV2 Untersuchung einer abhängigen Variable und mehreren unabhängigen Variablen mit Interaktion: AV ~ UV1 * UV2 9.2 Ein- und Zweistichprobenszenarien 9.2.1 t Test und Welch Test Für den Einstichproben t Test müssen wir die Spalte Extraversion aus dem Datensatz big5 herausziehen. Die zu testende Hypothese kann mit dem mu Argument entsprechend angepasst werden. t.test(big5$Extraversion) One Sample t-test data: big5$Extraversion t = 125.51, df = 199, p-value &lt; 2.2e-16 alternative hypothesis: true mean is not equal to 0 95 percent confidence interval: 3.027672 3.124328 sample estimates: mean of x 3.076 Eine einseitige Hypothese kann durch Umstellung des alternative Arguments auf \"less\" oder \"greater\" getestet werden. Die Standardeinstellung ist ein zweiseitiger Test. Das \\(\\alpha\\)-Niveau kann über das Argument conf.level modifiziert werden, welches mit 0.95 (also einem \\(\\alpha\\) von 5%) voreingestellt ist. Ein Vergleich zwischen zwei metrischen Merkmalen erfolgt durch die Eingabe zweier Vektoren. Für den t-Test nehmen wir außerdem gleiche Varianzen an (var.equal = TRUE). Bei einem Welch Test müsste das Argument var.equal auf FALSE gesetzt werden. t.test(x = big5$Alter, y = big5$Extraversion, var.equal = TRUE) Für einen Mittelwertsvergleich zwischen zwei Gruppen (hier Männer und Frauen) nutzen wir die Formelsyntax. Auf der linken Seite der Tilde ist die metrische Variable und auf der rechten Seite die kategoriale Variable eingetragen. t.test(Extraversion ~ Geschlecht, data = big5, var.equal = TRUE) Two Sample t-test data: Extraversion by Geschlecht t = -1.2746, df = 198, p-value = 0.2039 alternative hypothesis: true difference in means between group f and group m is not equal to 0 95 percent confidence interval: -0.16152463 0.03469536 sample estimates: mean in group f mean in group m 3.050000 3.113415 Für einen Test auf abhängige Stichproben, kann das paired Argument hinzugefügt werden. Anders als hier müssten für einen gepaarten t Test oder Welch Test gleich viele Werte in beiden Gruppen vorhanden sein. t.test(Extraversion ~ Geschlecht, data = big5, paired = TRUE) 9.2.2 Wilcoxon Test Der Wilcoxon Test für unabhängige Stichproben wird auch Mann-Whitney U-Test genannt. Hierbei handelt es sich um einen nicht-parametrischen Test, welcher bei Verletzungen der Annahmen von Normalverteilung und Varianzhomogenität Anwendung findet. Die Formelsyntax bleibt dabei dieselbe wie beim t Test. wilcox.test(Extraversion ~ Geschlecht, data = big5) Wilcoxon rank sum test with continuity correction data: Extraversion by Geschlecht W = 4265, p-value = 0.1528 alternative hypothesis: true location shift is not equal to 0 Auch beim Wilcoxon Test können abhängige Stichproben berücksichtigt werden (z.B. bei Messwiederholung). wilcox.test(Extraversion ~ Geschlecht, paired = TRUE, data = big5) 9.3 Unterschiede mehrerer Gruppen 9.3.1 Varianz- und Kovarianzanalyse Für Varianzanalysen (auch ANOVA genannt) mit Typ 2 und Typ 3 Quadratsummen muss in R das car Package installiert und geladen werden. library(car) Mit aov() (Akronym für analysis of variances, engl. für Varianzanalyse) wird das eigentliche Modell aufgestellt. Auf der linken Seite der Tilde steht die abhängige Variable und auf der rechten Seite eine oder mehrere durch ein Pluszeichen kombinierte unabhängige Variablen. Das Ausgeben der Ergebnisse erfolgt mit der Funktion Anova() aus dem car Package. result &lt;- aov(Extraversion ~ Gruppe + Alter, data = big5_mod) Anova(result, type = 3) Anova Table (Type III tests) Response: Extraversion Sum Sq Df F value Pr(&gt;F) (Intercept) 100.840 1 850.7365 &lt;2e-16 *** Gruppe 0.314 2 1.3235 0.2686 Alter 0.084 1 0.7052 0.4021 Residuals 23.232 196 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Um die Interaktion der Kovariaten zu berücksichtigen, verwenden wir alternativ das Pluszeichen mit einem Asterisk (bzw. Multiplikationszeichen). Dabei muss die interagierende Variable metrisches Skalenniveau haben, was einer sogenannten ANCOVA (Akronym für analysis of covariance, engl. für Kovarianzanalyse) entspricht. result2 &lt;- aov(Extraversion ~ Gruppe * Alter, data = big5_mod) Anova(result2, type = 3) Anova Table (Type III tests) Response: Extraversion Sum Sq Df F value Pr(&gt;F) (Intercept) 55.687 1 471.7948 &lt;2e-16 *** Gruppe 0.410 2 1.7388 0.1785 Alter 0.083 1 0.7067 0.4016 Gruppe:Alter 0.334 2 1.4152 0.2454 Residuals 22.898 194 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Die Interaktionseffekte werden mit einem Doppelpunkt in der Ausgabe markiert (hier Geschlecht:Alter). Für die genaue Untersuchung des Haupteffekts Gruppe, müssen wir bei statistischer Signifikanz noch einen Post-Hoc Test durchführen. Eine Möglichkeit dafür ist der Test von Tukey mit der Funktion TukeyHSD() (Akronym für Honest Significant Differences). TukeyHSD(result, &quot;Gruppe&quot;) Tukey multiple comparisons of means 95% family-wise confidence level Fit: aov(formula = Extraversion ~ Gruppe + Alter, data = big5_mod) $Gruppe diff lwr upr p adj Mittel-Jung 0.008320251 -0.1381335 0.15477398 0.9901253 Weise-Jung -0.210544218 -0.4379624 0.01687397 0.0760155 Weise-Mittel -0.218864469 -0.4721886 0.03445966 0.1053580 Eine Alternative dazu stellt der t Test dar, welcher die einzelnen Gruppen bezüglich der Extraversion paarweise vergleicht. Dafür müssen wir der Funktion pairwise.t.test() die entsprechenden Spalten als Vektoren übergeben. pairwise.t.test(big5_mod$Extraversion, big5_mod$Gruppe) Pairwise comparisons using t tests with pooled SD data: big5_mod$Extraversion and big5_mod$Gruppe Jung Mittel Mittel 0.89 - Weise 0.09 0.09 P value adjustment method: holm 9.3.2 Varianzanalyse mit Messwiederholung Für die Berechnung von Varianzanalysen mit Messwiederholung benötigen wir das Package afex und für die Post-Hoc Tests das emmeans Package. library(afex) library(emmeans) Bevor wir zur Berechnung kommen, müssen wir den Datensatz erst in ein langes Format umwandeln (siehe Kapitel 6.6). big5_long &lt;- big5_mod |&gt; pivot_longer( cols = Extraversion:Neurotizismus, names_to = &quot;Faktor&quot;, values_to = &quot;Auspraegung&quot; ) Anschließend übergeben wir innerhalb der Funktion aov_4() auf der linken Seite der Tilde die abhängige Variable und auf der rechten Seite der Tilde die unabhängigen Variablen. Innerhalb runder Klammern werden die Innersubjektfaktoren (hier Faktor) geschrieben, gegeben (|) dem Personenidentifikator (hier ID). result2 &lt;- aov_4(Auspraegung ~ Gruppe + (Faktor | ID), data = big5_long) result2 Anova Table (Type 3 tests) Response: Auspraegung Effect df MSE F ges p.value 1 Gruppe 2, 197 0.30 2.69 + .014 .070 2 Faktor 1, 197 0.27 0.10 &lt;.001 .749 3 Gruppe:Faktor 2, 197 0.27 1.60 .008 .205 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;+&#39; 0.1 &#39; &#39; 1 Als Post-Hoc Test können wir in diesem Fall die geschätzten Randsummen mithilfe von emmeans() (Akronym für estimated marginal means) ausgeben lassen. post_aov &lt;- emmeans(result2, ~ Gruppe) post_aov Gruppe emmean SE df lower.CL upper.CL Jung 3.14 0.0321 197 3.08 3.20 Mittel 3.03 0.0624 197 2.91 3.15 Weise 2.93 0.1042 197 2.73 3.14 Results are averaged over the levels of: Faktor Confidence level used: 0.95 Für Signifikanztests der jeweiligen Vergleiche können wir die Randsummen der Funktion pair() übergeben. pairs(post_aov) contrast estimate SE df t.ratio p.value Jung - Mittel 0.1097 0.0702 197 1.563 0.2642 Jung - Weise 0.2083 0.1090 197 1.911 0.1382 Mittel - Weise 0.0986 0.1214 197 0.812 0.6959 Results are averaged over the levels of: Faktor P value adjustment: tukey method for comparing a family of 3 estimates 9.3.3 Kruskal-Wallis Test Der Kruskal-Wallis Test wird angewendet, wenn wir mehr als zwei Gruppen untersuchen und wir nicht von Normalverteilung und Varianzhomogenität ausgehen können. Auch hier ist auf der linken Seite der Tilde die abhängige und auf der linken Seite die unabhängige Variable. kruskal.test(Extraversion ~ Gruppe, data = big5_mod) Kruskal-Wallis rank sum test data: Extraversion by Gruppe Kruskal-Wallis chi-squared = 4.6538, df = 2, p-value = 0.0976 9.3.4 Friedman Test Den Friedman Test verwenden wir in denselben Anwendungsfällen wie den Kruskal-Wallis Test mit dem Unterschied, dass hier Innersubjektfaktoren betrachtet werden. Wir benötigen daher wie im Kontext der Varianzanalyse mit Messwiederholung in Kapitel 9.3.2 den Datensatz wieder im langen Format (siehe Kapitel 6.6). Die Syntax unterscheidet sich nur insofern, als dass wir keine Klammern um den Messwiederholungsterm auf der rechten Seite der Tilde schreiben. friedman.test(Auspraegung ~ Faktor | ID, data = big5_long) Friedman rank sum test data: Auspraegung and Faktor and ID Friedman chi-squared = 1.3474, df = 1, p-value = 0.2457 9.4 Korrelationskoeffizienten Mit der Funktion cor.test() können die Produkt-Moment Korrelation nach Pearson (“pearson”), die Rangkorrelation nach Spearman (\"spearman\") oder nach Kendall (\"kendall\") angewendet werden. Dafür muss lediglich das method Argument entsprechend angepasst werden. Als Argumente übergeben wir außerdem die beiden numerischen Spalten, die wir mit dem Dollar-Operator aus dem Datensatz herausziehen müssen. 9.4.1 Produkt-Moment Korrelation nach Pearson cor.test(big5$Extraversion, big5$Neurotizismus, method = &quot;pearson&quot;) Pearson&#39;s product-moment correlation data: big5$Extraversion and big5$Neurotizismus t = 0.98352, df = 198, p-value = 0.3266 alternative hypothesis: true correlation is not equal to 0 95 percent confidence interval: -0.06968989 0.20646897 sample estimates: cor 0.06972529 9.4.2 Rangkorrelation nach Spearman cor.test(big5$Extraversion, big5$Neurotizismus, method = &quot;spearman&quot;) 9.4.3 Kendall-Tau Korrelation cor.test(big5$Extraversion, big5$Neurotizismus, method = &quot;kendall&quot;) 9.5 Regressionsmodelle 9.5.1 Lineare Regression Die lm() Funktion (Akronym für lineares Modell) erstellt ein lineares Regressionsmodell. Auf der linken Seite der Tilde (~) wird die abhängige Variable und auf die rechte Seite eine oder mehrere unabhängige Variablen übergeben. Beachte an dieser Stelle, dass die unabhängigen Variablen bei Regressionsanalysen entweder binär (0, 1) oder intervallskaliert sein müssen. Die Zusammenfassung der Ergebnisse erhalten wir mit summary(). model &lt;- lm(Extraversion ~ Geschlecht + Alter, data = big5) summary(model) Call: lm(formula = Extraversion ~ Geschlecht + Alter, data = big5) Residuals: Min 1Q Median 3Q Max -0.80975 -0.25093 -0.05391 0.18644 1.24502 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 3.0570058 0.0327166 93.439 &lt;2e-16 *** Geschlechtm 0.0596565 0.0499234 1.195 0.234 Alter -0.0001192 0.0001261 -0.945 0.346 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.3461 on 197 degrees of freedom Multiple R-squared: 0.01261, Adjusted R-squared: 0.002587 F-statistic: 1.258 on 2 and 197 DF, p-value: 0.2865 Falls wir, wie bei einer Varianzanalyse, eine kategoriale Variable wie Altersgruppe (Gruppe) mit mehr als 2 Stufen innerhalb einer Regression untersuchen möchten, müssen wir zuerst sogenannte Dummy Variablen erstellen. Das heißt, wir kreieren für jede Altersgruppe außer unserer Referenzgruppe (z.B. “Jung”) eine binäre neue Spalte. Am einfachsten geht dies mit der Umwandlung in Faktoren (siehe Kapitel 6.10). big5_mod1 &lt;- big5_mod |&gt; mutate(Gruppe = as.factor(Gruppe)) Wenn die gruppierende Variable ein Faktor ist, erstellt R von selbst die Dummy Variablen und gibt die \\(\\beta\\)-Koeffizienten mit entsprechendem Signifikanztest für jede der Faktorstufen (außer der Referenzgruppe) aus. model2 &lt;- lm(Extraversion ~ Gruppe, data = big5_mod1) summary(model2) Call: lm(formula = Extraversion ~ Gruppe, data = big5_mod1) Residuals: Min 1Q Median 3Q Max -0.68912 -0.19744 -0.08912 0.21088 1.21088 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 3.08912 0.02838 108.868 &lt;2e-16 *** GruppeMittel 0.00832 0.06197 0.134 0.8933 GruppeWeise -0.21054 0.09622 -2.188 0.0298 * --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 0.344 on 197 degrees of freedom Multiple R-squared: 0.02464, Adjusted R-squared: 0.01473 F-statistic: 2.488 on 2 and 197 DF, p-value: 0.0857 9.5.2 Lineare gemischte Regression library(lmerTest) model3 &lt;- lmer(Leukozyten ~ Alter + (Zeitpunkt | PersonID)) summary(model3) 9.5.3 Logistische Regression Falls die abhängige Variable binär (0, 1) ist, müssen wir eine logistische Regression verwenden (auch binomiales Logit Modell genannt). In R trägt die Funktion den Namen glm() (Akronym für Generalisiertes Lineares Modell). Exemplarisch erstellen wir uns zu Beginn eine binäre abhängige Variable (Geschlecht). big5_bin &lt;- big5 |&gt; mutate(Geschlecht = if_else(Geschlecht == &quot;m&quot;, 1, 0)) Nun können wir genau wie bei der linearen Regression das Modell aufstellen und mit summary() ausgeben. model4 &lt;- glm(Geschlecht ~ Extraversion + Alter, data = big5_bin) summary(model4) Call: glm(formula = Geschlecht ~ Extraversion + Alter, data = big5_bin) Deviance Residuals: Min 1Q Median 3Q Max -0.5630 -0.4113 -0.3701 0.5707 0.6859 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 0.0474582 0.3131682 0.152 0.880 Extraversion 0.1206277 0.1009469 1.195 0.234 Alter -0.0001855 0.0001793 -1.035 0.302 (Dispersion parameter for gaussian family taken to be 0.2422681) Null deviance: 48.380 on 199 degrees of freedom Residual deviance: 47.727 on 197 degrees of freedom AIC: 289.01 Number of Fisher Scoring iterations: 2 9.5.4 Multinomiales Logit Modell Zur Berechnung von multinomialen Logit Modellen muss das VGAM Package installiert und geladen sein. library(VGAM) Multinomiale Logit Modelle (auch Baseline Logit Modelle genannt) verwenden wir dann, wenn unsere abhängige Variable nicht binär ist, sondern mehrere ungeordnete Stufen hat. Hier schauen wir uns exemplarisch den Einfluss von Geschlecht und Alter auf eine Frage zur Offenheit (O1) an. Diese ist zwar eigentlich ordinal skaliert, allerdings bleiben wir einfachheitshalber bei dem Beispiel. Entscheiden ist hier das family Argument. Wir müssen festlegen, welche Faktorstufe die Referenzkategorie darstellt, mit der wir die restlichen Kategorien vergleichen wollen. Auch hier wird die Zusammenfassung mithilfe der Funktion summary() ausgegeben. model5 &lt;- vglm(O1 ~ Geschlecht + Alter, data = big5, family = multinomial(refLevel = 1)) summary(model5) Call: vglm(formula = O1 ~ Geschlecht + Alter, family = multinomial(refLevel = 1), data = big5) Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept):1 -0.43014 1.56406 -0.275 0.783 (Intercept):2 0.85767 1.50833 0.569 0.570 (Intercept):3 0.98431 1.46124 0.674 0.501 (Intercept):4 0.66895 1.46387 0.457 0.648 Geschlechtm:1 1.57251 1.20827 1.301 0.193 Geschlechtm:2 1.70249 1.16454 1.462 0.144 Geschlechtm:3 0.25837 1.15895 0.223 0.824 Geschlechtm:4 0.89654 1.15546 0.776 0.438 Alter:1 0.05434 0.06709 0.810 0.418 Alter:2 0.02951 0.06614 0.446 0.655 Alter:3 0.06521 0.06442 1.012 0.311 Alter:4 0.06540 0.06442 1.015 0.310 Names of linear predictors: log(mu[,2]/mu[,1]), log(mu[,3]/mu[,1]), log(mu[,4]/mu[,1]), log(mu[,5]/mu[,1]) Residual deviance: 534.8599 on 788 degrees of freedom Log-likelihood: -267.43 on 788 degrees of freedom Number of Fisher scoring iterations: 9 No Hauck-Donner effect found in any of the estimates Reference group is level 1 of the response 9.5.5 Kumulatives Logit Modell Zur Berechnung von kumulativen Logit Modellen muss das VGAM Package installiert und geladen sein. library(VGAM) Kumulative Logit Modelle (auch Proportional Odds Model genannt) verwenden wir bei ordinal skalierter abhängiger Variable. Die Variable O1 ist eine Frage zur Offenheit, die von 0 (trifft gar nicht zu) bis 5 (trifft zu) bewertet wird. Im Vergleich zu Baseline Logit Modellen verändert sich an dieser Stelle nur das family Argument. Hier müssen wir die cumulative() Funktion verwenden. model6 &lt;- vglm(O1 ~ Geschlecht + Alter, data = big5, family = propodds) summary(model6) Call: vglm(formula = O1 ~ Geschlecht + Alter, family = propodds, data = big5) Coefficients: Estimate Std. Error z value Pr(&gt;|z|) (Intercept):1 3.8522994 0.4725677 8.152 3.58e-16 *** (Intercept):2 2.0844977 0.2465282 8.455 &lt; 2e-16 *** (Intercept):3 0.7750703 0.1905505 4.068 4.75e-05 *** (Intercept):4 -0.6701122 0.1882403 -3.560 0.000371 *** Geschlechtm -0.4445943 0.2618293 -1.698 0.089502 . Alter 0.0005654 0.0007258 0.779 0.435967 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Names of linear predictors: logitlink(P[Y&gt;=2]), logitlink(P[Y&gt;=3]), logitlink(P[Y&gt;=4]), logitlink(P[Y&gt;=5]) Residual deviance: 552.8905 on 794 degrees of freedom Log-likelihood: -276.4453 on 794 degrees of freedom Number of Fisher scoring iterations: 5 Warning: Hauck-Donner effect detected in the following estimate(s): &#39;(Intercept):1&#39; Exponentiated coefficients: Geschlechtm Alter 0.6410843 1.0005655 9.5.6 Poisson Regression Zur Modellierung von Häufigkeiten (Zähldaten) wird die Poisson Regression verwendet. model7 &lt;- glm(Infektion_frequenz ~ Geschlecht + Alter, data = daten, family = poisson) summary(model7) Falls eine Over-Dispersion besteht, kann die Quasipoisson Verteilung dem entgegensteuern. model8 &lt;- glm(Infektion_frequenz ~ Geschlecht + Alter, data = daten, family = quasipoisson) summary(model8) 9.5.7 Negative Binomial Regression Für dieses Kapitel ist die Installation und das Laden des MASS Packages notwendig. library(MASS) Falls bei der Modellierung von Zähldaten eine Over-Dispersion besteht, muss anstelle der Poisson Verteilung eine negative Binomial Verteilung verwendet werden. Diese wird mit der Funktion glm.nb() umgesetzt. model9 &lt;- glm.nb(Infektion_frequenz ~ Geschlecht + Alter, data = daten) summary(model9) 9.5.8 Cox Regression Zur Berechnung eines Cox Proportional Hazards Modell muss das survival Package installiert und geladen werden. library(surival) Für unser Beispiel nehmen wir uns den lung Datensatz aus dem survival Package zur Hand. lung # A tibble: 228 × 10 inst time status age sex ph.ecog ph.karno pat.karno meal.cal wt.loss &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 3 306 2 74 1 1 90 100 1175 NA 2 3 455 2 68 1 0 90 90 1225 15 3 3 1010 1 56 1 0 90 90 NA 15 4 5 210 2 57 1 1 90 60 1150 11 # … with 224 more rows Mit der Funktion coxph() wird das Modell geschätzt. Besonders ist an dieser Stelle, dass wir der Funktion keine einzelne abhängige Variable übergeben. Stattdessen verwenden wir in der Helferfunktion Surv() sowohl die Überlebenszeit in Tagen als auch die Information über den Tod bzw. das Ausscheiden aus der Studie (event = status). Falls eine Modellierung in Abhängigkeit der Start- und Endzeit gewünscht ist, kann die Startzeit dem time und die Endzeit dem time2 Argument übergeben werden. Hier schauen wir uns exemplarisch eine mögliche Assoziation der Kovariate Geschlecht mit der Überlebenszeit an. Dabei wird das biologische Geschlecht in männlich (1) und weiblich (2) kodiert. cox_res &lt;- coxph(Surv(time = time, event = status) ~ sex, data = lung) summary(cox_res) Call: coxph(formula = Surv(time = time, event = status) ~ sex, data = lung) n= 228, number of events= 165 coef exp(coef) se(coef) z Pr(&gt;|z|) sex -0.5310 0.5880 0.1672 -3.176 0.00149 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 exp(coef) exp(-coef) lower .95 upper .95 sex 0.588 1.701 0.4237 0.816 Concordance= 0.579 (se = 0.021 ) Likelihood ratio test= 10.63 on 1 df, p=0.001 Wald test = 10.09 on 1 df, p=0.001 Score (logrank) test = 10.33 on 1 df, p=0.001 In der Ausgabe sehen wir die Ergebnisse des Likelihood Ratio, Rao Score und Wald Tests. Die entsprechende Hazard Ratio der Kovariaten kann unter exp(coef) abgelesen werden (hier 0.5880). Eine Hazard Ratio unter 1 sagt in unserem Beispiel also eine Risikoreduktion beim weiblichen Geschlecht aus. cox_res2 &lt;- survdiff(Surv(time = time, event = status) ~ sex, data = lung) summary(cox_res2) 9.6 Kontingenztafeln Für die Auswertung von Kontingenztafeln nutzen wir die in Kapitel 7.2 erstellte Vierfeldertafel, die die Extraversionsausprägung über 3 gegen das Geschlecht aufträgt. tbl &lt;- table(big5_mod$Extraversion &gt; 3, big5_mod$Geschlecht) 9.6.1 Exakter Fisher-Test Nach Erstellung der Kontingenztafel mit table() können wir diese einfach der Funktion fisher.test() übergeben. fisher.test(tbl) Fisher&#39;s Exact Test for Count Data data: tbl p-value = 0.6663 alternative hypothesis: true odds ratio is not equal to 1 95 percent confidence interval: 0.6284963 2.1062910 sample estimates: odds ratio 1.150348 Als Ausgabe erhalten wir unter anderem die Odds Ratio und das Konfidenzintervall. Auch hier können wir mit dem alternative Argument auf einseitiges Testen umstellen (“less”, “greater”). 9.6.2 Chi Quadrat Tests Für die Berechnung des \\(\\chi^2\\) Tests nach Pearson verwenden wir die Funktion chisq.test(). chisq.test(tbl) Pearson&#39;s Chi-squared test with Yates&#39; continuity correction data: tbl X-squared = 0.11804, df = 1, p-value = 0.7312 Bei abhängigen Merkmalen wird stattdessen Mcnemars \\(\\chi^2\\) Test verwendet. mcnemar.test(tbl) McNemar&#39;s Chi-squared test with continuity correction data: tbl McNemar&#39;s chi-squared = 0.67368, df = 1, p-value = 0.4118 9.7 Voraussetzungen überprüfen 9.7.1 Normalverteilung der Residuen Eine Alternative zu den hier vorgestellten Hypothesentests zur Überprüfung der Normalverteilung stellt der graphische Vergleich der Verteilungen mithilfe eines Quantil-Quantil Plots dar (siehe Kapitel 8.8). Exemplarisch werden in den folgenden Kapitel die Residuen aus dem linearen Regressionsmodell verwendet (siehe Kapitel 9.5.1). Dafür muss das broom Package installiert und geladen sein. library(broom) model &lt;- lm(Extraversion ~ Geschlecht + Alter, data = big5) resid_df &lt;- augment(model) 9.7.1.1 Shapiro-Wilk Test Beim Shapiro-Wilk Test zur Überprüfung der Normalverteilung müssen wir der Funktion shapiro.test() lediglich die entsprechende Spalte des Datensatzes mit den Residuen als Zahlenreihe übergeben. shapiro.test(resid_df$.resid) Shapiro-Wilk normality test data: resid_df$.resid W = 0.95933, p-value = 1.675e-05 Da der p-Wert hier bei einem \\(\\alpha\\) Niveau von 5% signifikant ist, würden wir an dieser Stelle von einer Verletzung der Normalverteilung sprechen. Die Annahme der Normalverteilung muss demnach abgelehnt werden. 9.7.1.2 Kolmogorov-Smirnov Test Der Kolmogorov-Smirnov Test wird fast gleich wie der Shapiro-Wilk Test angewandt. Mit dem y Argument muss man allerdings zusätzlich die Verteilung, mit der wir die Spalte der Residuen (.resid) vergleichen (hier Normalverteilung), explizit festlegen. ks.test(resid_df$.resid, &quot;rnorm&quot;) Asymptotic one-sample Kolmogorov-Smirnov test data: resid_df$.resid D = 3.2359, p-value &lt; 2.2e-16 alternative hypothesis: two-sided Der Kolmogorov-Smirnov Test funktioniert nur, wenn es keine doppelten Werte gibt, was bei intervallskalierten Merkmalen in der Regel gegeben ist. 9.7.2 Varianzhomogenität 9.7.2.1 F Test Mit dem F Test können wir die Hypothese der Varianzgleichheit zwischen zwei Gruppen (hier Männer und Frauen) testen. var.test(Extraversion ~ Geschlecht, data = big5) F test to compare two variances data: Extraversion by Geschlecht F = 1.1868, num df = 117, denom df = 81, p-value = 0.413 alternative hypothesis: true ratio of variances is not equal to 1 95 percent confidence interval: 0.7871945 1.7628258 sample estimates: ratio of variances 1.186837 Da der p-Wert mit 0.413 größer als 0.05 (häufig gewähltes \\(\\alpha\\) Niveau) ist, würden wir hier von Varianzhomogenität (Varianzgleichheit) ausgehen. Wir erhalten außerdem den F Wert, die Freiheitsgrade und das Konfidenzintervall. 9.7.2.2 Levene Test Für dieses Kapitel muss das car Package installiert und geladen werden. library(car) Nun können wir der Funktion leveneTest() in gewohnter Formelsyntax die Spalten Extraversion und Geschlecht des Datensatzes big5 übergeben. leveneTest(Extraversion ~ Geschlecht, data = big5) Levene&#39;s Test for Homogeneity of Variance (center = median) Df F value Pr(&gt;F) group 1 1e-04 0.9923 198 Wir erhalten auch hier die Freiheitsgrade, Teststatistik und den p-Wert. Dabei kommen wir ausgehend vom p-Wert auf den gleichen Schluss wie beim F Test. Der Vorteil des Levene und des Bartletts Test ist der, dass wir innerhalb einer Funktion die Varianz mehrere Gruppen miteinander vergleichen können. 9.7.2.3 Bartletts Test Der Bartlett Test funktioniert genau wie die beiden bisher eingeführten Tests zur Überprüfung der Varianzhomogenität. bartlett.test(Extraversion ~ Geschlecht, data = big5) Bartlett test of homogeneity of variances data: Extraversion by Geschlecht Bartlett&#39;s K-squared = 0.69049, df = 1, p-value = 0.406 Auch hier kommen wir auf dieselbe Schlussfolgerung der vorhandenen Varianzhomogenität zwischen Männern und Frauen hinsichtlich der mittleren Extraversionsausprägung. 9.8 Ergebnisse formatieren Für das Umformatieren in tibbles, die wiederum in Tabellenform exportiert werden können, muss das broom Package installiert und geladen werden. library(broom) Als Beispiel verwenden wir das lineare Regressionsmodell aus Kapitel 9.5.1. model &lt;- lm(Extraversion ~ Geschlecht + Alter, data = big5) Die wichtigsten Informationen werden mit der Funktion tidy() ausgeben, welche nur das Modell als Argument benötigt. tidy(model) # A tibble: 3 × 5 term estimate std.error statistic p.value &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) 3.06 0.0327 93.4 4.12e-165 2 Geschlechtm 0.0597 0.0499 1.19 2.34e- 1 3 Alter -0.000119 0.000126 -0.945 3.46e- 1 Zusätzliche Informationen wie die Varianzaufklärung oder Informationskriterien erhalten wir mit glance(). glance(model) # A tibble: 1 × 12 r.squared adj.r.squared sigma statis…¹ p.value df logLik AIC BIC devia…² df.re…³ nobs &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; 1 0.0126 0.00259 0.346 1.26 0.286 2 -70.1 148. 161. 23.6 197 200 # … with abbreviated variable names ¹​statistic, ²​deviance, ³​df.residual Die Residuen erhalten wir mithilfe von augment(). augment(model) # A tibble: 200 × 9 Extraversion Geschlecht Alter .fitted .resid .hat .sigma .cooksd .std.resid &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 3 m 36 3.11 -0.112 0.0122 0.347 0.000439 -0.327 2 3.1 f 30 3.05 0.0466 0.00858 0.347 0.0000527 0.135 3 3.4 m 23 3.11 0.286 0.0122 0.346 0.00285 0.832 4 3.3 m 54 3.11 0.190 0.0123 0.347 0.00126 0.552 # … with 196 more rows Während tidy() für alle hier vorgestellten statistischen Modellen funktioniert (außer der Varianzanalyse mit Messwiederholung), können glance() und augment() nicht immer angewendet werden. Die aktuelle Liste der unterstützten Funktion kann in der Dokumentation des broom Packages eingesehen werden. "],["ergebnisse-exportieren.html", "Kapitel 10 Ergebnisse exportieren 10.1 Wichtige Begriffe 10.2 Berichte erstellen 10.3 Tabellen umwandeln 10.4 Alternative mit Quarto", " Kapitel 10 Ergebnisse exportieren Nachdem alle Berechnungen mit R durchgeführt wurden, möchte man in der Regel die erstellten Tabellen und Abbildungen in das für die wissenschaftliche Arbeit verwendete Textverarbeitungsprogramm einfügen. Die Ergebnisse einfach aus der Konsole zu kopieren und bspw. in Word einzufügen sieht allerdings schlecht aus und benötigt nachträglich einige Formatierungen. Glücklicherweise gibt es zwei Erweiterungen, mit denen man die Ergebnisse aus R direkt in PDFs oder Word-Dokumente, Internetseiten oder LaTeX Code umwandeln kann. Auf diese Weise können nicht nur einzelne Tabellen, sondern ganze Paper oder Bücher erstellt werden. 10.1 Wichtige Begriffe Während der Datenanalyse werden alle Auswertungen zunächst nur innerhalb von RStudio angezeigt. Die Ergebnisse aus R in ein anderes Format zu bringen, hat vor allem zwei Vorteile: Die Auswertungen können auch mit KollegInnen und BetreuerInnen besprochen werden, die kein R installiert haben. Tabellen und Abbildungen müssen nicht erst in Word oder einem anderen Programm manuell erstellt werden. Bevor wir uns in den folgenden Kapiteln anschauen, wie das genau funktioniert, müssen wir zunächst einige Begrifflichkeiten klären. In R existiert eine Erweiterung namens R Markdown, welche die Ergebnisse aus R in Word, PDF oder Internetseiten umwandeln kann. HTML. Das sogenannte Hypertext Markup Language (HTML) Format ist das strukturelle Rückrad des Internets. Es gibt die Form von Internetseiten vor, die von Browsern wie Firefox, Chrome oder Brave dargestellt wird. Aber auch ohne Internet können HTML Dateien im Browser geöffnet werden. Dadurch ist es sehr praktisch zum gegenseitigen Teilen von Inhalten, da jeder und jede einen Browser auf dem Computer installiert hat. Markdown. Um das Erstellen von Inhalten in HTML Dokumenten einfacher zu gestalten, wurde Markdown erfunden. Es bietet eine deutlich einfachere Syntax zum Bearbeiten eines Textes und wird heute von vielen Programmen verwendet (z.B. Notion oder Obsidian). YAML. Damit nicht nur das Schreiben von Texten sondern auch die Konfigurationen leichter werden, gibt es YAML (Akronym für yet another markup language). Dabei werden verschiedene Optionen durch Einrücken voneinander abgegrenzt und sind so für das menschliche Auge gut lesbar. R Markdown. Die Funktionen von Markdown werden von R Markdown erweitert, um diese nicht nur für HTML Dateien sondern auch für Word- und PDF-Dokumente anzuwenden. So ist es möglich, eine R Markdown Datei zu verwenden, die mit derselben Basis in Word, PDF und HTML umgewandelt werden kann. Das rmarkdown Package ist dabei direkt in RStudio integriert. Es handelt sich bei R Markdown nicht um ein R Skript, sondern um einen eigenes Dateiformat, welches mit .Rmd und nicht mit .R endet. Quarto. Eine neuere Alternative zu R Markdown ist Quarto. Auch hier handelt es sich um ein eigenes Dateiformat, welches mit .qmd endet. Die Anwendung der beiden Formate ist grundsätzlich sehr ähnlich. Unterschiede und mögliche Vorteile werden in der folgenden Info-Box diskutiert. Pandoc. Die Umwandlung der Dateien findet hinter den Kulissen mithilfe von Pandoc statt. Da Pandoc seit der RStudio Version 1.3 vorinstalliert ist, muss du dir darum keine Gedanken mehr machen. Wer eine ältere Version auf dem Computer hat, muss Pandoc manuell unter https://pandoc.org/installing.html herunterladen. Für das Umwandeln von R Markdown Dateien in Word durch Pandoc ist außerdem eine Installation von Microsoft Office oder LibreOffice auf dem Computer notwendig. LaTeX. Das zuvor beschriebene Pandoc formiert die Datei in LaTeX um, welches wiederum für das Kreieren des PDFs verantwortlich ist. LaTeX wird in abgeänderter Form bereits seit Ende der 70er Jahre vor allem von NaturwissenschaftlerInnen für die Erstellung wissenschaftlicher Arbeiten verwendet wird. Es ist notwendig, dieses Programm auf dem Computer installiert zu haben, wenn man seine Analyse in ein PDF umwandeln möchte. Für R Nutzer ist die einfachste Installation über das tinytex Package. Dafür muss zuerst das Package installiert werden. Anschließend erfolgt mit install_tinytex() die Installation von LaTeX. install.packages(&quot;tinytex&quot;) tinytex::install_tinytex() Alternativ kann auf Windows MiKTeX, auf macOS MacTeX und auf Linux LiveTeX installiert werden. Dies erfolgt unabhängig von R durch Befolgen der jeweiligen Installationsanweisungen auf der entsprechenden Internetseite. Das Unternehmen Posit (EntwicklerInnen von RStudio) hat eine Alternative zu R Markdown namens Quarto entwickelt. Der Aufbau von R Markdown und Quarto Dateien ist dabei sehr ähnlich, weswegen es kaum einen Unterschied macht, für welches Programm man sich zunächst entscheidet. R Markdown existiert deutlich länger, weswegen es diverse Erweiterungen und Dokumentation dafür gibt. Einige dieser Erweiterungen sind ohne Zusatzpakete direkt in Quarto integriert. Tendenziell sehen die Umwandlungen mit Quarto etwas moderner aus. Außerdem kann Quarto besser mit anderen Programmiersprachen wie Python oder Julia verwendet werden. Für welches dieser Formate man sich letzten Endes entscheidet, hängt von der persönlichen Präferenz und dem eigenen Anwendungsgebiet ab. 10.2 Berichte erstellen Für dieses Kapitel muss das knitr Package installiert und geladen werden. library(knitr) Öffne zum Erstellen von R Markdown Dokumenten (Endung .Rmd) das Dropdown-Menü mit dem Papier und dem grünen Pluszeichen unter dem Reiter File. Abbildung 10.1: Erster Schritt in der Erstellung eines neuen R Markdown Skripts. Wähle in diesem Reiter R Markdown aus. Die Punkte implizieren, dass noch weitere Informationen vor dem Erstellen notwendig sind. Anschließend kann man das gewünschte Ausgabeformat, den Titel und Autor festlegen. Beim Bestätigen auf OK wird eine Vorlage erstellt, die man nach Belieben anpassen kann. Abbildung 10.2: Zweiter Schritt zur Erstellung eines neuen R Markdown Skripts. Die wichtigsten Formatierungsmöglichkeiten in Markdown sehen wie folgt aus: Fett gedruckt: **fett** ergibt fett Kursiv: *kursiv* ergibt kursiv Code Integration im Text: `mean(x)` ergibt mean(x) Links: [Klicke hier](https://cran.r-project.org/) wird zu: Klicke hier (im gebundenen Buch sind Links nicht extra farblich hervorgehoben) Überschriften können mit einer führenden Raute (# Überschrift 1) erstellt werden. Für Abschnitte innerhalb des Hauptkapitels können beliebig viele Rauten hinzugefügt werden (z.B. ## Unterkapitel 1). Um das etwas abstrakte Konzept verständlicher zu machen, soll an dieser Stelle eine ganze R Markdown Datei namens Beispiel.Rmd abgebildet werden. Zu Beginn des Dokumentes befindet sich der YAML-Kopf, in dem verschiedene Optionen angepasst werden können (siehe Kapitel 10.1). Wir beschränken uns hier auf die Auswahl des Titels, des Autors, des Datums sowie einer optisch ansprechenden Abbildung der Tabellen (df_print: paged oder df_print: kable). Beachte im Kontext von YAML immer die richtige Einrückung der Optionen. Nach erfolgreicher Definition der Optionen können wir grau hinterlegte Code Blöcke mithilfe von drei Backticks (```) erstellen. Diese erlauben das Ausführen von R Funktionen. Den Backticks folgen geschweifte Klammern. Die erste Information ist die verwendete Programmiersprache (hier R). Weitere Einstellungen dieses Code Blocks werden in den Zeilen darunter mit einer Hashpipe (#|) festgelegt (z.B. #| label: FALSE). Die einzelnen Optionen werden mit einem Doppelpunkt und nicht mit einem Gleichheitszeichen übergeben. Im ersten Code Block laden wir alle Packages und Datensätze. Auch Vorberechnungen, die später nicht dargestellt werden sollen, würden an dieser Stelle ihren Platz finden. Durch die Option include: FALSE wird der Inhalt zwar ausgeführt, aber nicht angezeigt. Eine weitere Option zum Ausblenden des Codes ist das Argument echo, welches ebenfalls auf FALSE gesetzt werden kann. So können bspw. ausschließlich die Ergebnisse in Form von Tabellen ohne zugehörigen R Code angezeigt werden. – Beginn der Datei Beispiel.Rmd – --- title: &quot;Vorläufige Ergebnisse&quot; author: &quot;Student A&quot; date: &quot;2023-01-13&quot; output: html_document: df_print: paged pdf_document: df_print: kable word_document: df_print: kable --- ```{r} #| label: setup #| include: FALSE library(tidyverse) library(remp) library(knitr) options(dplyr.summarise.inform = FALSE) data(big_five) ``` ## Deskriptive Statistik Verschiedene Lagemaße wie Minimum, 1. Quartil, Mittelwert, Median, 3. Quartil, Maximum, Standardabweichung und Standardfehler. ```{r} big_five |&gt; descriptive() ``` ## Visualisierung Ein Streudiagramm zur anschaulichen Darstellung des Zusammenhangs zwischen **Extraversion** und **Neurotizismus**. ```{r} #| echo: FALSE #| fig.cap: &quot;Streudiagramm zur Extraversion und Neurotizismus.&quot; ggplot(big_five, aes(x = Extraversion, y = Neurotizismus)) + geom_point(position = &quot;jitter&quot;) ``` – Ende der Datei Beispiel.Rmd – Die Ausgabe nach Umwandlung in ein HTML Dokument ist in Abbildung 10.3 zu sehen. Abbildung 10.3: Umwandlung von Markdown in HTML. Jedes R Markdown Dokument hat die Endung .Rmd und beginnt mit einem so genannten YAML-Kopf, der durch drei Bindestriche oben und unten vom restlichen Dokument abgegrenzt ist. Fortgeschrittenere Anpassungsmöglichkeiten sind im Buch R Markdown - The Definitive Guide von Xie, Allaire und Grolemund beschrieben. Nützliche Optionen für die Code Abschnitte: Ausschalten von Benachrichtigungen und Warnungen mit message: FALSE respektive warning: FALSE. Ausblenden des zugehörigen R Codes mit echo: FALSE. R Code anzeigen, aber nicht auswerten mit eval: FALSE. Name des Chunks zur späteren Referenz mit label: Name. Einstellen der Dimensionen einer Abbildung mit fig.height: 5 und fig.width: 10. Beschriftung der Abbildung mit fig.cap: \"Dies ist eine Abbildung.\" Zentrieren der Abbildung mit fig.align: \"center\". Umwandeln können wir das R Markdown Dokument durch Klicken auf das Wort Knit (engl. für stricken) in der Leiste unter dem Reiter der geöffneten Dateien oder durch die Tastenkombination Strg / Cmd + Shift + K. Wenn man nur auf das Symbol drückt, wird die Datei in das an erster Stelle im YAML Kopf festgelegten Format umgewandelt. Besser ist es jedoch, das Dropdown-Menü durch einen Klick auf den Pfeil nach unten zu öffnen und den gewünschten Dateityp auszuwählen. Abbildung 10.4: Umwandlung des R Markdown Skripts in HTML, PDF oder Word. R Markdown Dateien können nur umgewandelt werden, wenn alle notwendigen Informationen enthalten sind. Es müssen also innerhalb der Datei alle Packages und Datensätze explizit geladen werden. Dies trifft auch zu, obwohl man die Packages oder Datensätze möglicherweise bereits vorher verwendet hat. Man kann jede R Markdown Datei als isoliert von allem anderen in RStudio geöffneten betrachten. RStudio bietet auch einen sogenannten Visual Editor zum Bearbeiten der R Markdown oder Quarto Datei an, welcher in einer Zeile unter den Dateinamen und unter dem Knit Button als Option per Mausklick ausgewählt werden kann. Dieser übersetzt die Markdown Inhalte direkt im Dokument, um einen besseren und übersichtlicheren Eindruck zu erhalten. Alternativ kannst du auch dedizierte Markdown Editoren wie Zettlr oder Typora verwenden, welche vor allem den Vorteil einer besseren Rechtschreibprüfung bieten. 10.3 Tabellen umwandeln 10.3.1 Exportieren nach Word und PDF Für die Tabellen benötigen wir für beide Formate das knitr Package. library(knitr) Wenn keine ganzen Berichte, sondern nur Tabellen für die eigene Arbeit z.B. in Word erstellt werden sollen, vereinfacht sich die R Markdown Datei aus Kapitel 10.2. Im YAML-Kopf spezifizieren wir an dieser Stelle nur den Titel und den Ausgabetyp als Word und PDF. Alle Tabellen sollen dabei mit der kable() Funktion aus dem knitr Package erstellt werden (df_print: kable). Damit der R Code nicht angezeigt wird, muss in weiterer Folge noch die Option echo: FALSE in den entsprechenden Code Abschnitten hinzugefügt werden. – Beginn der Datei Tabelle.Rmd – --- title: &#39;Beispiel&#39; output: word_document: df_print: kable pdf_document: df_print: kable --- ```{r} #| label: setup #| include: FALSE library(tidyverse) library(knitr) library(remp) data(big_five) ``` ```{r} #| echo: FALSE big_five |&gt; select(Extraversion, Neurotizismus) |&gt; descriptive() ``` – Ende der Datei Tabelle.Rmd – Abbildung 10.5: Beispielhafter Output einer Tabelle von R Markdown in Word. Das Aussehen der Tabelle kann innerhalb von Word anschließend entsprechend angepasst werden. Allerdings solltest du die Breite einer gewöhnlichen Din A4 Seite beachten. Wenn du eine sehr große Korrelationsmatrix ausgeben möchtest, solltest du entweder eine Word Vorlage in Querformat verwenden (die Vorlage muss denselben Dateinamen wie das R Markdown Dokument haben) oder die Tabelle in Teilen abbilden lassen. Zur Umwandlung in ein Word Dokument klickt man wieder auf Knit und anschließend auf Knit to Word oder betätigt die Tastenkombination Strg / Cmd + Shift + K. Für die Umwandlung in ein PDF wählt man entsprechend Knit to PDF aus. Mit einer Code- und Textbasis können wir mit R Markdown Tabellen in Word, PDF oder HTML erstellen. Beachte dabei, dass du zum Erstellen von PDF Dokumenten LaTeX auf deinem Computer installiert haben musst (siehe Kapitel 10.1). 10.3.2 Exportieren nach LaTeX Für dieses Kapitel muss das xtable Package installiert und geladen sein. library(xtable) Es gibt auch die Möglichkeit, tibbles aus R direkt in LaTeX Code umzuwandeln, um diesen dann in die zugehörige LaTeX Datei einzufügen. In den bisherigen Kapiteln wurde LaTeX nur hinter den Kulissen von Pandoc zum Erstellen von PDFs verwendet. Falls du eine wissenschaftliche Publikation direkt in LaTeX schreibst, benötigst du allerdings den tatsächlichen LaTeX Code. Exemplarisch verwenden wir dieselben deskriptiven Lage- und Streuungsmaße wie im letzten Kapitel. erg &lt;- big_five |&gt; select(Extraversion, Neurotizismus) |&gt; descriptive() |&gt; select(Variable, Min, Mean, Median, Max, SE) erg # A tibble: 2 × 6 Variable Min Mean Median Max SE &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Extraversion 2.3 3.08 3 4.3 0.02 2 Neurotizismus 1.4 3.13 3.1 4.6 0.05 Zum Erstellen des LaTeX Codes greift man auf die Funktion xtable() aus dem gleichnamigen Package zurück. Das erste Argument ist hierbei der auszugebende Datensatz. Das zweite Argument der Funktion ist digits, mit dem man pro Spalte die Anzahl der gerundeten Nachkommastellen festlegt. Dabei können wir entweder eine einzelne Zahl eingeben und somit für alle Spalten dieselbe Rundung anwenden oder für jede Spalte die Rundung einzeln als Vektor mithilfe von c() definieren. Da in der Funktion auch die Zeilennamen berücksichtigt werden, muss der Vektor immer um eins länger sein als die Anzahl der Spalten des eigentlichen Datensatzes. Die Funktion print() mit dem Argument include.rownames verhindert anschließend, dass jede Zeile des Datensatzes nummeriert ausgegeben wird. tabelle &lt;- xtable(erg, digits = c(0, 1, 2, 2, 2, 2, 3)) print(tabelle, include.rownames = FALSE) % latex table generated in R 4.2.2 by xtable 1.8-4 package % Thu Mar 16 20:26:57 2023 \\begin{table}[ht] \\centering \\begin{tabular}{lrrrrr} \\hline Variable &amp; Min &amp; Mean &amp; Median &amp; Max &amp; SE \\\\ \\hline Extraversion &amp; 2.30 &amp; 3.08 &amp; 3.00 &amp; 4.30 &amp; 0.020 \\\\ Neurotizismus &amp; 1.40 &amp; 3.13 &amp; 3.10 &amp; 4.60 &amp; 0.050 \\\\ \\hline \\end{tabular} \\end{table} 10.4 Alternative mit Quarto Zur Erstellung eines Quarto Dokuments innerhalb von RStudio wähle links das Dropdown-Menü mit dem Papier und dem grünen Pluszeichen unter dem Reiter File aus und klicke auf Quarto Document.... Bevor die Datei erstellt wird, können noch Titel, Autor und das Ausgabeformat ausgewählt werden. Nach Betätigen der Create Taste öffnet sich ein Beispieldokument mit dem typischen Aufbau einer Quarto Datei. Auch hier startet die Datei mit einem YAML-Kopf zum Festlegen der Optionen des Dokuments. An dieser Stelle ergibt sich ein wichtiger Unterschied zu R Markdown Dateien. Während in R Markdown die Ausgabeformate mit output definiert wurden, heißt das Argument hier format. Auch die Bezeichnung der Optionen innerhalb der Formate ist anders. Wichtig ist bei Ausgabe als Internetseite (HTML-Dokument) die zusätzliche Verwendung des Arguments embed-resources, da ansonsten ein extra Ordner mit den zugehörigen Javascript und CSS Dateien erstellt wird, die für das Verhalten und Aussehen des HTML-Dokuments verantwortlich sind. Wir verwenden an dieser Stelle dasselbe Beispiel wie in Kapitel 10.2. Die einzigen Unterschiede sind der abgeänderte YAML-Kopf und die Dateiendung mit .qmd anstelle von .Rmd. – Beginn der Datei Quarto.qmd – --- title: &quot;Vorläufige Ergebnisse&quot; author: &quot;Student A&quot; date: &quot;2023-01-13&quot; format: html: embed-resources: true df-print: paged docx: df-print: kable pdf: df-print: kable --- ```{r} #| label: setup #| include: FALSE library(tidyverse) library(remp) library(knitr) options(dplyr.summarise.inform = FALSE) data(big_five) ``` ## Deskriptive Statistik Verschiedene Lagemaße wie Minimum, 1. Quartil, Mittelwert, Median, 3. Quartil, Maximum, Standardabweichung und Standardfehler. ```{r} big_five |&gt; descriptive() ``` ## Visualisierung Ein Streudiagramm zur anschaulichen Darstellung des Zusammenhangs zwischen **Extraversion** und **Neurotizismus**. ```{r} #| echo: FALSE #| fig.cap: &quot;Streudiagramm zur Extraversion und Neurotizismus.&quot; ggplot(big_five, aes(x = Extraversion, y = Neurotizismus)) + geom_point(position = &quot;jitter&quot;) ``` – Ende der Datei Quarto.qmd – Umgewandelt wird bei Quarto Dokumenten nicht mit dem Button Knit, sondern durch Render. Du kannst alternativ auch hier die Tastenkombination Strg / Cmd + Shift + K verwenden. Das Ergebnis nach Umwandlung in ein HTML-Dokument ist in Abbildung 10.6 zu sehen. Die Ausgabe unterscheidet sich nur im Aussehen von der durch R Markdown erstellten Datei. Nach Umwandlung in ein Word- oder PDF-Dokument finden sich noch weniger optische Unterschiede. Erst bei komplexeren Anwendungsfällen wirst du mögliche Vor- oder Nachteile von Quarto gegenüber R Markdown bemerken. Abbildung 10.6: Umwandlung der Quarto Datei in HTML, PDF oder Word. "],["datatypes.html", "Kapitel 11 Datenstrukturen 11.1 Vektor 11.2 Matrix 11.3 Data.frame und tibble 11.4 Liste 11.5 Umwandlungen 11.6 Objektorientierung", " Kapitel 11 Datenstrukturen Wer tiefer in R eintauchen möchte, sollte neben den bereits verwendeten tibbles ebenfalls die anderen Datenstrukturen kennenlernen. In R gibt es außerdem Vektoren, Matrizen, data.frames und Listen. Ein Vektor enthält einen oder mehrere Werte in einer Reihe desselben Datentyps. Eine Matrix erweitert den Vektor um eine zweite Dimension, kann aber ebenfalls nur denselben Datentyp beinhalten. Data.frames sind wie Matrizen zweidimensional, allerdings kann jede Spalte einen beliebigen Datentyp enthalten, der sich von den anderen Spalten unterscheidet. Eine Liste kann in jedem Element entweder Vektoren, Matrizen oder data.frames enthalten, welche auch miteinander kombiniert werden können. 11.1 Vektor Jede Spalte innerhalb eines tibbles ist für sich genommen ein Vektor, der aus einem einzigen Datentyp besteht. Erstellen kann man einen Vektor auf unterschiedliche Art und Weise. Bereits kennengelernt haben wir die c() Funktion (combine, engl. für kombinieren). c(11, 8, 24, 53) [1] 11 8 24 53 Man kann so neben numerischen Werten auch jeden anderen Datentyp zu einem Vektor kombinieren (z.B. Character). Für eine einfach Sequenz können wir den Doppelpunkt verwenden. Man könnte so bspw. das Erstellen des Vektors c(1, 2, 3, 4) etwas abkürzen. 1:4 [1] 1 2 3 4 Der Doppelpunkt ist dabei ein Shortcut für seq() (sequence, engl. für Sequenz). seq(from = 1, to = 4, by = 1) [1] 1 2 3 4 Zusätzlich können hier auch die Abstände zwischen den Zahlen der Frequenz kleiner oder größer gewählt werden (z.B. by = 0.2 oder by = 2). Auf einzelne Werte innerhalb eines Vektors kann mithilfe eckiger Klammern zugegriffen werden. Exemplarisch wird hier das dritte Element des Vektors c(1, 3, 2, 4), welcher als vec gespeichert ist, ausgewählt. vec &lt;- c(1, 3, 2, 4) vec[3] [1] 2 Die eckigen Klammern können auch mit c() oder dem Doppelpunkt kombiniert werden, um mehrere Elemente ausgeben zu lassen. vec[c(1, 4)] [1] 1 4 vec[1:2] [1] 1 3 Vektoren können immer nur einen Datentyp enthalten. Wenn eine Zahl mit einem Wort kombiniert wird, werden alle im Vektor enthaltenen Werte zum Typ Character umgewandelt. 11.2 Matrix Wenn man mehrere Vektoren eines Datentyps aneinander bindet, erhält man eine Matrix. Für zeilenweises Binden der Vektoren wird rbind() verwendet (row bind, engl. für Zeilen verbinden). Dabei müssen alle Vektoren dieselbe Länge haben. rbind( c(1, 3, 2, 4), 1:4 ) [,1] [,2] [,3] [,4] [1,] 1 3 2 4 [2,] 1 2 3 4 Das Äquivalent zum Verbinden von Spalten ist cbind() (column bind, engl. für Spalten verbinden). cbind( c(1, 3, 2, 4), 1:4 ) [,1] [,2] [1,] 1 1 [2,] 3 2 [3,] 2 3 [4,] 4 4 Seltener in der Datenanalyse benutzt, aber trotzdem manchmal nützlich ist die matrix() Funktion. Als Argumente müssen der Vektor, die Anzahl der Zeilen oder Spalten sowie die Information übergeben werden, ob die Werte zeilenweise (byrow) eingefügt werden sollen. mat &lt;- matrix( 1:9, ncol = 3, byrow = TRUE ) mat [,1] [,2] [,3] [1,] 1 2 3 [2,] 4 5 6 [3,] 7 8 9 Da nun zwei Dimensionen involviert sind, müssen zum Zugreifen auf Elemente innerhalb der Matrix auch zwei Parameter berücksichtigt werden: die Spalten- und Zeilenposition. Dabei werden innerhalb der eckigen Klammern getrennt von einem Komma zuerst die Zeilen und dann die Spalten angegeben. Möchte man den Wert aus Zeile 2 und Spalte 3 erhalten, würde man [2, 3] an den Variablennamen hängen. mat[2, 3] [1] 6 Wenn eine ganze Zeile oder Spalte zurückgeben werden soll, lässt man schlichtweg das auszulassende Argument weg. Für die erste Zeile schreibt man folglich: mat[1, ] [1] 1 2 3 Das Leerzeichen nach dem Komma ist zwar nicht zwingend notwendig, allerdings macht es deutlich, dass dort ein zweiter Wert fehlt. Genau wie Vektoren können auch in Matrizen nur Werte von einem Datentyp gespeichert werden. Bei Vermischung der Datentypen wird automatisch die Umwandlungsregel Character &gt; Integer &gt; Logical angewandt. Außerdem müssen die Vektoren innerhalb der Matrix dieselbe Länge haben. Aufgrund der Limitation, nur einen Datentyp enthalten zu können, findet die Matrix als Datenstruktur in der gewöhnlichen Datenanalyse in der Regel keine Anwendung. 11.3 Data.frame und tibble Ein data.frame ist ein zweidimensionales Datenformat, welches direkt in R integriert ist. Hingegen müssen tibbles aus dem gleichnamigen tibble Package des tidyverse zur Verwendung nach jedem Start von R neu geladen werden. Beide haben eine Anordnung wie die Matrix mit Zeilen und Spalten. Zwischen den Spalten darf der Datentyp variieren, wobei innerhalb einer Spalte noch immer derselbe Datentyp vorhanden sein muss. Einer der größten Vorteile der tibbles ist die übersichtlichere Ausgabe. Es werden nur 10 Zeilen ausgegeben. Auf einen Blick sieht man dabei die Datentypen der Spalten und die Dimensionen des Datensatzes. Außerdem sind die Zahlen zur besseren Übersichtlichkeit entsprechend eingerückt und negative Werte rot hervorgehoben. Das automatische Runden von tibbles bei der Anzeige ist hingegen nicht immer ein Vorteil. Während es beim explorativen Anschauen der Daten praktisch ist, muss beim deskriptiven oder inferenzstatistischen Betrachten der Daten eine bestimmte Anzahl von Kommastellen sichtbar sein, um sie in einer wissenschaftlichen Arbeit zu berichten. Grundsätzlich sind Funktionen, die für data.frames verwendet werden können, bis auf wenige Ausnahmen auch auf tibbles anwendbar. Wie man einen tibble erstellt, wurde bereits in Kapitel 5.3 eingeführt. Bei der Erstellung eines data.frames ändert sich nur die Funktion. data.frame( a = 1:2, b = 3:4 ) a b 1 1 3 2 2 4 Beim Zugriff auf einzelne Spalten wurde im Verlauf des Buches entweder select() aus dem tidyverse oder der Dollar-Operator verwendet. Die Funktion select() gibt dabei die einzelne Spalte als tibble zurück. tb &lt;- tibble( Geschlecht = c(&quot;m&quot;, &quot;f&quot;, &quot;d&quot;), Alter = c(44, 16, 52), ) tb |&gt; select(Alter) # A tibble: 3 × 1 Alter &lt;dbl&gt; 1 44 2 16 3 52 Eine alternative Schreibweise dafür sind einfache eckige Klammern. Da hier alle Zeilen der Spalte Alter zurückgegeben werden sollen, wird keine Zahl vor dem Komma angegeben. tb[ ,&quot;Alter&quot;] # A tibble: 3 × 1 Alter &lt;dbl&gt; 1 44 2 16 3 52 Hier gibt es einen weiteren Unterschied zwischen data.frames und tibbles. Während in data.frames bei Auswahl nur einer Spalte ein Vektor zurückgegeben wird, gibt ein tibble immer einen tibble zurück. Einzelne Spalten als Vektor können entweder mit dem Dollar-Zeichen oder mit doppelten eckigen Klammern mit dem Spaltennamen in Anführungszeichen aus einem data.frame oder tibble extrahiert werden. tb$Alter tb[[&quot;Alter&quot;]] [1] 44 16 52 Einzelne Werte können mit einfachen eckigen Klammern äquivalent zu Matrizen ausgewählt werden. tb[2, 1] # A tibble: 1 × 1 Geschlecht &lt;chr&gt; 1 f 11.4 Liste Listen sind die allgemeinste Datenstruktur. Ein Listenelement kann jede Datenstruktur enthalten – sogar ganze tibbles. Beim Erstellen ändert sich der Befehl zu list(). ls &lt;- list( Vektor = vec, Matrix = mat, Tibble = tb ) ls $Vektor [1] 1 3 2 4 $Matrix [,1] [,2] [,3] [1,] 1 2 3 [2,] 4 5 6 [3,] 7 8 9 $Tibble # A tibble: 3 × 2 Geschlecht Alter &lt;chr&gt; &lt;dbl&gt; 1 m 44 2 f 16 3 d 52 Die Zeichen vor dem Gleichheitszeichen sind dabei die Namen der Listenelemente, die man zum Abrufen verwenden kann. Mit Listen haben wir bis zu drei Dimensionen. Die verschiedenen Elemente innerhalb der Liste, die wiederum zweidimensionale tibbles enthalten können. Es ist sogar möglich, Listen innerhalb von Listen zu speichern. Im Rahmen des Einnistens greifen wir diesen Gedanken in Kapitel 12.4 wieder auf. Das Prinzip beim Zugreifen ändert sich im Vergleich zu tibbles nicht. Allerdings gibt es eine Dimensionen mehr. Würde man also auf den tibble der eben erstellen Liste ls zugreifen wollen, könnte man ls$Tibble oder ls[[3]] verwenden. Möchte man direkt auf Elemente innerhalb des tibbles zugreifen, erreicht man dies wie gewohnt mit einfach eckigen Klammern. ls[[3]][1, 2] # A tibble: 1 × 1 Alter &lt;dbl&gt; 1 44 Eine leere Liste einer bestimmten Länge kann mit vector() erstellt werden (hier z.B. eine Liste der Länge 3). Dies ist vor allem bei for-Schleifen wichtig, da so die Dauer der Berechnungen reduziert werden kann (siehe Kapitel 12.3). vector(&quot;list&quot;, 3) [[1]] NULL [[2]] NULL [[3]] NULL Eine besondere Art der Liste ist der tibble. Daher können wir grundsätzlich in eine Zelle nicht nur Zahlen oder Buchstaben hineinschreiben, sondern sogar ganze andere Datensätze darin abspeichern. df &lt;- tibble( a = c(1, 2, 3), b = list( tibble(a = c(1, 2, 3, 4), b = c(&quot;m&quot;, &quot;f&quot;, &quot;f&quot;, &quot;m&quot;)), tibble(x = 4:5, y = 6:7), Number = 1 ) ) df # A tibble: 3 × 2 a b &lt;dbl&gt; &lt;named list&gt; 1 1 &lt;tibble [4 × 2]&gt; 2 2 &lt;tibble [2 × 2]&gt; 3 3 &lt;dbl [1]&gt; Wie du siehst, sind in der Spalte b nun in den ersten zwei Zeilen tibbles enthalten. Wenn wir mit df$b oder df[[2]] nur diese Spalte anschauen, sehen wir eine Liste als Ausgabe. df[[2]] [[1]] # A tibble: 4 × 2 a b &lt;dbl&gt; &lt;chr&gt; 1 1 m 2 2 f 3 3 f 4 4 m [[2]] # A tibble: 2 × 2 x y &lt;int&gt; &lt;int&gt; 1 4 6 2 5 7 $Number [1] 1 11.5 Umwandlungen Sofern die Voraussetzungen der Dimensionen und Datentypen erfüllt sind, können Datenstrukturen ineinander überführt werden. Dabei haben die Funktionen immer das Präfix as. mit der Ausnahme bei tibbles mit dem Präfix as_. as.vector() as.matrix() as.data.frame() as_tibble() Besonders nützlich ist hierbei as.data.frame(), um einen tibble in einen data.frame umzuwandeln, falls die angezeigten Rundungen zu ungenau sind oder Funktionen nur mit data.frames fehlerfrei funktionieren. Für as_tibble() muss zuvor das tibble Package oder das tidyverse geladen sein. 11.6 Objektorientierung Für dieses Kapitel muss das sloop Package installiert und geladen werden. library(sloop) Grundsätzlich basieren die meisten bisher kennengelernten Datenstrukturen auf dem sogenannten S3 System der Objektorientierung. Das ist für den normalen R Nutzer nicht relevant, allerdings gibt es noch drei andere Systeme namens S4, R6 und R7. Diese können wir nicht ohne Weiteres mit den hier kennengelernten Funktion verwenden. Ein populäres Beispiel dafür ist die Seite Bioconductor (Alternative zu CRAN), welche diverse Packages mit biologischem Fokus zur Verfügung stellt. Dort haben beinahe alle Packages das S4 System als Basis, wodurch bspw. anstelle des Dollar-Operators mit dem at-Zeichen (@) auf Spalten zugegriffen werden muss. ls@Tibbel Dies sei an dieser Stelle nur deshalb beschrieben, da S4 und R6 Systeme zu seltsamen Fehlermeldungen führen können, wenn man die normalen Funktionen darauf anwendet. Mit der Funktion otype() aus dem sloop Package kann der Objekttyp herausgefunden werden. otype(big_five) [1] &quot;S3&quot; Langfristig werden voraussichtlich das S4 und R6 System vom neuen R7 System ersetzt werden, welches planmäßig direkt in R integriert werden soll. "],["iterationmain.html", "Kapitel 12 Funktionen wiederholt anwenden 12.1 Das Copy &amp; Paste Problem 12.2 Listenbasierte Berechnungen 12.3 for-Schleifen 12.4 Einnisten", " Kapitel 12 Funktionen wiederholt anwenden Im Zuge der Datenanalyse muss man häufig dieselben Berechnungen für mehrere Szenarien vornehmen. Um sich Zeit zu sparen und die Häufigkeit von Fehlern zu minimieren, existieren in jeder Programmiersprache sogenannte Schleifen. In diesem Kapitel lernst du drei verschiedene Arten kennen, diese sogenannten iterativen Prozesse selbst in R umzusetzen. 12.1 Das Copy &amp; Paste Problem In diesem Kapitel ist das Installieren und Laden des purrr Packages aus dem tidyverse eine Voraussetzung. library(tidyverse) In vielen Szenarien ist es nötig, die Funktion nicht nur einmal, sondern mehrmals anzuwenden. Die naheliegende Lösung dafür ist den Funktionsaufruf zu kopieren und leicht modifiziert für den nächsten Anwendungsfall zu verwenden. Ein Beispiel dafür haben wir bereits in Kapitel 9.6 beim Ausgeben der Häufigkeiten kategorialer Variablen gesehen. Wenn ein oder zwei Häufigkeiten ausgegeben werden sollen, ist das Kopieren der Funktion noch kein Problem. table(big5_mod$Geschlecht) f m 118 82 table(big5_mod$Gruppe) Jung Mittel Weise 147 39 14 Falls jedoch die Häufigkeiten von 20 bis 30 Variablen gewünscht sind, ist das Kopieren der jeweiligen Funktion nicht nur zeitaufwendig, sondern auch fehleranfällig. Im Verlauf der nächsten Kapitel werden wir drei mögliche Automatisierungen kennenlernen: map(), for-Schleifen und Einnisten. Mit der Funktion map() können wir die Funktion table() zur Berechnung der Häufigkeiten auf jede ausgewählte Spalte anwenden. Es werden also zuerst die Häufigkeiten der Geschlechter und anschließend die der Altersgruppen berechnet. big5_mod |&gt; select(Geschlecht, Gruppe) |&gt; map(table) $Geschlecht f m 118 82 $Gruppe Jung Mittel Weise 147 39 14 Durch einen weiteren Aufruf von map() dieses Mal mit der Funktion prop.table() können zusätzlich die Verhältnisse der Merkmale ausgegeben werden. big5_mod |&gt; select(Geschlecht, Gruppe) |&gt; map(table) |&gt; map(prop.table) $Geschlecht f m 0.59 0.41 $Gruppe Jung Mittel Weise 0.735 0.195 0.070 Da Häufigkeiten in der Regel nur bei kategorialen Variablen erwünscht sind, könnten wir auch nur Spalten vom Datentyp Character oder Factor ausrechnen lassen (siehe Kapitel 6.2). big5_mod |&gt; select(where(is.character) | where(is.factor)) |&gt; map(table) Copy &amp; Paste ist fehleranfällig und sollte nur bei weniger als zehn wiederholten Anwendungen von Funktionen verwendet werden. Alternativ können diese Funktionswiederholungen auf verschiedene Arten automatisiert werden. 12.2 Listenbasierte Berechnungen Für dieses Kapitel muss das purrr Package aus dem tidyverse installiert und geladen werden. library(tidyverse) Ein Beispiel zum wiederholten Anwenden einer Funktion mithilfe von map() wurde bereits im vorherigen Kapitel eingeführt. Während dort die Funktion auf einen tibble angewandt wurde (eine Sonderform der Liste), werden wir uns hier den klassischen Anwendungsfall von map() im Kontext von Listen anschauen. Als Beispiel wollen wir an dieser Stelle ein lineares Regressionsmodell zur Erklärung der Variation von Extraversion durch Geschlecht für jede Altersgruppe einzeln berechnen (siehe Kapitel 9.5.1). Dafür trennen wir den Datensatz zunächst mithilfe der Funktion split() in eine Liste mit drei Elementen. Das erste Element enthält einen Datensatz mit den jüngsten Personen, das zweite die mittlere Altersklasse und das dritte Element die Ältesten. mod_ls &lt;- split(big5_mod, ~ Gruppe) Zum Erstellen der Regressionsmodelle kopieren wir den Befehl dreimalig. Dabei wird jedes Mal mithilfe der doppelten eckigen Klammern auf ein anderes Listenelement zugegriffen (siehe Kapitel 11.4). model1 &lt;- lm(Extraversion ~ Geschlecht, data = mod_ls[[1]]) model2 &lt;- lm(Extraversion ~ Geschlecht, data = mod_ls[[2]]) model3 &lt;- lm(Extraversion ~ Geschlecht, data = mod_ls[[3]]) Mit der Funktion map() kann das redundante Kopieren der Funktion vermieden werden. Als einziges Argument wird das Regressionsmodell als anonyme Lambdafunktion übergeben (siehe Kapitel 6.4.4). Als Ergebnis erhalten wir eine Liste mit einem Modell pro Listenelement. mod_ls |&gt; map(\\(teildaten) lm(Extraversion ~ Geschlecht, data = teildaten)) $Jung Call: lm(formula = Extraversion ~ Geschlecht, data = teildaten) Coefficients: (Intercept) Geschlechtm 3.067 0.055 $Mittel Call: lm(formula = Extraversion ~ Geschlecht, data = teildaten) Coefficients: (Intercept) Geschlechtm 3.07000 0.05632 $Weise Call: lm(formula = Extraversion ~ Geschlecht, data = teildaten) Coefficients: (Intercept) Geschlechtm 2.8333 0.1267 Mit einem weiteren Aufruf von map() können wir für jedes der drei Modelle die Zusammenfassungen der Ergebnisse zeigen. mod_ls |&gt; map(\\(teildaten) lm(Extraversion ~ Geschlecht, data = teildaten)) |&gt; map(summary) Alternativ könnte auch die tidy() Funktion zum Ausgeben als tibble (anstelle einer Liste) verwendet werden (siehe Kapitel 9.8). Da die gewünschte Ausgabe hier ein tibble bzw. data.frame (kurz: df) ist, müssen wir stattdessen die Funktion map_df() benutzen. mod_ls |&gt; map(\\(teildaten) lm(Extraversion ~ Geschlecht, data = teildaten)) |&gt; map_df(tidy) # A tibble: 6 × 5 term estimate std.error statistic p.value &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) 3.07 0.0376 81.6 4.49e-123 2 Geschlechtm 0.0550 0.0598 0.919 3.60e- 1 3 (Intercept) 3.07 0.0649 47.3 1.08e- 34 4 Geschlechtm 0.0563 0.0930 0.605 5.49e- 1 # … with 2 more rows Wenn die Ausgabe nicht als Liste erfolgen soll, verändert sich der Funktionsname je nach gewünschter Datenstruktur und gewünschtem Datentyp in andere Varianten von map() (z.B. map_chr() für Character Vektoren oder map_dbl() für numerische Vektoren). Alternativ sind Funktionen mit ähnlicher Funktionsweise direkt in R integriert, die allerdings mitunter umständlicher zu verwenden sind (z.B. lapply(), apply(), tapply() und mapply()). Innerhalb der hier vorgestellten Funktionen werden sogenannte Schleifen verwendet. 12.3 for-Schleifen Eine wiederholte Anwendung von Funktionen für jeden Kontext unabhängig der Datenstruktur und des Datentyps wird durch for-Schleifen ermöglicht. Um das Konzept einzuführen, greifen wir an dieser Stelle auf dieselbe listenbasierte Berechnung mehrerer linearer Regressionmodelle des vorherigen Kapitels zurück. Zuerst wird also erneut der Datensatz als Liste aufgeteilt. mod_ls &lt;- split(big5_mod, ~ Gruppe) Mit Copy &amp; Paste müsste das Modell dreimalig ausgeschrieben werden. model1 &lt;- lm(Extraversion ~ Geschlecht, data = mod_ls[[1]]) model2 &lt;- lm(Extraversion ~ Geschlecht, data = mod_ls[[2]]) model3 &lt;- lm(Extraversion ~ Geschlecht, data = mod_ls[[3]]) Den ersten Schritt beim Berechnen einer for-Schleife stellt das Kreieren einer leeren Ergebnisliste dar. erg_ls &lt;- vector(&quot;list&quot;, 3) erg_ls [[1]] NULL [[2]] NULL [[3]] NULL Falls das Ergebnis für andere Kontexte nicht als Liste, sondern bspw. als numerischer Vektor gespeichert werden soll, könnte man stattdessen vector(\"numeric\", 3) wählen. In der eigentlichen Schleife soll für jedes i von 1 bis 3 das Modell aufgestellt und in erg_ls an entsprechender Stelle gespeichert werden. Dabei greifen wir auf den jeweiligen Datensatz an der Stelle von Index i aufgrund der Liste innerhalb einer doppelten eckigen Klammer zu. for(i in 1:3) { erg_ls[[i]] &lt;- lm(Extraversion ~ Geschlecht, data = mod_ls[[i]]) } erg_ls [[1]] Call: lm(formula = Extraversion ~ Geschlecht, data = mod_ls[[i]]) Coefficients: (Intercept) Geschlechtm 3.067 0.055 [[2]] Call: lm(formula = Extraversion ~ Geschlecht, data = mod_ls[[i]]) Coefficients: (Intercept) Geschlechtm 3.07000 0.05632 [[3]] Call: lm(formula = Extraversion ~ Geschlecht, data = mod_ls[[i]]) Coefficients: (Intercept) Geschlechtm 2.8333 0.1267 Eine sinnvolle Herangehensweise beim Erstellen von for-Schleifen ist es, den zu wiederholenden Funktionsaufruf zwei- bis dreimal zu kopieren, weil so die Automatisierung leichter fällt. In unserem Beispiel konnten wir so sehen, dass sich nur mod_ls[[1]] zu mod_ls[[2]] und mod_ls[[3]] verändert. Effiziente Schleifen zu schreiben ist nicht einfach. Daher sollte nach Möglichkeit auf die map() Funktionen aus dem purrr Package zurückgegriffen werden. Dies macht sich vor allem bei großen Datensätzen bemerkbar (siehe Kapitel 12.2). 12.4 Einnisten Zum Bearbeiten dieses Kapitels muss das tidyr Package aus dem tidyverse geladen werden. library(tidyverse) Durch die Funktion nest() können innerhalb von Zellen eines tibbles Datenstrukturen jeder Art verschachtelt werden. Dies wurde bereits in Kapitel 11.4 anhand eines einfachen Beispiels eingeführt. Dieses Konzept wenden wir beim big5_mod Datensatz an und gruppieren dafür innerhalb von nest() mithilfe des Arguments .by. big5_mod |&gt; nest(.by = Gruppe) # A tibble: 3 × 2 Gruppe data &lt;fct&gt; &lt;list&gt; 1 Mittel &lt;tibble [39 × 5]&gt; 2 Jung &lt;tibble [147 × 5]&gt; 3 Weise &lt;tibble [14 × 5]&gt; Als Ergebnis erhalten wir einen tibble, welcher in der ersten Spalte die Altersgruppen abbildet. Daneben steht eine neue zweite Spalte namens data, in der wiederum drei tibbles mit den Dimensionen 39x5, 147x5 und 14x5 gespeichert sind. Ähnlich wie bei den listenbasierten Berechnungen in Kapitel 12.2 können wir auch auf diese verschachtelten tibbles die map() Funktionen anwenden. Der Unterschied besteht darin, dass wir den Befehl innerhalb von mutate() ausführen müssen (siehe Kapitel 6.4). Schließlich soll mit den Inhalten einer Spalte eines tibbles eine neue Spalte erstellt werden. Im zweiten Schritt nehmen wir die Modelle und geben diese in einem aufgeräumten Format mit der Funktion tidy() aus (siehe Kapitel 9.8). big5_mod |&gt; nest(.by = Gruppe) |&gt; mutate( Modelle = map(data, \\(teildaten) lm(Extraversion ~ Geschlecht, data = teildaten)), Ergebnisse = map(Modelle, tidy) ) # A tibble: 3 × 4 Gruppe data Modelle Ergebnisse &lt;fct&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; 1 Mittel &lt;tibble [39 × 5]&gt; &lt;lm&gt; &lt;tibble [2 × 5]&gt; 2 Jung &lt;tibble [147 × 5]&gt; &lt;lm&gt; &lt;tibble [2 × 5]&gt; 3 Weise &lt;tibble [14 × 5]&gt; &lt;lm&gt; &lt;tibble [2 × 5]&gt; Die neue Spalte namens Modelle hat Einträge des Datentyps &lt;lm&gt; (die linearen Modelle). Daneben sind die Ergebnisse von tidy() verschachtelt (u.a. mit Teststatistiken und p-Werten). Damit wir an diese Ergebnisse herankommen, müssen wir diese abschließend mit der Funktion unnest() aus der eingenisteten Struktur herausholen. big5_mod |&gt; nest(.by = Gruppe) |&gt; mutate( Modelle = map(data, \\(teildaten) lm(Extraversion ~ Geschlecht, data = teildaten)), Ergebnisse = map(Modelle, tidy) ) |&gt; unnest(Ergebnisse) # A tibble: 6 × 8 Gruppe data Modelle term estimate std.error statistic p.value &lt;fct&gt; &lt;list&gt; &lt;list&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 Mittel &lt;tibble [39 × 5]&gt; &lt;lm&gt; (Intercept) 3.07 0.0649 47.3 1.08e- 34 2 Mittel &lt;tibble [39 × 5]&gt; &lt;lm&gt; Geschlechtm 0.0563 0.0930 0.605 5.49e- 1 3 Jung &lt;tibble [147 × 5]&gt; &lt;lm&gt; (Intercept) 3.07 0.0376 81.6 4.49e-123 4 Jung &lt;tibble [147 × 5]&gt; &lt;lm&gt; Geschlechtm 0.0550 0.0598 0.919 3.60e- 1 # … with 2 more rows "],["appendix.html", "Appendix Datensatzerläuterungen Literaturverzeichnis Verwendete Softwareversionen", " Appendix Datensatzerläuterungen Big Five Der Datensatz enthält die soziodemographische Variablen Alter und Geschlecht, die durchschnittliche Ausprägung der Big 5 Persönlichkeitsfaktoren Extraversion, Neurotizismus, Verträglichkeit und Gewissenhaftigkeit sowie 10 Fragen, um die Offenheit für neue Erfahrungen zu messen. Jede Frage wurde auf einer Likert Skala erhoben (1: Stimme überhaupt nicht zu, 2: Stimme etwas zu, 3: Neutral, 4: Stimme zu, 5: Stimme voll und ganz zu). Weitere Datensätze Für Informationen über andere Datensätze sei auf die Dokumentation verwiesen. Literaturverzeichnis "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
